{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f44f25518fb4e06b2f91a40c4392d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23186c287e6248f699ee0c81e5d9da7a",
              "IPY_MODEL_cd65aa5e68e3411dbc71139ca9797d03",
              "IPY_MODEL_48bf1e2a7d1e438bb6ffc519194797bb"
            ],
            "layout": "IPY_MODEL_2a3610f955c84452892513e2fe37611f"
          }
        },
        "23186c287e6248f699ee0c81e5d9da7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b62f25e7c594b109f2a78b1e440d8b4",
            "placeholder": "​",
            "style": "IPY_MODEL_9e4fbc333a214b7c9220d736d3a73798",
            "value": "config.json: 100%"
          }
        },
        "cd65aa5e68e3411dbc71139ca9797d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ee8cf36f4c41e1b2db8b24dd70a18a",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94768292709e4d71a56db30d4778c0bc",
            "value": 614
          }
        },
        "48bf1e2a7d1e438bb6ffc519194797bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d88fc8d38804c5f9b8f670922d05979",
            "placeholder": "​",
            "style": "IPY_MODEL_368b868468a64933b71e0cbe6ce11946",
            "value": " 614/614 [00:00&lt;00:00, 41.5kB/s]"
          }
        },
        "2a3610f955c84452892513e2fe37611f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b62f25e7c594b109f2a78b1e440d8b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4fbc333a214b7c9220d736d3a73798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3ee8cf36f4c41e1b2db8b24dd70a18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94768292709e4d71a56db30d4778c0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d88fc8d38804c5f9b8f670922d05979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368b868468a64933b71e0cbe6ce11946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2043ec35e4f4d3d951bb9fd45b25f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dc10852032c4cfe967aa69301c645f9",
              "IPY_MODEL_71cf0489caab462ebc3ee501e514e6c3",
              "IPY_MODEL_1516ca70c6f84c86a8696cf607d03d7d"
            ],
            "layout": "IPY_MODEL_3edc97bce2a2464dbf9eae1f5492ced7"
          }
        },
        "1dc10852032c4cfe967aa69301c645f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9368a2ea1ff740659040f9df00c9cf70",
            "placeholder": "​",
            "style": "IPY_MODEL_ddce9ee35bdc47c384d26c84a395d1dc",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "71cf0489caab462ebc3ee501e514e6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1972bc94832d4498bf9e1d20a0c0e2f1",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98a7c2fa34cf4b30966f16cff77d556c",
            "value": 26788
          }
        },
        "1516ca70c6f84c86a8696cf607d03d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dcec5edfa7d460f96e4fa25453bab85",
            "placeholder": "​",
            "style": "IPY_MODEL_83a339373e7545f2bafa38b5bac22f89",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.19MB/s]"
          }
        },
        "3edc97bce2a2464dbf9eae1f5492ced7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9368a2ea1ff740659040f9df00c9cf70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddce9ee35bdc47c384d26c84a395d1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1972bc94832d4498bf9e1d20a0c0e2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a7c2fa34cf4b30966f16cff77d556c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dcec5edfa7d460f96e4fa25453bab85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a339373e7545f2bafa38b5bac22f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fde39d34b91442d84aaf6f1089d20f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d05943c50334fbaa3dcc5ff6b97d1e7",
              "IPY_MODEL_a32a92fd8b3d462695bdf75c60085eab",
              "IPY_MODEL_f6b25b2b9694422da7efb6bb8f928f04"
            ],
            "layout": "IPY_MODEL_0df2d910af13486690fc794a6c8271ae"
          }
        },
        "8d05943c50334fbaa3dcc5ff6b97d1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9625cb33e26642209ab32abc4a36464e",
            "placeholder": "​",
            "style": "IPY_MODEL_7c34927a88034f3c970f8dd4cccc9a2f",
            "value": "Downloading shards: 100%"
          }
        },
        "a32a92fd8b3d462695bdf75c60085eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e4699427c840eab0dfb06e5ae03e08",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7692035db3f6483ab83284352d171379",
            "value": 2
          }
        },
        "f6b25b2b9694422da7efb6bb8f928f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aa6f900a01d4576bc5d247c29d64410",
            "placeholder": "​",
            "style": "IPY_MODEL_af88faad4c8d4cb1887501c9e30351f6",
            "value": " 2/2 [01:01&lt;00:00, 28.13s/it]"
          }
        },
        "0df2d910af13486690fc794a6c8271ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9625cb33e26642209ab32abc4a36464e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c34927a88034f3c970f8dd4cccc9a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85e4699427c840eab0dfb06e5ae03e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7692035db3f6483ab83284352d171379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5aa6f900a01d4576bc5d247c29d64410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af88faad4c8d4cb1887501c9e30351f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a7ec53a2a654edbb649723d9f237845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcc75806a4e64ad484639af4b0a3a8e8",
              "IPY_MODEL_34546d917667447787e3ce76b04d67dd",
              "IPY_MODEL_e31a6092c8be4e358eb03362cca38fe2"
            ],
            "layout": "IPY_MODEL_aded0e543ca941318750705f8221f966"
          }
        },
        "bcc75806a4e64ad484639af4b0a3a8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_564416f44e854691ba1534375def19c8",
            "placeholder": "​",
            "style": "IPY_MODEL_e24c6d3012024d5db0741c40f484b515",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "34546d917667447787e3ce76b04d67dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b7bc54d5cbe438292831364dcae0673",
            "max": 9976576152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b93d1829220b4c74a4c6573ade108800",
            "value": 9976576152
          }
        },
        "e31a6092c8be4e358eb03362cca38fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49f4e568589b4afa9c6ff843627013cc",
            "placeholder": "​",
            "style": "IPY_MODEL_a85edd49a25a4af9a161cd039d1d8767",
            "value": " 9.98G/9.98G [00:43&lt;00:00, 166MB/s]"
          }
        },
        "aded0e543ca941318750705f8221f966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "564416f44e854691ba1534375def19c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e24c6d3012024d5db0741c40f484b515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b7bc54d5cbe438292831364dcae0673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b93d1829220b4c74a4c6573ade108800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49f4e568589b4afa9c6ff843627013cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85edd49a25a4af9a161cd039d1d8767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "820ce7adac774fed80309d963109fd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83fcdd717fbb47c0b611c5d7dd5a8d29",
              "IPY_MODEL_78ca0f3dcf89406f8b0753d5a6c2bc14",
              "IPY_MODEL_4c35956eb73d414ba15ba5ebf3aafeef"
            ],
            "layout": "IPY_MODEL_901135536aa546ff9c7214c57f49a6a7"
          }
        },
        "83fcdd717fbb47c0b611c5d7dd5a8d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b52925d0c7489eae1b1f2fe4755c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_0428a6d06c1a4b5a801c132bd87e4d7d",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "78ca0f3dcf89406f8b0753d5a6c2bc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca67f3cc34d45c599b2c69dafa17fce",
            "max": 3500296424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fbf2edd3e1647ab9f5f912e964aa0ed",
            "value": 3500296424
          }
        },
        "4c35956eb73d414ba15ba5ebf3aafeef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc5ee63c2c14c22bd6f6e80c3d94055",
            "placeholder": "​",
            "style": "IPY_MODEL_1f36e5588c444f06ba794fb2a39247f4",
            "value": " 3.50G/3.50G [00:16&lt;00:00, 249MB/s]"
          }
        },
        "901135536aa546ff9c7214c57f49a6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b52925d0c7489eae1b1f2fe4755c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0428a6d06c1a4b5a801c132bd87e4d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dca67f3cc34d45c599b2c69dafa17fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fbf2edd3e1647ab9f5f912e964aa0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fc5ee63c2c14c22bd6f6e80c3d94055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f36e5588c444f06ba794fb2a39247f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24a9e407b46d40c6af2505c24ce2ac9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef6118a4805542368862eb4af4fe9097",
              "IPY_MODEL_e765b1d1ec5a4726b54cf5fd002dd710",
              "IPY_MODEL_1f0b1e9b4d9040749d0d7a8bf90855ec"
            ],
            "layout": "IPY_MODEL_d2bb2017a864437cbd87caae59bbf499"
          }
        },
        "ef6118a4805542368862eb4af4fe9097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9fba519e21f441eac977bbf0ec7cef5",
            "placeholder": "​",
            "style": "IPY_MODEL_2f893b02cd9943b3a993fa0a2b1d4016",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e765b1d1ec5a4726b54cf5fd002dd710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c154b8107604d1c9e1e8eef658a2549",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57c09239648b469d947eea45903bc08a",
            "value": 2
          }
        },
        "1f0b1e9b4d9040749d0d7a8bf90855ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00eb3d1e74a4279b6e59b43bffd56f6",
            "placeholder": "​",
            "style": "IPY_MODEL_4755b7a0fd5e4e03b05b5a1d6dc66345",
            "value": " 2/2 [00:58&lt;00:00, 26.99s/it]"
          }
        },
        "d2bb2017a864437cbd87caae59bbf499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9fba519e21f441eac977bbf0ec7cef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f893b02cd9943b3a993fa0a2b1d4016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c154b8107604d1c9e1e8eef658a2549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57c09239648b469d947eea45903bc08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b00eb3d1e74a4279b6e59b43bffd56f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4755b7a0fd5e4e03b05b5a1d6dc66345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6de30dbda7db47869a9b3a943536c614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4251b30ca904278b9c1cd907d2ea33c",
              "IPY_MODEL_00b0001629a641c284964ba5ed671f73",
              "IPY_MODEL_9471753f1c3541fdab8f58d2de85ce25"
            ],
            "layout": "IPY_MODEL_c6534ba2e08d4b25ac9b8b218f1d30b2"
          }
        },
        "c4251b30ca904278b9c1cd907d2ea33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8f31d2572604f22b37f54a7c0122340",
            "placeholder": "​",
            "style": "IPY_MODEL_57b7dd1abe9e41bea5f6e1221c62ec8e",
            "value": "generation_config.json: 100%"
          }
        },
        "00b0001629a641c284964ba5ed671f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_085833309e7d4ecbb3b68f48f9ce4b99",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f260a76dfaf4a5abb1e7ec5c37f2430",
            "value": 188
          }
        },
        "9471753f1c3541fdab8f58d2de85ce25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c5624fd0b042d0b45b9937efb61a79",
            "placeholder": "​",
            "style": "IPY_MODEL_839bc671e5dd48a4a0a488494caa594f",
            "value": " 188/188 [00:00&lt;00:00, 12.2kB/s]"
          }
        },
        "c6534ba2e08d4b25ac9b8b218f1d30b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8f31d2572604f22b37f54a7c0122340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b7dd1abe9e41bea5f6e1221c62ec8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "085833309e7d4ecbb3b68f48f9ce4b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f260a76dfaf4a5abb1e7ec5c37f2430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4c5624fd0b042d0b45b9937efb61a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "839bc671e5dd48a4a0a488494caa594f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0cc51d8af524bda93c87a51aeb668bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65b7fb7ce2164875b962b2749f1b3b23",
              "IPY_MODEL_36bc261dbffa4d71afcbc4141185cd16",
              "IPY_MODEL_3ab0120f427e45e49d45d80e448d19e9"
            ],
            "layout": "IPY_MODEL_16d7071b113c480191a4aeaf7c6d3644"
          }
        },
        "65b7fb7ce2164875b962b2749f1b3b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3efb4bac6e40f5b0ffa0efeeda8b7c",
            "placeholder": "​",
            "style": "IPY_MODEL_d0d3943866e344d3809de54f60d78c98",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "36bc261dbffa4d71afcbc4141185cd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_108729f80ee54e4d80268bbc1550dd3d",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68e9a7ff491543f38d9986eabd057f78",
            "value": 1618
          }
        },
        "3ab0120f427e45e49d45d80e448d19e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5017fe0f175d46d3be30d818b107d849",
            "placeholder": "​",
            "style": "IPY_MODEL_a2b43515c26442fdbf52c3dcc01849b0",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 115kB/s]"
          }
        },
        "16d7071b113c480191a4aeaf7c6d3644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3efb4bac6e40f5b0ffa0efeeda8b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0d3943866e344d3809de54f60d78c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "108729f80ee54e4d80268bbc1550dd3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e9a7ff491543f38d9986eabd057f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5017fe0f175d46d3be30d818b107d849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b43515c26442fdbf52c3dcc01849b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e47f91060af45589ce64113762d253b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38694bf78ea44694841f0871d48327d4",
              "IPY_MODEL_5a3d6534d9824991a33fd59454613bfa",
              "IPY_MODEL_a2eb66b5210d4a1ea212efc4357c5fb0"
            ],
            "layout": "IPY_MODEL_73f409df692c44e2884196d8067067e1"
          }
        },
        "38694bf78ea44694841f0871d48327d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c52b52b2d9744c1f990c756c486aae73",
            "placeholder": "​",
            "style": "IPY_MODEL_539653d0fc714982b22d29e1b711ff81",
            "value": "tokenizer.model: 100%"
          }
        },
        "5a3d6534d9824991a33fd59454613bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cebac32c040a44008e29c83f6baca16f",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_053fb6ab8e3841abbcfaa70303449527",
            "value": 499723
          }
        },
        "a2eb66b5210d4a1ea212efc4357c5fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b169dec2097b4960ad1b7578c16a616e",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac45475f2134fcca6e6a6455c27aa83",
            "value": " 500k/500k [00:00&lt;00:00, 30.6MB/s]"
          }
        },
        "73f409df692c44e2884196d8067067e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c52b52b2d9744c1f990c756c486aae73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "539653d0fc714982b22d29e1b711ff81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cebac32c040a44008e29c83f6baca16f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "053fb6ab8e3841abbcfaa70303449527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b169dec2097b4960ad1b7578c16a616e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac45475f2134fcca6e6a6455c27aa83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9011770f8d741ecbc2cfa54349d33c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18de817313834c87a1ae662b3b23d2f7",
              "IPY_MODEL_c9675e14bbdc4112a8f13568a43b71fc",
              "IPY_MODEL_7d01b671527c490aa149b982f5fafefa"
            ],
            "layout": "IPY_MODEL_0c6514f0c9944068a214982cb051438a"
          }
        },
        "18de817313834c87a1ae662b3b23d2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae794a04f0c14b969e94fadf7f717d76",
            "placeholder": "​",
            "style": "IPY_MODEL_8bc4173fd8f44431ac40790ed627df5b",
            "value": "tokenizer.json: 100%"
          }
        },
        "c9675e14bbdc4112a8f13568a43b71fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42cb7e18bd7044a3a05cd866deeb42d3",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3f302f66fb349d5adebe110d54cba80",
            "value": 1842767
          }
        },
        "7d01b671527c490aa149b982f5fafefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dde47747db94502b4d0f24ebcd48790",
            "placeholder": "​",
            "style": "IPY_MODEL_7ceaa16c81d64ccca55492d979e5c506",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 7.02MB/s]"
          }
        },
        "0c6514f0c9944068a214982cb051438a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae794a04f0c14b969e94fadf7f717d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc4173fd8f44431ac40790ed627df5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42cb7e18bd7044a3a05cd866deeb42d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f302f66fb349d5adebe110d54cba80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dde47747db94502b4d0f24ebcd48790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ceaa16c81d64ccca55492d979e5c506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac9d01d1c2c246bb884dc58c7c172a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c72ec540f6e472ea5883f56f22c38c0",
              "IPY_MODEL_04d91a1433cd43b9856f346f34d4c8e1",
              "IPY_MODEL_84489bb79ceb434e82249c5fb519209d"
            ],
            "layout": "IPY_MODEL_0a9c2e0034af487099657c37a58ebc93"
          }
        },
        "5c72ec540f6e472ea5883f56f22c38c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39a1537271544a2aa13ae2d08269ecd0",
            "placeholder": "​",
            "style": "IPY_MODEL_7bdb89d2b1564c62b786acaab8b530a6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "04d91a1433cd43b9856f346f34d4c8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d21d18790bff452589336d29e28d0d7e",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f82bed047034a5382de937b694ea5e6",
            "value": 414
          }
        },
        "84489bb79ceb434e82249c5fb519209d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a99d3707a36477e946a3acbd2ce4bba",
            "placeholder": "​",
            "style": "IPY_MODEL_0a786e5d745540fc856e2753be11ed4b",
            "value": " 414/414 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "0a9c2e0034af487099657c37a58ebc93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a1537271544a2aa13ae2d08269ecd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bdb89d2b1564c62b786acaab8b530a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d21d18790bff452589336d29e28d0d7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f82bed047034a5382de937b694ea5e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a99d3707a36477e946a3acbd2ce4bba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a786e5d745540fc856e2753be11ed4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "660a430b570943fea33c49c64b787f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a2855aea5004a8d83d27f3141996e69",
              "IPY_MODEL_900f479d347c4a548c424957eec0a570",
              "IPY_MODEL_6fefcd1997294b51a698796c862563e0"
            ],
            "layout": "IPY_MODEL_dbd8303a68a44f30a2caa4d9b1edd85b"
          }
        },
        "1a2855aea5004a8d83d27f3141996e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e5a55c556741d0b414351dd69539bd",
            "placeholder": "​",
            "style": "IPY_MODEL_5b0be9e08d4e4114ad327512e02c21b2",
            "value": "modules.json: 100%"
          }
        },
        "900f479d347c4a548c424957eec0a570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3825c68edaf45748fe5c219d06b510a",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08c16ecc0ccb40989553a026aeaa83c0",
            "value": 349
          }
        },
        "6fefcd1997294b51a698796c862563e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_088d3f465a014be6b2e5fba053cf8251",
            "placeholder": "​",
            "style": "IPY_MODEL_567c39ae2edb423fa9fe65710d025b70",
            "value": " 349/349 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "dbd8303a68a44f30a2caa4d9b1edd85b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e5a55c556741d0b414351dd69539bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b0be9e08d4e4114ad327512e02c21b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3825c68edaf45748fe5c219d06b510a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c16ecc0ccb40989553a026aeaa83c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "088d3f465a014be6b2e5fba053cf8251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567c39ae2edb423fa9fe65710d025b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ae25547c0ad4f168ea9c4328ee30b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a3529bffb534abcaa6513a6465f8630",
              "IPY_MODEL_92560faf9f4742499cc9f888ecbe0a0b",
              "IPY_MODEL_94eb8d49696b49ccbf917c67b9116e36"
            ],
            "layout": "IPY_MODEL_1a10eb44a5744618a22fc0b0e3eb875c"
          }
        },
        "5a3529bffb534abcaa6513a6465f8630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0cb631bb6d14e50a28162daf8e9f097",
            "placeholder": "​",
            "style": "IPY_MODEL_2d2d75f1c0a7402ab60e7547e84f7140",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "92560faf9f4742499cc9f888ecbe0a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de3b6b82bae40b1b35348e415d2652b",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f461197184a242378cac80d9bb0a13ca",
            "value": 116
          }
        },
        "94eb8d49696b49ccbf917c67b9116e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c158b0ea8044d298880543ba8c91ac1",
            "placeholder": "​",
            "style": "IPY_MODEL_857566c52dd14bf09288933f3796802e",
            "value": " 116/116 [00:00&lt;00:00, 8.04kB/s]"
          }
        },
        "1a10eb44a5744618a22fc0b0e3eb875c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0cb631bb6d14e50a28162daf8e9f097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2d75f1c0a7402ab60e7547e84f7140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8de3b6b82bae40b1b35348e415d2652b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f461197184a242378cac80d9bb0a13ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c158b0ea8044d298880543ba8c91ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "857566c52dd14bf09288933f3796802e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0058df8af6e04a99a4c515e861cdd840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf3f2e7406664f99aaf4fb07b894cb55",
              "IPY_MODEL_e04d3e2c405b4fa8ae31e7a584c8dc85",
              "IPY_MODEL_f6f4e0430c554df4b6d2b69ef8f539ff"
            ],
            "layout": "IPY_MODEL_1f34cdcc18c1455baa2a7ccda2b0b1de"
          }
        },
        "cf3f2e7406664f99aaf4fb07b894cb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aef89f5053e448c7883bde176f0326c0",
            "placeholder": "​",
            "style": "IPY_MODEL_24c64127d3c44545b04c65b0b26bedd1",
            "value": "README.md: 100%"
          }
        },
        "e04d3e2c405b4fa8ae31e7a584c8dc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cce74ca94ab485d984eae8def8f6feb",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_975a6a1d3617480a9db4fe468f42d337",
            "value": 10621
          }
        },
        "f6f4e0430c554df4b6d2b69ef8f539ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77651858867541888a9f3b9e89dda820",
            "placeholder": "​",
            "style": "IPY_MODEL_6e682385575640379a502225120bb2b5",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 679kB/s]"
          }
        },
        "1f34cdcc18c1455baa2a7ccda2b0b1de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef89f5053e448c7883bde176f0326c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24c64127d3c44545b04c65b0b26bedd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cce74ca94ab485d984eae8def8f6feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "975a6a1d3617480a9db4fe468f42d337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77651858867541888a9f3b9e89dda820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e682385575640379a502225120bb2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0ab1a4d686c45f29cb42a0305335564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dae1ac367f824b7b802bbb33dfc58f80",
              "IPY_MODEL_7c1b86b554f64d858662903201c73fcd",
              "IPY_MODEL_d9786aad6a2c4efea5a2359efa49a31d"
            ],
            "layout": "IPY_MODEL_0e3ff65d74d24827bc8f252327765ece"
          }
        },
        "dae1ac367f824b7b802bbb33dfc58f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b67345449c1d47569793ed412bd76695",
            "placeholder": "​",
            "style": "IPY_MODEL_0581db2aabb4449aaa978d20763ae1fb",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "7c1b86b554f64d858662903201c73fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5226df417164e98a319262e6c7bf9c3",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43aefacf9dec400fb2bd239989239cc7",
            "value": 53
          }
        },
        "d9786aad6a2c4efea5a2359efa49a31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad013d907844779927317db7d4b4f9e",
            "placeholder": "​",
            "style": "IPY_MODEL_e5a23cc0dc254ffeb9ae117bf9f5102c",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.19kB/s]"
          }
        },
        "0e3ff65d74d24827bc8f252327765ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67345449c1d47569793ed412bd76695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0581db2aabb4449aaa978d20763ae1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5226df417164e98a319262e6c7bf9c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43aefacf9dec400fb2bd239989239cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ad013d907844779927317db7d4b4f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a23cc0dc254ffeb9ae117bf9f5102c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64b720cd90cd4320868a79bafa5eb9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a8d8eeda36a4e2ca561981d6b343697",
              "IPY_MODEL_22a92851d818474ab870cf67d11cb22c",
              "IPY_MODEL_6714d59d686d4914a42926abcba63f24"
            ],
            "layout": "IPY_MODEL_19098490e90946538e88ff37574092ec"
          }
        },
        "1a8d8eeda36a4e2ca561981d6b343697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef007d2e3614491bb1be8c48bd5c71cc",
            "placeholder": "​",
            "style": "IPY_MODEL_82da42c27611403d99864e9bab91dec8",
            "value": "config.json: 100%"
          }
        },
        "22a92851d818474ab870cf67d11cb22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d3a25c49b7e4aff92ddee21ac88f73b",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b19907cd45d4d56beb7bd7c7d1ca8b0",
            "value": 571
          }
        },
        "6714d59d686d4914a42926abcba63f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1573b90a6934bcc97cd704bab512334",
            "placeholder": "​",
            "style": "IPY_MODEL_9765c4638d044d27b3bf413a0aaa201b",
            "value": " 571/571 [00:00&lt;00:00, 24.3kB/s]"
          }
        },
        "19098490e90946538e88ff37574092ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef007d2e3614491bb1be8c48bd5c71cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82da42c27611403d99864e9bab91dec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d3a25c49b7e4aff92ddee21ac88f73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b19907cd45d4d56beb7bd7c7d1ca8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1573b90a6934bcc97cd704bab512334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9765c4638d044d27b3bf413a0aaa201b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d85880f3bf343e2a4e4a7a3ed19ca80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ba598730578459390390d5b30ac96a6",
              "IPY_MODEL_7b19566be7594dd087f6b860c46907aa",
              "IPY_MODEL_9c49270cfdf847c685ab37a230636903"
            ],
            "layout": "IPY_MODEL_74606bf5bc844e6b94f7f84d1f42b039"
          }
        },
        "7ba598730578459390390d5b30ac96a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31f249ed50d546b6bea739720a976371",
            "placeholder": "​",
            "style": "IPY_MODEL_69f4fe206d744323bc7fd25ff6105c39",
            "value": "model.safetensors: 100%"
          }
        },
        "7b19566be7594dd087f6b860c46907aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_110ff227953a4ff88e885839e7f97cb0",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff0595a3699746c6a0445abc112fa733",
            "value": 437971872
          }
        },
        "9c49270cfdf847c685ab37a230636903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94bed7f33b7a455aa6fc84b26829a341",
            "placeholder": "​",
            "style": "IPY_MODEL_8b48f8bc09a54ecbacb8c3031926b63d",
            "value": " 438M/438M [00:01&lt;00:00, 248MB/s]"
          }
        },
        "74606bf5bc844e6b94f7f84d1f42b039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f249ed50d546b6bea739720a976371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f4fe206d744323bc7fd25ff6105c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "110ff227953a4ff88e885839e7f97cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0595a3699746c6a0445abc112fa733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94bed7f33b7a455aa6fc84b26829a341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b48f8bc09a54ecbacb8c3031926b63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59d7ae8a67cc41329308a3cbf7f5b739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19c22b17485f4058abd4a4cd532de5b2",
              "IPY_MODEL_9a5d5561b7b6478a813da55cfd6c8570",
              "IPY_MODEL_1a7fb1ec7c85490f88a0fb5ebcecdc29"
            ],
            "layout": "IPY_MODEL_e21362aa9b0443be81ae406079f1797f"
          }
        },
        "19c22b17485f4058abd4a4cd532de5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4170db6cdf4160843a7693d0fec4a6",
            "placeholder": "​",
            "style": "IPY_MODEL_334309978afb4ca3b61bad493d4401a6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9a5d5561b7b6478a813da55cfd6c8570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37b1def29f6c42f99867b3f5510ef278",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee865b74415d4de5890a154fade0a2ec",
            "value": 363
          }
        },
        "1a7fb1ec7c85490f88a0fb5ebcecdc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23084bb3f345411a9c1e416cb875bc49",
            "placeholder": "​",
            "style": "IPY_MODEL_5642c46b500d4694a1187bf4d0ba53a8",
            "value": " 363/363 [00:00&lt;00:00, 23.9kB/s]"
          }
        },
        "e21362aa9b0443be81ae406079f1797f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b4170db6cdf4160843a7693d0fec4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "334309978afb4ca3b61bad493d4401a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37b1def29f6c42f99867b3f5510ef278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee865b74415d4de5890a154fade0a2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23084bb3f345411a9c1e416cb875bc49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5642c46b500d4694a1187bf4d0ba53a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "700cbf3774404a35a6f051787b886f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50e93e5d27094adfa755566be9013349",
              "IPY_MODEL_0ac982a2c41342acb60708b6b7db8e44",
              "IPY_MODEL_6229d96ac9e84c969b20427e804e0854"
            ],
            "layout": "IPY_MODEL_c79290b97be04ff3a4d611de3809026e"
          }
        },
        "50e93e5d27094adfa755566be9013349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427edc9628224d0398effe145b67cc90",
            "placeholder": "​",
            "style": "IPY_MODEL_d50483c1ac4844618c2e61d385f17fcd",
            "value": "vocab.txt: 100%"
          }
        },
        "0ac982a2c41342acb60708b6b7db8e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a103e5d1946d4b16be574d7ec1ded456",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6244ead88f04f0baa5f8beda7382a0a",
            "value": 231536
          }
        },
        "6229d96ac9e84c969b20427e804e0854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e1dd139cee44ab49db527b204abe50e",
            "placeholder": "​",
            "style": "IPY_MODEL_b092327659e740d7a72485c3e1ac19ba",
            "value": " 232k/232k [00:00&lt;00:00, 3.75MB/s]"
          }
        },
        "c79290b97be04ff3a4d611de3809026e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427edc9628224d0398effe145b67cc90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50483c1ac4844618c2e61d385f17fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a103e5d1946d4b16be574d7ec1ded456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6244ead88f04f0baa5f8beda7382a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e1dd139cee44ab49db527b204abe50e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b092327659e740d7a72485c3e1ac19ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c5d5d23c15d4198a064d690336e9160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07661b4c79794fafb8994bacc0f74746",
              "IPY_MODEL_7759827cd7d34ae4b115014ef8d3b715",
              "IPY_MODEL_9c9f2a95f38f4e33b8429917ccd5af8d"
            ],
            "layout": "IPY_MODEL_75d3f95468424924a8a2e5f00f9fd809"
          }
        },
        "07661b4c79794fafb8994bacc0f74746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bdab3a6c83341ab9f83deb24c21c52b",
            "placeholder": "​",
            "style": "IPY_MODEL_52a0bddea5014317945566d3fb102fa0",
            "value": "tokenizer.json: 100%"
          }
        },
        "7759827cd7d34ae4b115014ef8d3b715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91f48715f4fd45cfa89786ebebdd6a45",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cf0b778b1224ad2b6fa0b18966506a5",
            "value": 466021
          }
        },
        "9c9f2a95f38f4e33b8429917ccd5af8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc1a469e40fc494db65d6f85a01b8439",
            "placeholder": "​",
            "style": "IPY_MODEL_00a3edeb1f82474eab845cadda14e6eb",
            "value": " 466k/466k [00:00&lt;00:00, 6.95MB/s]"
          }
        },
        "75d3f95468424924a8a2e5f00f9fd809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdab3a6c83341ab9f83deb24c21c52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a0bddea5014317945566d3fb102fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91f48715f4fd45cfa89786ebebdd6a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf0b778b1224ad2b6fa0b18966506a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc1a469e40fc494db65d6f85a01b8439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00a3edeb1f82474eab845cadda14e6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b14563674e046cc92cbe32a6c26e073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_398a7903e32e46fd879e49dba0602638",
              "IPY_MODEL_48c737d0b6d6416b90436d5fc711a12c",
              "IPY_MODEL_37cca22f018d441e9d51ffb42e80eb4d"
            ],
            "layout": "IPY_MODEL_02db7dfda8404d2eb4a7e3a761f33a6a"
          }
        },
        "398a7903e32e46fd879e49dba0602638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b451941d17934dffa39478a95ac35877",
            "placeholder": "​",
            "style": "IPY_MODEL_efea7d0297ae4a1fad457a68798d16a6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "48c737d0b6d6416b90436d5fc711a12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3e205726c34f19be623259cf6696b1",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b2ca0c463a740949c050e940884dad4",
            "value": 239
          }
        },
        "37cca22f018d441e9d51ffb42e80eb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa3eb6fdc9f46f7aa1fecfdb359c136",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc920c630574a3eb3569cbb447594d0",
            "value": " 239/239 [00:00&lt;00:00, 19.8kB/s]"
          }
        },
        "02db7dfda8404d2eb4a7e3a761f33a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b451941d17934dffa39478a95ac35877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efea7d0297ae4a1fad457a68798d16a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c3e205726c34f19be623259cf6696b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2ca0c463a740949c050e940884dad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fa3eb6fdc9f46f7aa1fecfdb359c136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc920c630574a3eb3569cbb447594d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c80f1d3985241d9bcdaad0c547446db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e94b90d5d09040f290d8df3c3a590033",
              "IPY_MODEL_8822b38ab43142c1b6ccf51f99473d95",
              "IPY_MODEL_661fca0d34374a96a4e625a177edc15f"
            ],
            "layout": "IPY_MODEL_a5a48eb63dbb49d59965f0cf82e091a7"
          }
        },
        "e94b90d5d09040f290d8df3c3a590033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4c150ed15546f6b650745e841d57a2",
            "placeholder": "​",
            "style": "IPY_MODEL_77a93f0ebdd14e3db2d9561e8c5fad51",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "8822b38ab43142c1b6ccf51f99473d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_623ddc42e76f46fe9df818517dc1fae5",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac7c6c90a5fd44c2ba466da3be0bedbf",
            "value": 190
          }
        },
        "661fca0d34374a96a4e625a177edc15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80802eb6aa384d93add2ded4147debcd",
            "placeholder": "​",
            "style": "IPY_MODEL_fd662d4aca3d460c97fc2c9cac97dc91",
            "value": " 190/190 [00:00&lt;00:00, 10.5kB/s]"
          }
        },
        "a5a48eb63dbb49d59965f0cf82e091a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e4c150ed15546f6b650745e841d57a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a93f0ebdd14e3db2d9561e8c5fad51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "623ddc42e76f46fe9df818517dc1fae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac7c6c90a5fd44c2ba466da3be0bedbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80802eb6aa384d93add2ded4147debcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd662d4aca3d460c97fc2c9cac97dc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "D_enpOdzpuOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a8965d-9340-4e40-976f-7ee58d992d98"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/295.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/295.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-m4IwNArwH9",
        "outputId": "6b2c75c9-7c91-4972-b536-483f580919a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Embedding\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E0Vni-br_uu",
        "outputId": "cdbb9930-eae6-4a66-d1fa-e6fcddaed34a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMrV7K16sSu6",
        "outputId": "f426d74a-a269-4c09-aba7-f7b09ba66b9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.10.59-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama_index)\n",
            "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core==0.10.59 (from llama_index)\n",
            "  Downloading llama_index_core-0.10.59-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama_index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama_index)\n",
            "  Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl.metadata (610 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama_index)\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama_index)\n",
            "  Downloading llama_index_readers_file-0.1.32-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama_index) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core==0.10.59->llama_index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.59->llama_index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.59->llama_index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core==0.10.59->llama_index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (1.26.4)\n",
            "Collecting openai>=1.1.0 (from llama-index-core==0.10.59->llama_index)\n",
            "  Downloading openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (8.5.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.59->llama_index)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.59->llama_index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.59->llama_index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama_index)\n",
            "  Downloading llama_cloud-0.0.11-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.3.1)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama_index)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama_index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama_index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama_index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama_index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama_index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama_index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama_index) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.59->llama_index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.59->llama_index) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.59->llama_index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.59->llama_index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.59->llama_index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.59->llama_index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama_index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama_index) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.59->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.59->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama_index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.59->llama_index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.59->llama_index)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.59->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.59->llama_index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.59->llama_index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.59->llama_index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.59->llama_index) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama_index) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.59->llama_index) (1.16.0)\n",
            "Downloading llama_index-0.10.59-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_core-0.10.59-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.1.27-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.1.32-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading llama_cloud-0.0.11-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Downloading openai-1.38.0-py3-none-any.whl (335 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.9/335.9 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: striprtf, dirtyjson, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-cloud, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-cloud-0.0.11 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.59 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.27 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.32 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 llama_index-0.10.59 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.38.0 striprtf-0.0.26 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqxkITa1t0ry",
        "outputId": "58dbb401-eb0b-4770-dc37-61c1302163fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-huggingface\n",
            "  Downloading llama_index_llms_huggingface-0.2.5-py3-none-any.whl.metadata (841 bytes)\n",
            "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.23.5)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.57 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.10.59)\n",
            "Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n",
            "  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.0.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.38.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (9.4.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.16.0)\n",
            "Requirement already satisfied: pydantic<3,>2 in /usr/local/lib/python3.10/dist-packages (from text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.8.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.19.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.32.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (3.21.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-huggingface) (1.16.0)\n",
            "Downloading llama_index_llms_huggingface-0.2.5-py3-none-any.whl (11 kB)\n",
            "Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: text-generation, llama-index-llms-huggingface\n",
            "Successfully installed llama-index-llms-huggingface-0.2.5 text-generation-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFouifT0sfsD",
        "outputId": "cc9846e0-7406-4323-8b1e-c3f1b3730490"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gicnA91JtLH9",
        "outputId": "3968469f-26c9-4e07-960c-20a5f6eb5d7c",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id_='48ff95fc-3123-40ef-aac7-4d58c66e03a8', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 1: Motivation and Basic Biological\\nBackground of Neurons\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5060183c-eb5a-49c2-beb0-4d4f57c008aa', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives\\nTo briefly recall the role of ML/AI in Neuroscience and vice\\nversa.\\nTo present the biological background of neurons necessary to\\nunderstand the anatomy of neurons and mechanisms behind\\nthe generation and propagation of an action potential (spike).\\nREMARK: We do not intend to provide an all-inclusive introduction\\nto the intricate subject of neurobiology. Instead, we opt to present a\\nbasic and highly selective overview of the biological background of\\nneurons, emphasizing only aspects crucial for comprehending the\\ntheoretical work that will be expounded in this course. For an\\nin-depth discussion of neurobiology, please refer to the existing\\nliterature, e.g., Luo, Liqun. Principles of neurobiology . Garland\\nScience, 2015.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='60ecd776-e842-4d94-a6e2-2338adca42f5', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1 Introduction and Motivation\\nWhat is Intelligence? Could it be (in a nutshell) the ability to perceive\\nand adapt to the environment and take actions that maximize success?\\nHow does it work? One way to understand it is to (try) replicate Human\\nCognition, including reasoning, problem-solving, abstract thinking,\\nlearning from experience, understanding natural language, creativity,\\nmemory, perceiving the environment, adaptability, and control of objects.\\nCognitive Science exists at the intersection of computational neuroscience\\nand machine learning (ML), encompassing both biological intelligence\\n(BI) and artificial intelligence (AI).\\nSchematic diagram of biological and artificial computing systems. a) The human brain. b) The biological neural\\nnetwork. c) A biological synapse. d) A biological neuron. e) An AI chip. f) Spiking neural networks. g) An artificial\\nspiking neuron..\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2fe0390e-f58d-47c9-95ff-863a6f997ea1', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1 Introduction and Motivation\\nNeuroscience offers two benefits to ML and AI.\\nIt is a rich source of inspiration for developing a better\\nunderstanding of novel ML algorithms, regardless of the\\nmathematical methods that have conventionally dominated AI\\nand ML, such as artificial neural networks and deep learning.\\nNeuroscience can validate AI techniques, with a neuron-based\\nimplementation being strong evidence for its integration into a\\ncomprehensive artificial intelligence system.\\nhttps://cnai.kaist.ac.kr/\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a114168f-04ad-48cf-ac9c-3811415b59aa', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1 Introduction and Motivation\\nOn the other hand, ML and AI could retroactively benefit neuroscience.\\nML algorithms are enhancing neuroscience research by improving the\\nanalysis of neurophysiological datasets, e.g., Electroencephalography\\n(EEG), forecasting epileptic seizures, etc\\nDOI: 10.15496/publikation-37739\\nThus, understanding the fundamental biology and mathematical modeling\\n— chiefly using dynamical system theory — of biological neural networks\\nand their influence on information processing efficiency is crucial for\\ndeveloping and optimizing neuroscience-inspired ML algorithms.\\nThis is the strategy in the course.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='098b1d0e-e3e7-4c29-a112-31eda73c46c0', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1 Elements of neuronal systems\\nSunny/Stone via Getty Images\\nBiologydictionary.net Editors. “Organ” Biologydictionary.net. 2014\\nhttps://en.wikipedia.org/wiki/Caenorhabditis_elegans.\\nAn adult human brain made up of about 86 billion neurons\\n100 trillion (1014) synapses ( ≃850000 km of wiring)\\nC. elegans has exactly 302 neurons and only 9000 synapses\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='08816d2c-6a68-4434-8759-c46b02276960', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1.1 Structure of a biological neuron and action potential\\nhttps://en.wikipedia.org/wiki/Membrane_potential.\\nTime evolution of membrane potential during the emission of an action potential\\nhttps://en.wikipedia.org/wiki/Membrane_potential.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4f763afd-8566-4706-84c7-edc0e1dcb0d6', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1.1 Structure of a biological neuron and action potential\\nhttps://en.wikipedia.org/wiki/Membrane_potential.\\nTime evolution of membrane potential during the emission of an action potential\\nhttps://en.wikipedia.org/wiki/Membrane_potential. Marius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='614d96f1-566a-43ee-81bb-670bcabb471b', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1.2 Information Processing in Neurons and Synapses\\nThe Economist.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='576a1513-0fab-4ef1-a47f-b6f2ae5daf87', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1.3 Types of Synapses\\nA. E. Pereda, Nat. Rev. Neurosci. 2014, 15, 250..\\na) Chemical synapses are by far the most prevalent and are the main player involved in excitatory synapses.\\nThe transfer of neurotransmitters from a presynaptic axon to a postsynaptic dendrite. Unlike an electrical\\nsynapse, chemical synapses are separated by a space called the synaptic cleft, typically measured between\\n15 and 25 nm. In the figure, the arrival of action potential results in the activation of voltage-gated Ca+\\nchannels, promoting the probabilistic release of neurotransmitters by exocytosis from presynaptic\\nmembrane. The ionotropic and metabotropic receptors on the postsynaptic membrane can detect and\\ntranslate the information carried by neurotransmitters into different postsynaptic behaviors, varying from\\nchanges in membrane potential to gene expression.\\nb) Electrical synapses allow direct, virtually instantaneous, and passive flow of electric current through\\nspecial intercellular connections called gap junctions. Electrical transmission is conducted by gap junctions\\n(some clusters of intercellular channels) between two adjacent cells. The transmission is bidirectional: when\\nan action potential is transmitted from pre-synapse to postsynapse, the postsynaptic resting potential\\npropagates concurrently to the pre-synapse.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a5cde77c-d92b-478b-b5c0-eb275ba5a03e', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1.3 Types of synapses and their main modalities of\\nsynaptic transmissions.\\nc) Mixed synapse. Chemical and electrical transmission coexist\\nat mixed synapses. Chemical synapses (such as\\nglutamate-based) influence the connective strength of\\nelectrical synapses by activating the NMDA receptors and\\nCaMKII.\\nAn excitatory synapse is a synapse in which an action\\npotential in a presynaptic neuron increases the probability of\\nan action potential occurring in a postsynaptic neuron.\\nAn inhibitory synapse is a synapse in which an action\\npotential in a presynaptic neuron decreases the probability of\\nan action potential occurring in a postsynaptic neuron.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='52e22e07-3536-4314-9803-b85c19ad3909', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s1.pdf', 'file_path': '/content/data/Lecture_s1.pdf', 'file_type': 'application/pdf', 'file_size': 2924841, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1.4 Types of neurons\\n.\\nSensory neurons detect stimuli in the external environment. They are activated by sensory input such as\\nlight, sound, heat, or pressure and carry information from the sense organs (like the eyes and ears) to the\\nbrain. E.g., a pain signal will be sent to the brain if a bee stings you.\\nInterneurons connect other nerve cells and help to relay messages between the brain and the rest of the\\nbody. They allow impulses to pass from the sensory neurons to the brain, and from the brain to the motor\\nneurons.\\nMotor neurons carry impulses from the brain to the muscles and control all of our voluntary movements.\\nThis allows us to react to stimuli in our environment. For example, if a bee stings you, the motor neurons\\nwill transmit messages from the brain to the muscles of your arm and cause you to swat at the insect.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d163310f-2710-4083-b922-909f2a34ee0c', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 10: Slow-fast analysis, singular Hopf bifurcation,\\nphase plane analysis, and excitability in a slow-fast neuron\\nmodel\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='116c8167-c1c6-4c5d-b12c-a78f7864c449', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives\\n1Using multiple timescales (slow-fast) analysis to understand\\nthe excitability\\n2Understand and calculate the singular Hopf bifurcation\\n3Use phase plane analysis to understand excitability and\\noscillatory regimes of neurons\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0fc1dbb7-2f08-4c88-ba6f-9acebaefab05', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast and phase plane analyses of a neuron model\\nConsider the general equation of the FitzHugh-Nagumo\\n(FHN) neuron model given two coupled ODEs on either the\\nslow timescale τor the fast timescale t\\n{\\nεdxτ\\ndτ=F(xτ,yτ),\\ndyτ\\ndτ=G(xτ,yτ),(1)\\n{dxt\\ndt=F(xt,yt),\\ndyt\\ndt=εG(xt,yt),(2)\\nwhere the functions FandGare two polynomials of the form:\\n{\\nF(x,y) =−ax+ (a+1)x2+ex3+fy+I\\nG(x,y) = d+bx−cy,(3)\\nand 0<ε:=τ\\nt≪1 is the timescale separation parameter\\n(called in slow-fast analysis the the singular parameter)\\nbetween the fast voltage variable x∈Rand the slow recovery\\nvariable y∈Rthat restores the resting state of the neuron.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5ca19804-a8db-470b-bf60-e45d2bb4159b', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast and phase plane analyses of a neuron model\\nWe note that Eq. (2) preserves the sense of the dynamics of\\ntrajectories of Eq. (1). The only difference is the speed of the\\ntrajectories in phase space.\\nWe also note that in the literature, there are three different\\nversions of the FHN neuron model depending on the values of\\nthe parameters a,b,c,d,eandf.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='70a707a6-e36d-42c9-b1bd-2d724ee2af4d', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast and phase plane analyses of a neuron model\\n1The simplest version is obtained with a=−1,b=1,c=0,\\ne=−1/3,f=−1\\n{\\ndx = ( xt−x3\\nt/3−y+I)dt,\\ndyt=ε(xt+d)dt,(4)\\n2The second version is obtained with a=−1,b=1,c=0,\\ne=−1/3,f=−1\\n{\\ndxt= ( xt−x3\\nt/3−yt+I)dt,\\ndyt=ε(xt+d−cyt)dt,(5)\\n3The third version is obtained with d=0,e=−1,f=−1\\n{\\ndxt= [xt(a−xt)(xt−1)−yt+I]dt,\\ndyt=ε(bxt−cyt)dt,(6)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='13e04bb4-4238-4b2b-8428-79db747720d1', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast and phase plane analyses of a neuron model\\nFor this lecture, we shall use the third version because it\\nallows for richer dynamical behaviors than the two others.\\nExercise 3A\\n1Use the definition of the singular parameter (i.e.,\\n0<ε:=τ\\nt≪1 ) to show how we can convert Eq.(6) from its\\nfast timescale to it corresponding slow timescale version (i.e.,\\nwhere the variable are now xτ,yτ, and the time is τ).\\n2By settingε→0 (also known as taking the singular limit)\\nreduce Eq.(6) into a 1-dimensional ODE governing the\\nevolution of the fast variable xon the slow timescale τ.\\nLet us start by giving some important general definitions:\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6d2c125d-62a8-473d-9178-2a8b5ee0587f', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='61e3955a-5161-4f49-a144-6d0f1ea6bc8f', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c48f69d0-9c38-4896-bd5b-1f519388c303', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8027522e-7fc9-4f5d-a26c-391829aad70e', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8df12a25-3ef0-4246-9a01-5df388645cad', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8c192a25-b289-46e5-b6ec-825b3741f5ce', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b1be46fb-381b-4f73-a152-e0cbd0e7caf0', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d81e8e0e-d677-455b-ad06-c71bfe6fbc2a', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9cde9610-0920-4da9-b2cb-664dd706fe59', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e5070b99-31e6-4a51-a3e3-cca880c6d56d', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='General slow-fast dynamical system: singular limits\\nDefinition\\n{\\ndvt=f(vt,wt)dt\\ndwt=εg(vt,wt)dtεt=τ←−→{\\nεdvτ=f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\n↓ε=0 ↓ε=0{\\ndvt=f(vt,wt)dt\\ndwt=0↮{\\n0 =f(vτ,wτ)dτ\\ndwτ=g(vτ,wτ)dτ\\nLayer problem Reduced problem\\nM0:={f=0}=critical manifold =fixed points of layer problem.\\nM0:={f=0}=is the phase space of the reduced problem.\\nvslaved to wthrough constraint f=0.\\nwacts as a parameter in the layer problem.\\nM0is normally hyperbolic if the scalar (dvf)(p)̸=0,∀p∈M 0.\\nM0is attracting if (dvf)(p)<0, repelling if (dvf)(p)>0.\\nM0is of saddle-type if ... ≤re(λjk)<0<re(λjk+1)≤...\\na fold point ssatisfies (dvf)(s) =0,M0looses hyperbolicity at s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a621f029-c535-4086-93b9-ac50e4eec44b', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s10.pdf', 'file_path': '/content/data/Lecture_s10.pdf', 'file_type': 'application/pdf', 'file_size': 186474, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast and phase plane analyses of a neuron model\\nNow we consider the FHN model given by Eq.(6), where for\\nsimplicity, we assume that there is no input current, i.e., I=0:\\n{\\nεdxτ\\ndτ=F(xτ,yτ) =xτ(a−xτ)(1−xτ)−yτ,\\ndyτ\\ndτ=G(xτ,yτ,c) =bxτ−cyτ,(7)\\n{dxt\\ndt=F(xt,yt) =xt(a−xt)(1−xt)−yt,\\ndyt\\ndt=εG(xt,yt) =ε(bxt−cyt),(8)\\nwhere b>0 and c>0 is a co-dimension one Hopf\\nbifurcation, 0 <a<1, and 0<ε:=τ\\nt≪1.\\nWe shall focus on the slow-fast analysis of Eqs.(7) and (8),\\nwhich allows us to analytically and geometrically understand\\nthe mechanism behind the dynamical behaviors of the FHN\\nneuron model during excitability and spiking.\\nThe first major idea to analyze Eqs.(7) and (8) is to take the\\nsingular limit (i.e., ε→0)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7c05d465-5d40-4715-a2c4-7cd3e7e15953', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 11: Slow-fast analysis, singular Hopf bifurcation,\\nphase plane analysis, and excitability in a slow-fast neuron\\nmodel (Continuation of Lecture 10)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='59819f88-9d8e-4bd2-a22e-e2ea6aec26a3', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nNow we consider the FHN model given by:\\n{\\nεdxτ\\ndτ=F(xτ,yτ) =xτ(a−xτ)(1−xτ)−yτ,\\ndyτ\\ndτ=G(xτ,yτ,c) =bxτ−cyτ,(1)\\nor\\n{dxt\\ndt=F(xt,yt) =xt(a−xt)(1−xt)−yt,\\ndyt\\ndt=εG(xt,yt) =ε(bxt−cyt),(2)\\nwhereb>0 andc>0 is a co-dimension one Hopf\\nbifurcation, 0 <a<1, and 0<ε:=τ\\nt≪1.\\nWe shall focus on the slow-fast analysis of Eqs.(1) and (2),\\nwhich allows us to analytically and geometrically understand\\nthe mechanism behind the dynamical behaviors of the FHN\\nneuron model during excitability and spiking.\\nFor the slow-fast analysis of Eqs. (1) and (2), we take the\\nsingular limit ε=0.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='27be5bb4-ef11-47c5-9cb5-94f6226e51fe', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nThe singular limit in Eq.(2) yields:\\n{dx\\ndt=x(a−x)(1−x)−y,\\ndy\\ndt=0,(3)\\nEq.(3) is called the fast subsystem of the FHN model, and it\\nis an ODE parametrized by y(which is now a constant). The\\nflow of the fast subsystem is called the fast flow.\\nThe singular limit in Eq.(1) yields:\\n{0 =x(a−x)(1−x)−y,\\ndy\\ndτ=bx−cy,(4)\\nEq.(4) is a differential-algebraic equation called the slow\\nsubsystem of the FHN model, and the flow of the slow\\nsubsystem is called the slow flow.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d0d7e693-b852-4ab8-802b-bbb6c03dbb4f', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nThe algebraic constraint of Eq.(4) defines the critical manifold\\nM0of the FHN neuron (which is exactly the x-nullcline).\\nM0:={(x,y)∈R2|F(x,y) =x(x−a)(1−x)−y=0}(5)\\nNote that points on M0are fixed points of the fast subsystem\\nin Eq.(3).\\nThe FHN neuron model is normally hyperbolic (i.e., ∂xF̸=0)\\naway from the local maximum and a minimum of the critical\\nmanifoldM0. At the special points defined by\\n(xs,ys) :={(x,y)∈R2|∂xF=dy\\ndx=−3x2+2(a+1)x−a=0}\\n(6)\\nM0looses normal hyperbolicity (since ∂xF=0) at its fold\\npoints (xs,ys), also known as singular points.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8bef44d5-529b-4fcb-9d93-1cd5c114033b', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nNote: In general, the solution to an ordinary differential\\nequation (ODE) may or may not be unique at a particular\\npoint. Whether or not a solution is unique depends on the\\nproperties of the ODE and the conditions imposed on the\\nproblem. The existence and uniqueness theorem for ODEs\\nstates that a first-order ODE will have a unique solution that\\nsatisfies specific initial or boundary conditions under certain\\nconditions. This theorem guarantees the uniqueness of the\\nsolution in a certain interval or domain. However, it’s\\nimportant to note that the solution might not be unique in\\nsome cases. Non-uniqueness can occur when the ODE is\\nsingular or ill-posed, meaning that it lacks sufficient conditions\\nto guarantee the existence of a unique solution.\\nAt the fold point (xs,ys), the existence and uniqueness\\ntheorem of first-order ODEs does not hold, and the solutions\\n(trajectories) of the slow subsystem in Eq.(4) are forced to\\nleaveM0precisely at the singular points (xs,ys).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='fa8e72e8-1ffe-4aa6-8f47-b8727ddf00c7', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nNote: In general, the solution to an ordinary differential\\nequation (ODE) may or may not be unique at a particular\\npoint. Whether or not a solution is unique depends on the\\nproperties of the ODE and the conditions imposed on the\\nproblem. The existence and uniqueness theorem for ODEs\\nstates that a first-order ODE will have a unique solution that\\nsatisfies specific initial or boundary conditions under certain\\nconditions. This theorem guarantees the uniqueness of the\\nsolution in a certain interval or domain. However, it’s\\nimportant to note that the solution might not be unique in\\nsome cases. Non-uniqueness can occur when the ODE is\\nsingular or ill-posed, meaning that it lacks sufficient conditions\\nto guarantee the existence of a unique solution.\\nAt the fold point (xs,ys), the existence and uniqueness\\ntheorem of first-order ODEs does not hold, and the solutions\\n(trajectories) of the slow subsystem in Eq.(4) are forced to\\nleaveM0precisely at the singular points (xs,ys).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='14939a2e-3168-47f2-b61c-ed62ee43d4cc', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nSo, since the critical manifold M0of the FHN neuron model\\nlooses its hyperbolicity at the (xs,ys), the slow flow in Eq.(4)\\nmust detach from M0and should become fast, that is\\ndy\\ndτ=0, and horizontally jump from one attracting branch of\\nM0to another.\\nTo see this more clearly, it is more convenient to use an\\nalternative procedure to derive the slow flow on M0in terms\\nof the fast variable x. We implicitly differentiate\\nF(x,y) =y−h(x) =0 with respect with τ\\ndy\\ndτ=G(x,y) =h′(x)dx\\ndτ⇒dx\\ndτ=G(x,y)\\nh′(x).\\nUsing the constraint y=h(x)(i.e., the critical manifold M0),\\nwe have the expression of the slow flow of the fast variable x\\nonM0as\\ndx\\ndτ=G(x,h(x))\\nh′(x), (7)\\nwhich becomes singular at the fold point xswithh′(xs) =0.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='06f9661e-6705-4cfc-9ec6-7eadbe83138e', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\n−0.5 0 0.5 1 1.5 2 2.5−0.4−0.200.20.40.6\\nvwε=0\\nε=0.1\\nM0\\nFigure: In the singular limit (i.e., when ε=0), black single and double\\narrows indicate slow and fast flow, respectively. Blue trajectories\\nrepresent some solutions of the FHN when ε̸=0.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='bc7b0a90-8519-4c84-be8e-6ddf7776ec2b', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nA fold point (xs,ys)is said to be a folded singularity at the\\nbifurcation parameter value c=c0, if it satisfies the\\nassumptions of a nondegenerate fold point, i.e.,\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3F(xs,ys,c0) =0,\\n∂xF(xs,ys,c0) =0\\n∂yF(xs,ys,c0)̸=0\\n∂xxF(xs,ys,c0)̸=0\\nG(xs,ys,c0) =0.(8)\\nA folded singularity of the FHN model is called generic if\\n{∂xG(xs,ys,c0)̸=0\\n∂cG(xs,ys,c0)̸=0(9)\\nExercise 3B: Are the fold points defined in Eq. (6) above\\n(which you must explicitly calculate) generic fold points or\\nnot?\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='dfb536de-dd07-4d0a-bc63-6129a8ec08ff', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nAn arbitrary point p∈M 0at which a slow and a fast\\nsegment are concatenated is called\\na jump point if the fast flow is directed away from M0,\\na drop point if the fast flow is directed toward M0.\\nAt a generic fold point (xs,ys), the slow subsystem in Eq.(4)\\nis singular, and solutions reach (xs,ys)in finite forward or\\nbackward time. This makes the generic fold point (xs,ys)a\\njump point , an ingredient necessary for the existence of\\ndeterministic relaxation oscillations.\\nFor the full FHN model (i.e., ε>0), the fixed point are\\ndefined by\\n(xe,ye) :={(x,y)∈R2|F(x,y) =G(x,y) =0}(10)\\nFrom Eq. (1), we obtain the fixed point equations given as\\n{b\\ncx=−x3+ (a+1)x2−ax\\ny=b\\ncx(11)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e2700dcd-81bd-42e7-97be-01776a8f381f', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nEq.(11) has solutions for x\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f3x0=0\\nx1=a+1\\n2−√\\n(a−1)2\\n4−b\\nc\\nx2=a+1\\n2+√\\n(a−1)2\\n4−b\\nc(12)\\nNote that x1andx2exist (i.e., x1,x2∈R) only if(a−1)2\\n4>b\\nc.\\nSee that if (a−1)2<4b\\nc=⇒x0is the unique fixed point.\\nAlso, because b>0,c>0 and 0<a<1, the set of fixed\\npoints in Eq.(12) becomes ordered, i.e., x0<a<x1,2<1.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7c5aec16-3242-491e-99d9-94418aab09ed', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The slow-fast analysis of FitzHugh-Nagumo neuron model\\nA bifurcation is said to occur if some or all of the fixed points\\nin Eq. (12) coincide.\\nFor example, x1=x2if and only if(a−1)2\\n4=b\\nc\\nFor this course, we shall consider x0to be the only fixed point.\\nThe stability of x0is given by the eigenvalues of the Jacobian\\nmatrix of Eq.(2) ( From your previous exercises, this should\\nnow be a pretty easy check! ). We consider our unique fixed\\npoint (x0,y0) = (0,0)to be stable.\\nWith a unique and stable fixed point, the neuron is said to be\\nin the excitable regime. The excitable regime of a neuron can\\nthus be defined as a state where, starting from an initial\\ncondition within the basin of attraction of a unique stable\\nfixed point , the neuron experiences at most one significant\\nnon-monotonic excursion (spike) in the phase space. After this\\nspike, the phase trajectory returns to the fixed point and\\nremains there until further perturbation.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5f442a44-95d4-4c24-a0d4-f0d4349786ec', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Excitability of FitzHugh-Nagumo neuron model\\nPhase portrait of the excitable regime of the FHN neuron.\\nThe evolution of a trajectory in the excitable regime is\\nconstrained by the isoclines of the FHN neuron given by:\\ndy\\ndx=ε(bx−cy)\\nx(x−a)(1−x)−y(13)\\nExercise 3C: Using the slow-fast FHN neuron model written in\\nthe fast timescale t, show how the isocline in Eq.(13) is\\nobtained?\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a900a236-d5c9-4e07-bb35-2caa5c4c1862', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Excitability of FitzHugh-Nagumo neuron model\\nPhase portrait of the excitable regime of the FHN neuron.\\nIsoclines:\\ndy\\ndx=ε(bx−cy)\\nx(x−a)(1−x)−y(14)\\nIfy=b\\ncx=⇒dy\\ndx=0 in Eq.(14)\\nIfy=x(x−a)(1−x) =⇒dy\\ndx=∞in Eq.(14)\\nIf 0<x<a, thendy\\ndx<0\\nIfa<x<1, thendy\\ndx>0\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='94a28fc2-3a5c-438b-909b-f85b23460480', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Excitability of FitzHugh-Nagumo neuron model\\nPhase portrait of the excitable regime of the FHN neuron.\\n0<x(t=0)<a, then the trajectory moves directly to the\\nunique and stable fixed point located at (x0,y0) = (0,0)and\\nthe voltage x(t)of the neuron immediately starts to decrease\\nto zero — the resting state of the neuron.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='731cf0b7-192b-4d60-97bc-6658c8e689fd', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Excitability of FitzHugh-Nagumo neuron model\\nPhase portrait of the excitable regime of the FHN neuron.\\na<x(t=0)<1, then the trajectory x(t)first increases, and\\nthe FHN \"fires\" or \"spikes\". The trajectory undergoes a long\\nexcursion in phase space before returning to the fixed point at\\n(x0,y0) = (0,0). This make the FHN a Type II neuron model.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='24ecd4f6-1f24-4ed1-8820-72fecc381dea', embedding=None, metadata={'page_label': '15', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Excitability of FitzHugh-Nagumo neuron model\\nPhase portrait of the excitable regime of the FHN neuron.\\nThus, we see that x(t=0) =aacts a threshold between\\ndifferent behaviors called excitability.\\nx(t)≥acan also be used as a threshold that determines\\nwhether at a time tthere is a spike or not.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a2b33bf4-4212-4da1-b053-d2676bf77440', embedding=None, metadata={'page_label': '16', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Excitability of FitzHugh-Nagumo neuron model\\nIn summary, a neuron is said to be in an excitable state when\\nstarting with some initial condition in the basin of attraction\\nof aunique stable fixed point will result in at most one large\\nnon-monotonic excursion (spike) into the phase space after\\nwhich the trajectory returns and stays at this fixed point.\\nSelf-sustained spiking is not possible in the excitable regime\\nunless a parameter is changed such that a Hopf bifurcation\\noccurs.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4ce997b2-d8ce-40ef-aabf-a105a43ac73a', embedding=None, metadata={'page_label': '17', 'file_name': 'Lecture_s11.pdf', 'file_path': '/content/data/Lecture_s11.pdf', 'file_type': 'application/pdf', 'file_size': 3264477, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Singular Hopf bifurcation in the slow-fast FHN neuron\\nSelf-sustained spiking can be achieved in the FHN neuron\\nmodel only via a Hopf bifurcation, making, as we shall see\\nlater, the FHN neuron model a Type II neuron model, in\\ncontrast to Type I neuron model.\\nThe slow-fast FHN neuron model (and, in general, any 2D\\nslow-fast dynamical system) is said to undergo a singular Hopf\\nbifurcation (SHB) if the linearized center manifold of the\\nsystem has a pair of singular eigenvalues λ(ε,c)at the Hopf\\nbifurcation point c=cH. That is, if we have\\nλ(ε,c) =µ(ε,c) +iβ(ε,c)such thatµ(ε,c=cH) =0 and\\nd\\ndcµ(ε,c=cH)̸=0, then the FHN undergoes a SHB if:\\n1lim\\nε→0|β(ε,c)|=∞on the slow time-scale τ, and\\n2lim\\nε→0β(ε,c) =0 on the fast time-scale t.\\nExercise 3D: For ε=0.001, show that the slow-fast FHN\\nneuron given in Eqs. (1) and (2) can undergo a SHB at\\nc=cH. Simulate this FHN neuron on each timescale (i.e., on\\nτandt) and show the corresponding time series with at least\\n5 spikes, where a spike is counted only when x≥1.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1948ab24-5497-448e-ace2-2ca767507ac6', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 12: Type I and Type II neurons.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='05bd6bfa-4f89-4c7f-915c-7dfaefd985d5', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objective\\nUnderstand the firing pattern and differences between Type I\\nand Type II neurons\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='94cab216-1b95-457e-bb86-00f0e1907b1f', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nType I and Type II are commonly used classifications for\\nneuronal firing patterns.\\nType I neurons exhibit continuous spiking in response to a\\nsustained stimulus (input current).\\nIn contrast, Type II neurons display an initial burst of spikes\\nfollowed by a quiescent period, even in the presence of a\\nconstant stimulus.\\nSome neuron models are of Type I only, some of Type II only,\\nand some can be of Type I or II, depending on the model’s\\nparameter values.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='16aaa163-f37e-4a62-bdb2-1ee2938ce4c6', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nType I and Type II are commonly used classifications for\\nneuronal firing patterns.\\nType I neurons exhibit continuous spiking in response to a\\nsustained stimulus (input current).\\nIn contrast, Type II neurons display an initial burst of spikes\\nfollowed by a quiescent period, even in the presence of a\\nconstant stimulus.\\nSome neuron models are of Type I only, some of Type II only,\\nand some can be of Type I or II, depending on the model’s\\nparameter values.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7fef3133-5397-4bc3-b07d-ca933e75a5b7', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nType I and Type II are commonly used classifications for\\nneuronal firing patterns.\\nType I neurons exhibit continuous spiking in response to a\\nsustained stimulus (input current).\\nIn contrast, Type II neurons display an initial burst of spikes\\nfollowed by a quiescent period, even in the presence of a\\nconstant stimulus.\\nSome neuron models are of Type I only, some of Type II only,\\nand some can be of Type I or II, depending on the model’s\\nparameter values.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8346a68c-66db-4296-bbe3-3a82fdc85a9f', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nType I and Type II are commonly used classifications for\\nneuronal firing patterns.\\nType I neurons exhibit continuous spiking in response to a\\nsustained stimulus (input current).\\nIn contrast, Type II neurons display an initial burst of spikes\\nfollowed by a quiescent period, even in the presence of a\\nconstant stimulus.\\nSome neuron models are of Type I only, some of Type II only,\\nand some can be of Type I or II, depending on the model’s\\nparameter values.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='22344d1a-da5e-4987-a7b5-93e3d3516af3', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nType I neurons exhibit continuous firing as long as the input current\\nremains above a specific threshold value. They respond to stimuli in\\na more graded manner, with the membrane potential and firing rate\\nchanging proportionally to the intensity or duration of the input\\nstimulus. Unlike Type II neurons, Type I neurons do not display the\\ncharacteristic spikes-and-quiescent pattern. Instead, their responses\\nare continuous and graded, with the response’s magnitude and\\nshape dependent on the stimulus’s strength.\\nType II neurons demonstrate a threshold-based firing behavior. They\\ngenerate action potentials (spikes) only when the membrane\\npotential surpasses a specific threshold, resulting in all-or-nothing\\nresponses with a distinct shape and magnitude. In an all-or-nothing\\nresponse, the generated action potential is of the same magnitude\\nand shape, regardless of the stimulus intensity that caused the\\nthreshold crossing. This binary response generates either an action\\npotential (spike) or no action potential (no spike).\\nNote that the classifications of Type I and Type II neurons serve as\\nsimplified categorizations to describe firing behaviors. It can be\\nmore complex in real neurons, exhibiting characteristics that may\\nfall between the strict definitions of Type I or Type II.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='fcdbe3a8-6c7a-4e3e-89f8-396831fab72d', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nType I neurons exhibit continuous firing as long as the input current\\nremains above a specific threshold value. They respond to stimuli in\\na more graded manner, with the membrane potential and firing rate\\nchanging proportionally to the intensity or duration of the input\\nstimulus. Unlike Type II neurons, Type I neurons do not display the\\ncharacteristic spikes-and-quiescent pattern. Instead, their responses\\nare continuous and graded, with the response’s magnitude and\\nshape dependent on the stimulus’s strength.\\nType II neurons demonstrate a threshold-based firing behavior. They\\ngenerate action potentials (spikes) only when the membrane\\npotential surpasses a specific threshold, resulting in all-or-nothing\\nresponses with a distinct shape and magnitude. In an all-or-nothing\\nresponse, the generated action potential is of the same magnitude\\nand shape, regardless of the stimulus intensity that caused the\\nthreshold crossing. This binary response generates either an action\\npotential (spike) or no action potential (no spike).\\nNote that the classifications of Type I and Type II neurons serve as\\nsimplified categorizations to describe firing behaviors. It can be\\nmore complex in real neurons, exhibiting characteristics that may\\nfall between the strict definitions of Type I or Type II.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3cc44e95-5543-438a-a0e8-9c8b6a6913a0', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nType I neurons exhibit continuous firing as long as the input current\\nremains above a specific threshold value. They respond to stimuli in\\na more graded manner, with the membrane potential and firing rate\\nchanging proportionally to the intensity or duration of the input\\nstimulus. Unlike Type II neurons, Type I neurons do not display the\\ncharacteristic spikes-and-quiescent pattern. Instead, their responses\\nare continuous and graded, with the response’s magnitude and\\nshape dependent on the stimulus’s strength.\\nType II neurons demonstrate a threshold-based firing behavior. They\\ngenerate action potentials (spikes) only when the membrane\\npotential surpasses a specific threshold, resulting in all-or-nothing\\nresponses with a distinct shape and magnitude. In an all-or-nothing\\nresponse, the generated action potential is of the same magnitude\\nand shape, regardless of the stimulus intensity that caused the\\nthreshold crossing. This binary response generates either an action\\npotential (spike) or no action potential (no spike).\\nNote that the classifications of Type I and Type II neurons serve as\\nsimplified categorizations to describe firing behaviors. It can be\\nmore complex in real neurons, exhibiting characteristics that may\\nfall between the strict definitions of Type I or Type II.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9a28e0bc-ba9e-4601-8140-991137eeb242', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nThe Leaky Integrate-and-Fire (LIF) neuron model, given in\\nEq.(1) below, is an example of a Type I that cannot be a\\nType II. LIF considers the incoming input current and spikes\\nwhen a certain threshold is reached. The LIF neuron model\\nincludes a leak term, accounting for the passive charge\\nleakage across the neuron’s membrane. The equation\\ngoverning the membrane potential (V, measured in mV) is:\\n{τmdV\\ndt=−(V−Vrest) +RmI(t)\\nifV(t)≥Vthreshold,then V←−Vreset(1)\\nτmrepresents the membrane time constant that determines the\\nleakiness of the neuron. Typical values range from 10 ms to 30\\nms. However, it can be adjusted based on the desired timescale\\nof the neuron’s dynamics.\\nVrestis the resting potential of the neuron and is set at -70 mV.\\nRmis the membrane resistance. The typical values range from\\n1MΩ(megaohm) to 10 MΩ.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6f8d90a6-ce9e-4b02-b493-87316aeb7ad9', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nVthresholdis the membrane threshold potential, typically set at\\n-55.0 mV.\\nVresetis the reset membrane potential, typically set at -75.0\\nmV.\\nI(t)is the input current as a function of time tand measured\\ninnA\\nExamples of Type II neuron models (that we have studied in\\nprevious lectures and exercises) include\\nThe Hodgkin-Huxley (HH) neuron model\\nHindmarsh-Rose (HR) neuron model\\nFitzHugh-Nagumo (FHN) neuron model\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='60868ab6-ff53-4523-b0a2-c789b838ed47', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nThe Morris-Lecar (ML) neuron model describes the dynamics of a\\nneuron’s membrane potential based on ion channel conductances.\\nAdjusting the model’s parameters, such as the conductance values,\\ncan simulate different firing behaviors, making it possible for ML to\\nexhibit characteristics of both Type I and Type II neurons.\\nWhen the ML model’s parameters are set so that the neuron\\nexhibits continuous and graded firing, similar to Type I behavior, it\\nis considered a Type I neuron. In this case, the firing rate or\\nmembrane potential change is proportional to the intensity or\\nduration of the input stimulus.\\nOn the other hand, by adjusting the parameters to generate a\\nthreshold-based firing behavior, where action potentials occur in an\\nall-or-nothing manner, the ML neuron can exhibit characteristics\\nsimilar to Type II behavior. This results in a binary response, where\\nthe generated action potential is of the same magnitude and shape\\nregardless of the stimulus intensity.\\nTherefore, the Morris-Lecar neuron model is a versatile\\nmathematical framework that can represent both Type I and Type II\\nfiring behaviors by appropriately adjusting its parameters, making it\\na valuable tool for studying different aspects of neural dynamics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1d2adc76-4b68-4558-8f40-4e46c2590107', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nThe Morris-Lecar (ML) neuron model describes the dynamics of a\\nneuron’s membrane potential based on ion channel conductances.\\nAdjusting the model’s parameters, such as the conductance values,\\ncan simulate different firing behaviors, making it possible for ML to\\nexhibit characteristics of both Type I and Type II neurons.\\nWhen the ML model’s parameters are set so that the neuron\\nexhibits continuous and graded firing, similar to Type I behavior, it\\nis considered a Type I neuron. In this case, the firing rate or\\nmembrane potential change is proportional to the intensity or\\nduration of the input stimulus.\\nOn the other hand, by adjusting the parameters to generate a\\nthreshold-based firing behavior, where action potentials occur in an\\nall-or-nothing manner, the ML neuron can exhibit characteristics\\nsimilar to Type II behavior. This results in a binary response, where\\nthe generated action potential is of the same magnitude and shape\\nregardless of the stimulus intensity.\\nTherefore, the Morris-Lecar neuron model is a versatile\\nmathematical framework that can represent both Type I and Type II\\nfiring behaviors by appropriately adjusting its parameters, making it\\na valuable tool for studying different aspects of neural dynamics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f2e57d57-62f5-42f2-af6d-41c9a922fcf1', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nThe Morris-Lecar (ML) neuron model describes the dynamics of a\\nneuron’s membrane potential based on ion channel conductances.\\nAdjusting the model’s parameters, such as the conductance values,\\ncan simulate different firing behaviors, making it possible for ML to\\nexhibit characteristics of both Type I and Type II neurons.\\nWhen the ML model’s parameters are set so that the neuron\\nexhibits continuous and graded firing, similar to Type I behavior, it\\nis considered a Type I neuron. In this case, the firing rate or\\nmembrane potential change is proportional to the intensity or\\nduration of the input stimulus.\\nOn the other hand, by adjusting the parameters to generate a\\nthreshold-based firing behavior, where action potentials occur in an\\nall-or-nothing manner, the ML neuron can exhibit characteristics\\nsimilar to Type II behavior. This results in a binary response, where\\nthe generated action potential is of the same magnitude and shape\\nregardless of the stimulus intensity.\\nTherefore, the Morris-Lecar neuron model is a versatile\\nmathematical framework that can represent both Type I and Type II\\nfiring behaviors by appropriately adjusting its parameters, making it\\na valuable tool for studying different aspects of neural dynamics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='40eaf96a-2c0a-4b4c-9481-c9129edf0c95', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nThe Morris-Lecar (ML) neuron model describes the dynamics of a\\nneuron’s membrane potential based on ion channel conductances.\\nAdjusting the model’s parameters, such as the conductance values,\\ncan simulate different firing behaviors, making it possible for ML to\\nexhibit characteristics of both Type I and Type II neurons.\\nWhen the ML model’s parameters are set so that the neuron\\nexhibits continuous and graded firing, similar to Type I behavior, it\\nis considered a Type I neuron. In this case, the firing rate or\\nmembrane potential change is proportional to the intensity or\\nduration of the input stimulus.\\nOn the other hand, by adjusting the parameters to generate a\\nthreshold-based firing behavior, where action potentials occur in an\\nall-or-nothing manner, the ML neuron can exhibit characteristics\\nsimilar to Type II behavior. This results in a binary response, where\\nthe generated action potential is of the same magnitude and shape\\nregardless of the stimulus intensity.\\nTherefore, the Morris-Lecar neuron model is a versatile\\nmathematical framework that can represent both Type I and Type II\\nfiring behaviors by appropriately adjusting its parameters, making it\\na valuable tool for studying different aspects of neural dynamics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2bc85909-0fc1-41d5-9038-927eb25681f1', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nThe Morris-Lecar (ML) neuron model is given by\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3CdV\\ndt=−gCaMss(V)(V−VCa)−gKW(V−Vk)\\n−gL(V−VL) +Iext\\ndW\\ndt=Wss(V)−W\\nτW(V)\\n(2)\\nwhere:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3Mss(V) =(\\n1+ tanh[( V−V1)/V2)])\\n/2\\nWss(V) =(\\n1+ tanh[( V−V3)/V4)])\\n/2\\nτW(V) =1/(\\nϕcosh[( V−V3)/2V4])(3)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3746945e-9ea4-4a27-ae5e-75d6e569c64f', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nWhere:\\nVis the membrane potential, Wis the recovery variable,\\nMss(V)is the steady-state activation variable for the calcium\\nconductance, VCais the ca equilibrium potential, gCais the\\nmaximum calcium conductance, wis the potassium activation\\nvariable, VKis the potassium equilibrium potential, gKis the\\nmaximum potassium conductance, VLis the leak equilibrium\\npotential, gLis the leak conductance, Iextis the external\\ncurrent, Cis the membrane capacitance, WSS(V)is the\\nsteady-state activation variable for the potassium\\nconductance, and τW(V)is the time constant for the\\npotassium activation variable. Parameters and constants.\\n{V1,V2,V3,V4}are tuning parameters for steady state and\\ntime constant, and ϕis the rate scaling parameter.\\nNote that there is more than one mathematical version of the\\nML neuron model. The one given above is the most used\\nversion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='70a5b587-f3c5-424f-b2fb-75dabfb3aec6', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nWhere the standard parameter values are:\\nV1=−1.2 mV\\nV2=18 mV\\nV3=2 mV\\nV4=30 mV\\ngCa=4.4µS/cm2\\ngK=8µS/cm2\\ngL=2µS/cm2\\nVCa=120 mV\\nVK=−84 mV\\nVL=−60 mV\\nC=20µF/cm2\\nϕ=0.041 ms−1\\nIext∈[0,100]µA/cm2\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='392a6b0b-1b1e-48be-83a2-0b5d318ef865', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nBifurcation in the Morris–Lecar model can be analyzed with\\nthe input current Iext, as the main bifurcation parameter and\\nϕ,gCa,gK,gL,V3,V4as secondary parameters for phase\\nplane analysis.\\nIn the ML model, the conductance parameters that primarily\\naffect the firing behavior are gK, the gCa, and gL.\\nTo create a type I neuron, you would generally have to reduce\\ngCaor increase gK.\\nTo create a type II neuron, the gCashould be high enough to\\nallow for sustained repetitive firing.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d801f5c6-a34a-45a6-860f-38e7fe3e9253', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nExercise 4A: Simulate the LIF neuron model given in this\\nlecture and show:\\n1The time series for the duration of T=200 ms of both the\\nmembrane potential Vand the input current I(t) =Acos (ωt),\\nwhen for the first 50 ms the amplitude of the input current is\\nA=0, for the next 50 ms A=100, the next 50 ms A=200,\\nand the last 50 ms A=0. Assume that the frequency of the\\ninput current is ω=0.25 Hz or any other number that you\\nshould indicate in your figures.\\n2From the results of your simulations , explain why you think\\nthe LIF is a Type I and not Type II neuron model.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='79bb6c04-f725-433c-9af6-2540f8a30bb7', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s12.pdf', 'file_path': '/content/data/Lecture_s12.pdf', 'file_type': 'application/pdf', 'file_size': 205639, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Type I and Type II neuron models\\nExercise 4B: Plot the v-nullcline and the w-nullcline of the\\nMorris-Lecar neuron model and vary the input current and/or\\nthe maximum calcium conductance such that:\\n1The two nullclines intersect at only one fixed point.\\n2The two nullclines intersect at two fixed points.\\n3The two nullclines intersect at three fixed points.\\nExercise 4C: Show the time series and the corresponding\\nphase portrait of the membrane potential and the recovery\\nvariables for a duration of T=1000 ms when:\\n1The external current is Iext=40 nA\\n2The external current is Iext=90 nA\\nPlease systematically organise your submission. For Exercises 4A1, 4B1, 4B2,\\n4B3, 4C1, and 4C2, I would like to see the outputs of your codes in one PDF\\nand the corresponding Python codes (with the \".py\" extension). For example,\\nyour Python code for exercise 7A1 should be called Exercise_7A1.py , and so on\\nfor the rest. Please ensure your codes can plot and show the figures required in\\nthe exercises, including all the necessary labeling and legends. I will NOT\\nmodify your code. So if your code does not run because of bugs and/or an\\nomission, you get no points for the corresponding exercise. Your explanation in\\nExercise 4A2 should not exceed 10 sentences in the PDF that contains all the\\noutputs of the codes.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3ebf1a90-1ddc-4bbe-b520-9ca570f251ca', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 13: Sources of noise in neurons, element of\\nprobability theory and applications to stochastic neuron\\nmodels.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d974dbf0-5d60-410b-a834-20eb50617b85', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives\\n1Learn about the sources of noise (stochasticity) in neurons.\\n2Recall basic concepts in probability theory, stochastic\\nprocesses, and built stochastic neuron models.\\n3How to simulate the stochastic neuron.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ee81a819-5c26-4fa1-bc1d-b7001a6b3248', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Sources and effects of noise in neurons\\nNoise (randomness or stochasticity) is ubiquitous in neural\\nsystems. It may arise from many different sources. .\\nThe sources of neuronal noise include synaptic noise, that is,\\nthe quasi-random release of neurotransmitters by synapses or\\nrandom synaptic input from other neurons, and channel noise,\\nthat is, the random switching of ion channels.\\nThe addition of noise terms into the neuron model equation\\nhas to be therefore seen as the effects of the other neurons\\n(synaptic noise) and the opening and closing of ion channels\\n(channel noise) on this neuron.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9b2b8b1d-91e1-4948-bb0d-cd627013e3f5', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Sources and effects of noise in neurons\\nNoise (randomness or stochasticity) is ubiquitous in neural\\nsystems. It may arise from many different sources. .\\nThe sources of neuronal noise include synaptic noise, that is,\\nthe quasi-random release of neurotransmitters by synapses or\\nrandom synaptic input from other neurons, and channel noise,\\nthat is, the random switching of ion channels.\\nThe addition of noise terms into the neuron model equation\\nhas to be therefore seen as the effects of the other neurons\\n(synaptic noise) and the opening and closing of ion channels\\n(channel noise) on this neuron.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a97a8c9c-9743-4403-b51d-92019fd3aa7e', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Sources and effects of noise in neurons\\nNoise (randomness or stochasticity) is ubiquitous in neural\\nsystems. It may arise from many different sources. .\\nThe sources of neuronal noise include synaptic noise, that is,\\nthe quasi-random release of neurotransmitters by synapses or\\nrandom synaptic input from other neurons, and channel noise,\\nthat is, the random switching of ion channels.\\nThe addition of noise terms into the neuron model equation\\nhas to be therefore seen as the effects of the other neurons\\n(synaptic noise) and the opening and closing of ion channels\\n(channel noise) on this neuron.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='38fd124d-4045-46fe-a5b3-09bd7014ae1e', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Sources and effects of noise in neurons\\nDepending on the deterministic parameter regime of a neuron\\nmodel, adding noise to either the membrane potential variable\\n(synaptic noise) and/or the recovery current variable (channel\\nnoise) can induce different dynamical effects. Some of these\\neffects can be somewhat counterintuitive, as noise plays a\\nconstructive role in weak signal detection or coherence of\\nspiking activity instead of being a nuisance. .\\nNeurons have been shown to use noise to improve information\\nprocesses via phenomena such as stochastic resonance (SR),\\ncoherence resonance (CR), inverse stochastic resonance (ICR),\\nstochastic synchronization (SS), etc\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='da9588a0-83ff-40cf-8110-68ed3ef11ee8', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Sources and effects of noise in neurons\\nDepending on the deterministic parameter regime of a neuron\\nmodel, adding noise to either the membrane potential variable\\n(synaptic noise) and/or the recovery current variable (channel\\nnoise) can induce different dynamical effects. Some of these\\neffects can be somewhat counterintuitive, as noise plays a\\nconstructive role in weak signal detection or coherence of\\nspiking activity instead of being a nuisance. .\\nNeurons have been shown to use noise to improve information\\nprocesses via phenomena such as stochastic resonance (SR),\\ncoherence resonance (CR), inverse stochastic resonance (ICR),\\nstochastic synchronization (SS), etc\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='dd76831b-3e47-4a6f-bf7f-d509f10437b2', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of stochastic neurons\\nMathematically, we want to perturb a dynamical system by\\nadding new terms to it. The perturbation is done by adding a\\nWiener process to the dynamical system, which becomes a\\nstochastic system. The study of stochastic dynamical systems\\nis more abstract than deterministic ones (i.e., the ones\\nwithout noise), and needs important definitions and results\\nfrom probability theory which are, unfortunately beyond the\\nscope of this course. .\\nTherefore, we only briefly define a few objects in probability\\ntheory, stochastic processes, Wiener and Ito processes, and\\nhow to numerically integrate stochastic neuron models.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='df538f53-5aa2-453e-8c6c-fd6c9b59ad2e', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of stochastic neurons\\nMathematically, we want to perturb a dynamical system by\\nadding new terms to it. The perturbation is done by adding a\\nWiener process to the dynamical system, which becomes a\\nstochastic system. The study of stochastic dynamical systems\\nis more abstract than deterministic ones (i.e., the ones\\nwithout noise), and needs important definitions and results\\nfrom probability theory which are, unfortunately beyond the\\nscope of this course. .\\nTherefore, we only briefly define a few objects in probability\\ntheory, stochastic processes, Wiener and Ito processes, and\\nhow to numerically integrate stochastic neuron models.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='91212b81-e4fd-4ec9-96bd-39d0bc9474cf', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nA probability space, denoted as (Ω,F,P), is a mathematical\\nconstruct used to model a random or stochastic process. It consists\\nof three components:\\n1The sample space (denoted as Ω) in a probability space is the\\nset of all possible outcomes of a random experiment. Each\\nelement in Ωrepresents a unique outcome that can occur\\nwhen the experiment is performed. The sample space can be:\\nFinite: When the number of possible outcomes is countable\\nand limited. For example, the sample space of flipping a coin is\\nΩ ={Heads,Tails}.\\nCountably Infinite: When the number of possible outcomes is\\ncountable but infinite. For example, the sample space of rolling\\na fair die indefinitely until a six appears is Ω ={1,2,3,...}.\\nUncountably Infinite: When the number of possible outcomes\\nis uncountable. For example, the sample space for measuring\\nthe exact amount of rainfall in a day is Ω = [0,∞).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a5d99a5b-9561-4556-bbf9-b21b783377c9', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nA probability space, denoted as (Ω,F,P), is a mathematical\\nconstruct used to model a random or stochastic process. It consists\\nof three components:\\n1The sample space (denoted as Ω) in a probability space is the\\nset of all possible outcomes of a random experiment. Each\\nelement in Ωrepresents a unique outcome that can occur\\nwhen the experiment is performed. The sample space can be:\\nFinite: When the number of possible outcomes is countable\\nand limited. For example, the sample space of flipping a coin is\\nΩ ={Heads,Tails}.\\nCountably Infinite: When the number of possible outcomes is\\ncountable but infinite. For example, the sample space of rolling\\na fair die indefinitely until a six appears is Ω ={1,2,3,...}.\\nUncountably Infinite: When the number of possible outcomes\\nis uncountable. For example, the sample space for measuring\\nthe exact amount of rainfall in a day is Ω = [0,∞).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9a52f72c-4f1e-4a1b-ba29-84e2af9d6ed1', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nA probability space, denoted as (Ω,F,P), is a mathematical\\nconstruct used to model a random or stochastic process. It consists\\nof three components:\\n1The sample space (denoted as Ω) in a probability space is the\\nset of all possible outcomes of a random experiment. Each\\nelement in Ωrepresents a unique outcome that can occur\\nwhen the experiment is performed. The sample space can be:\\nFinite: When the number of possible outcomes is countable\\nand limited. For example, the sample space of flipping a coin is\\nΩ ={Heads,Tails}.\\nCountably Infinite: When the number of possible outcomes is\\ncountable but infinite. For example, the sample space of rolling\\na fair die indefinitely until a six appears is Ω ={1,2,3,...}.\\nUncountably Infinite: When the number of possible outcomes\\nis uncountable. For example, the sample space for measuring\\nthe exact amount of rainfall in a day is Ω = [0,∞).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='54e35422-f7fc-40c4-b629-c32bd3ab2101', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\n1Sample space (Ω)\\n2Aσ-algebra (F) is a collection of subsets of a given set Ωthat satisfies\\ncertain properties, making it suitable for defining a probability measure.\\nFormally, a σ-algebraFon a set Ωis a collection of subsets of Ωsuch\\nthat:\\nThe set Ωitself is inF:Ω∈F\\nClosed under complementation: If a set Ais inF, then its\\ncomplement Ac(relative to Ω) is also inF:A∈F =⇒Ac∈F\\nClosed under countable unions: If A1,A2,A3,...are inF, then the\\nunion of all these sets is also in F:\\nA1,A2,A3,...∈F =⇒⋃∞\\ni=1Ai∈FSince theσ-algebra is closed under complementation and countable\\nunions, it is also closed under countable intersections by De Morgan’s\\nlaws. Specifically:\\n∞⋂\\ni=1Ai=(∞⋃\\ni=1Ac\\ni)c\\n∈F\\nExample: Consider a simple set Ω ={a,b,c}. One possible σ-algebra on\\nΩis:\\nF={∅,{a},{b,c},{a,b,c}}\\nThis collectionFis aσ-algebra because it includes Ω, is closed under\\ncomplementation, and is closed under countable unions.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2e2aacb4-7b95-4574-bf35-9e8555ea7df2', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\n1Sample space (Ω)\\n2Aσ-algebra (F) is a collection of subsets of a given set Ωthat satisfies\\ncertain properties, making it suitable for defining a probability measure.\\nFormally, a σ-algebraFon a set Ωis a collection of subsets of Ωsuch\\nthat:\\nThe set Ωitself is inF:Ω∈F\\nClosed under complementation: If a set Ais inF, then its\\ncomplement Ac(relative to Ω) is also inF:A∈F =⇒Ac∈F\\nClosed under countable unions: If A1,A2,A3,...are inF, then the\\nunion of all these sets is also in F:\\nA1,A2,A3,...∈F =⇒⋃∞\\ni=1Ai∈F\\nSince theσ-algebra is closed under complementation and countable\\nunions, it is also closed under countable intersections by De Morgan’s\\nlaws. Specifically:\\n∞⋂\\ni=1Ai=(∞⋃\\ni=1Ac\\ni)c\\n∈FExample: Consider a simple set Ω ={a,b,c}. One possible σ-algebra on\\nΩis:\\nF={∅,{a},{b,c},{a,b,c}}\\nThis collectionFis aσ-algebra because it includes Ω, is closed under\\ncomplementation, and is closed under countable unions.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='bcc0261e-36d6-4959-b5e6-ddff07361df5', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\n1Sample space (Ω)\\n2Aσ-algebra (F) is a collection of subsets of a given set Ωthat satisfies\\ncertain properties, making it suitable for defining a probability measure.\\nFormally, a σ-algebraFon a set Ωis a collection of subsets of Ωsuch\\nthat:\\nThe set Ωitself is inF:Ω∈F\\nClosed under complementation: If a set Ais inF, then its\\ncomplement Ac(relative to Ω) is also inF:A∈F =⇒Ac∈F\\nClosed under countable unions: If A1,A2,A3,...are inF, then the\\nunion of all these sets is also in F:\\nA1,A2,A3,...∈F =⇒⋃∞\\ni=1Ai∈F\\nSince theσ-algebra is closed under complementation and countable\\nunions, it is also closed under countable intersections by De Morgan’s\\nlaws. Specifically:\\n∞⋂\\ni=1Ai=(∞⋃\\ni=1Ac\\ni)c\\n∈F\\nExample: Consider a simple set Ω ={a,b,c}. One possible σ-algebra on\\nΩis:\\nF={∅,{a},{b,c},{a,b,c}}\\nThis collectionFis aσ-algebra because it includes Ω, is closed under\\ncomplementation, and is closed under countable unions.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b91b7f22-1429-43d1-aeb7-ceb7f2d837e5', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\n1Sample space ( Ω)\\n2σ-algebra (F)\\n3Probability measure ( P): This is a function that assigns a probability to\\neach event inF. The probability measure must satisfy the following\\nproperties:\\nP(Ω) =1: The probability of the entire sample space is 1.\\nP(A)≥0 for any event A∈F: Probabilities are non-negative.\\nPis countably additive: For any countable collection of mutually\\nexclusive events A1,A2,...∈F,\\nP(∞⋃\\ni=1Ai)\\n=∞∑\\ni=1P(Ai).\\nIn summary, a probability space (Ω,F,P)provides a formal framework\\nfor assigning probabilities to events and studying stochastic phenomena.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='49ce6a4f-3f67-44a7-b340-0bddb59333ba', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nIn the context of probability theory, a filtration is a mathematical\\nconcept used to describe the evolution of information over time. It\\nformalizes the idea that as time progresses, more information\\nbecomes available. In the context of probability theory, a filtration\\nis a mathematical concept used to describe the evolution of\\ninformation over time. It formalizes the idea that as time\\nprogresses, more information becomes available.Definition : A filtration on a probability space (Ω,F,P)is a family\\nofσ-algebras{Ft}t≥0indexed by time tsuch that:\\n1F0⊂F tfor allt≥0: This implies that F0is the initial\\nσ-algebra, representing the initial information, and this\\ninformation is included in all future σ-algebras.\\n2Fs⊂F tfor all 0≤s≤t: This means that the σ-algebras are\\nincreasing, reflecting the idea that as time progresses, the\\namount of available information can only increase or stay the\\nsame. This property is known as the filtration property.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='aa4b7e0e-739c-4880-b8db-3a961bc81c4f', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nIn the context of probability theory, a filtration is a mathematical\\nconcept used to describe the evolution of information over time. It\\nformalizes the idea that as time progresses, more information\\nbecomes available. In the context of probability theory, a filtration\\nis a mathematical concept used to describe the evolution of\\ninformation over time. It formalizes the idea that as time\\nprogresses, more information becomes available.\\nDefinition : A filtration on a probability space (Ω,F,P)is a family\\nofσ-algebras{Ft}t≥0indexed by time tsuch that:\\n1F0⊂F tfor allt≥0: This implies that F0is the initial\\nσ-algebra, representing the initial information, and this\\ninformation is included in all future σ-algebras.\\n2Fs⊂F tfor all 0≤s≤t: This means that the σ-algebras are\\nincreasing, reflecting the idea that as time progresses, the\\namount of available information can only increase or stay the\\nsame. This property is known as the filtration property.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='dc4f0d7c-4c57-4ab0-a2d4-934a9789b354', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nIn the context of probability theory, a filtration is a mathematical\\nconcept used to describe the evolution of information over time. It\\nformalizes the idea that as time progresses, more information\\nbecomes available. In the context of probability theory, a filtration\\nis a mathematical concept used to describe the evolution of\\ninformation over time. It formalizes the idea that as time\\nprogresses, more information becomes available.\\nDefinition : A filtration on a probability space (Ω,F,P)is a family\\nofσ-algebras{Ft}t≥0indexed by time tsuch that:\\n1F0⊂F tfor allt≥0: This implies that F0is the initial\\nσ-algebra, representing the initial information, and this\\ninformation is included in all future σ-algebras.\\n2Fs⊂F tfor all 0≤s≤t: This means that the σ-algebras are\\nincreasing, reflecting the idea that as time progresses, the\\namount of available information can only increase or stay the\\nsame. This property is known as the filtration property.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c8d78ded-29ca-4267-b82c-574fbe16cc04', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nShorter formal Definition: Let (Ω,F,P)be a probability space. A\\nfiltration{Ft}t≥0is a family of σ-algebrasFt⊂Fsuch that for\\nall 0≤s≤t,\\nFs⊆F t.Example: Consider a probability space (Ω,F,P)and a stochastic\\nprocess{Xt}t≥0, whereXtrepresents the value of a stock at time\\nt. The filtration{Ft}t≥0can be interpreted as follows:\\nF0represents the information available at the initial time\\n(e.g., initial stock price).\\nFtrepresents all the information available up to and including\\ntimet(e.g., all past stock prices up to time t).\\nImportance: Filtrations are crucial in the study of random\\nprocesses and provide a rigorous way to handle the evolution of\\ninformation and ensure that stochastic processes are properly\\naligned with the available information at each point in time.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ed48236d-b2ad-4d7f-9428-892934918d87', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nShorter formal Definition: Let (Ω,F,P)be a probability space. A\\nfiltration{Ft}t≥0is a family of σ-algebrasFt⊂Fsuch that for\\nall 0≤s≤t,\\nFs⊆F t.\\nExample: Consider a probability space (Ω,F,P)and a stochastic\\nprocess{Xt}t≥0, whereXtrepresents the value of a stock at time\\nt. The filtration{Ft}t≥0can be interpreted as follows:\\nF0represents the information available at the initial time\\n(e.g., initial stock price).\\nFtrepresents all the information available up to and including\\ntimet(e.g., all past stock prices up to time t).Importance: Filtrations are crucial in the study of random\\nprocesses and provide a rigorous way to handle the evolution of\\ninformation and ensure that stochastic processes are properly\\naligned with the available information at each point in time.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b3aa2f4d-c4c9-4f9b-80b6-49ccc2c6b0d0', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nShorter formal Definition: Let (Ω,F,P)be a probability space. A\\nfiltration{Ft}t≥0is a family of σ-algebrasFt⊂Fsuch that for\\nall 0≤s≤t,\\nFs⊆F t.\\nExample: Consider a probability space (Ω,F,P)and a stochastic\\nprocess{Xt}t≥0, whereXtrepresents the value of a stock at time\\nt. The filtration{Ft}t≥0can be interpreted as follows:\\nF0represents the information available at the initial time\\n(e.g., initial stock price).\\nFtrepresents all the information available up to and including\\ntimet(e.g., all past stock prices up to time t).\\nImportance: Filtrations are crucial in the study of random\\nprocesses and provide a rigorous way to handle the evolution of\\ninformation and ensure that stochastic processes are properly\\naligned with the available information at each point in time.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='023ef213-ba9d-4c90-83e8-ecdbef2768c5', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nA Borel set is a set that can be formed through countable operations (such as\\ncountable unions, countable intersections, and relative complements) starting\\nfrom open sets in a given topological space. In the context of probability\\ntheory, Borel sets are crucial because they form the Borel σ-algebra, which is\\nthe smallest σ-algebra containing all open sets.Formal Definition: Given a\\ntopological space X, the Borelσ-algebraB(X)is defined as the σ-algebra\\ngenerated by the open sets of X. That is,B(X)is the smallest collection of\\nsubsets of Xthat includes all open sets and is closed under countable unions,\\ncountable intersections, and complements.\\nInRn, the Borelσ-algebraB(Rn)is generated by the open sets of Rn.\\nExamples:\\n1InR: Every open interval (a,b)is a Borel set. Every closed interval [a,b]\\nis a Borel set because it can be constructed from open intervals.\\nCountable sets (like Q, the set of rational numbers) and their\\ncomplements (like R\\\\Q, the set of irrational numbers) are Borel sets.\\n2InRn: Open balls and open rectangles are Borel sets. More complex sets\\nformed by countable unions and intersections of open sets, such as the\\nunion of countably many open balls.\\nBorel sets are important because they provide the framework within measures (like the\\nLebesgue measure) and integrals. In probability theory, random variables are typically\\ndefined to be measurable with respect to the Borel σ-algebra, ensuring that the\\npreimage of any Borel set is an event in the underlying probability space.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5684417d-2597-4db6-a098-ce36548c4b61', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nA Borel set is a set that can be formed through countable operations (such as\\ncountable unions, countable intersections, and relative complements) starting\\nfrom open sets in a given topological space. In the context of probability\\ntheory, Borel sets are crucial because they form the Borel σ-algebra, which is\\nthe smallest σ-algebra containing all open sets. Formal Definition: Given a\\ntopological space X, the Borelσ-algebraB(X)is defined as the σ-algebra\\ngenerated by the open sets of X. That is,B(X)is the smallest collection of\\nsubsets of Xthat includes all open sets and is closed under countable unions,\\ncountable intersections, and complements.\\nInRn, the Borelσ-algebraB(Rn)is generated by the open sets of Rn.Examples:\\n1InR: Every open interval (a,b)is a Borel set. Every closed interval [a,b]\\nis a Borel set because it can be constructed from open intervals.\\nCountable sets (like Q, the set of rational numbers) and their\\ncomplements (like R\\\\Q, the set of irrational numbers) are Borel sets.\\n2InRn: Open balls and open rectangles are Borel sets. More complex sets\\nformed by countable unions and intersections of open sets, such as the\\nunion of countably many open balls.\\nBorel sets are important because they provide the framework within measures (like the\\nLebesgue measure) and integrals. In probability theory, random variables are typically\\ndefined to be measurable with respect to the Borel σ-algebra, ensuring that the\\npreimage of any Borel set is an event in the underlying probability space.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a90dc3fe-076d-4cf7-9309-96356c2f40a3', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nA Borel set is a set that can be formed through countable operations (such as\\ncountable unions, countable intersections, and relative complements) starting\\nfrom open sets in a given topological space. In the context of probability\\ntheory, Borel sets are crucial because they form the Borel σ-algebra, which is\\nthe smallest σ-algebra containing all open sets. Formal Definition: Given a\\ntopological space X, the Borelσ-algebraB(X)is defined as the σ-algebra\\ngenerated by the open sets of X. That is,B(X)is the smallest collection of\\nsubsets of Xthat includes all open sets and is closed under countable unions,\\ncountable intersections, and complements.\\nInRn, the Borelσ-algebraB(Rn)is generated by the open sets of Rn.\\nExamples:\\n1InR: Every open interval (a,b)is a Borel set. Every closed interval [a,b]\\nis a Borel set because it can be constructed from open intervals.\\nCountable sets (like Q, the set of rational numbers) and their\\ncomplements (like R\\\\Q, the set of irrational numbers) are Borel sets.\\n2InRn: Open balls and open rectangles are Borel sets. More complex sets\\nformed by countable unions and intersections of open sets, such as the\\nunion of countably many open balls.\\nBorel sets are important because they provide the framework within measures (like the\\nLebesgue measure) and integrals. In probability theory, random variables are typically\\ndefined to be measurable with respect to the Borel σ-algebra, ensuring that the\\npreimage of any Borel set is an event in the underlying probability space.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b0aef8d5-77e1-4426-b48f-5331c27a3a0d', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nA Borel set is a set that can be formed through countable operations (such as\\ncountable unions, countable intersections, and relative complements) starting\\nfrom open sets in a given topological space. In the context of probability\\ntheory, Borel sets are crucial because they form the Borel σ-algebra, which is\\nthe smallest σ-algebra containing all open sets. Formal Definition: Given a\\ntopological space X, the Borelσ-algebraB(X)is defined as the σ-algebra\\ngenerated by the open sets of X. That is,B(X)is the smallest collection of\\nsubsets of Xthat includes all open sets and is closed under countable unions,\\ncountable intersections, and complements.\\nInRn, the Borelσ-algebraB(Rn)is generated by the open sets of Rn.\\nExamples:\\n1InR: Every open interval (a,b)is a Borel set. Every closed interval [a,b]\\nis a Borel set because it can be constructed from open intervals.\\nCountable sets (like Q, the set of rational numbers) and their\\ncomplements (like R\\\\Q, the set of irrational numbers) are Borel sets.\\n2InRn: Open balls and open rectangles are Borel sets. More complex sets\\nformed by countable unions and intersections of open sets, such as the\\nunion of countably many open balls.Borel sets are important because they provide the framework within measures (like the\\nLebesgue measure) and integrals. In probability theory, random variables are typically\\ndefined to be measurable with respect to the Borel σ-algebra, ensuring that the\\npreimage of any Borel set is an event in the underlying probability space.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4766088a-2484-47e2-b1d3-2d5a5816be51', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nA Borel set is a set that can be formed through countable operations (such as\\ncountable unions, countable intersections, and relative complements) starting\\nfrom open sets in a given topological space. In the context of probability\\ntheory, Borel sets are crucial because they form the Borel σ-algebra, which is\\nthe smallest σ-algebra containing all open sets. Formal Definition: Given a\\ntopological space X, the Borelσ-algebraB(X)is defined as the σ-algebra\\ngenerated by the open sets of X. That is,B(X)is the smallest collection of\\nsubsets of Xthat includes all open sets and is closed under countable unions,\\ncountable intersections, and complements.\\nInRn, the Borelσ-algebraB(Rn)is generated by the open sets of Rn.\\nExamples:\\n1InR: Every open interval (a,b)is a Borel set. Every closed interval [a,b]\\nis a Borel set because it can be constructed from open intervals.\\nCountable sets (like Q, the set of rational numbers) and their\\ncomplements (like R\\\\Q, the set of irrational numbers) are Borel sets.\\n2InRn: Open balls and open rectangles are Borel sets. More complex sets\\nformed by countable unions and intersections of open sets, such as the\\nunion of countably many open balls.\\nBorel sets are important because they provide the framework within measures (like the\\nLebesgue measure) and integrals. In probability theory, random variables are typically\\ndefined to be measurable with respect to the Borel σ-algebra, ensuring that the\\npreimage of any Borel set is an event in the underlying probability space.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a0d4f07b-866e-4b80-9c63-f37ded9cf63b', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nConsider a probability space (Ω,F,P)with a filtration{M t}t≥0,\\nthe termMt-measurable is used to describe a random variable (or\\nmore generally, a stochastic process) that is measurable with\\nrespect to the σ-algebraMt. This concept is crucial for defining\\nwhen a random variable is \"adapted\" to a given filtration, meaning\\nthat the variable’s value at time tonly depends on the information\\navailable up to that time.Definition : A random variable Xt: Ω→Rnis said to be\\nMt-measurable if, for every Borel set B⊂Rn,\\n{ω∈Ω :Xt(ω)∈B}∈M t.\\nIn other words, the preimage of any Borel set under Xtbelongs to\\ntheσ-algebraMt. This ensures that the value of Xtis determined\\nby the information contained in Mt.\\nExample: Consider a filtration {M t}t≥0and a stochastic process\\n{Xt}t≥0. IfXtrepresents the price of a stock at time t, saying that\\nXtisMt-measurable implies that the stock price at time tis fully\\ndetermined by the information available up to time t.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3d889e17-a711-40c1-9129-c1b11c8368df', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nConsider a probability space (Ω,F,P)with a filtration{M t}t≥0,\\nthe termMt-measurable is used to describe a random variable (or\\nmore generally, a stochastic process) that is measurable with\\nrespect to the σ-algebraMt. This concept is crucial for defining\\nwhen a random variable is \"adapted\" to a given filtration, meaning\\nthat the variable’s value at time tonly depends on the information\\navailable up to that time.\\nDefinition : A random variable Xt: Ω→Rnis said to be\\nMt-measurable if, for every Borel set B⊂Rn,\\n{ω∈Ω :Xt(ω)∈B}∈M t.\\nIn other words, the preimage of any Borel set under Xtbelongs to\\ntheσ-algebraMt. This ensures that the value of Xtis determined\\nby the information contained in Mt.\\nExample: Consider a filtration {M t}t≥0and a stochastic process\\n{Xt}t≥0. IfXtrepresents the price of a stock at time t, saying that\\nXtisMt-measurable implies that the stock price at time tis fully\\ndetermined by the information available up to time t.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ea3edda7-c051-420a-918d-753ee0804b12', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nDefinition 1: Let (Ω,F,P)be a probability space. A filtration\\non(Ω,F), is a familyM={M t}t≥0ofσ-algebrasMt⊂F\\nsuch that 0≤s<t⇒M s⊂M t.\\nA stochastic process {Xt}t≥0,Xt: Ω−→Rn,∀t, is called\\nadapted to the filtration {M t}if for each t≥0,Xtis\\nMt-measurable.\\nDefinition 2: A stochastic process, {Wt}t≥0,\\nWt: Ω−→Rn,∀t, defined for a filtration {M t}t≥0and\\ncharacterized by\\n1W0=0 almost surely\\n2Wt−Wsis independent ofMtandWt−Ws∼N (0,t−s)\\nis called a n-dimensional Wiener process orBrownian motion .\\nThe application t→Wt(ω)is called a sample path orrandom\\ntrajectory of the Wiener process for a fixed ω∈Ω.\\nTheorem\\nFor almost every ω∈Ω,P(Wt(ω)is nowhere differentiable ) =1.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='32d83585-9e0e-417c-8883-28552cc2c411', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nDefinition 1: Let (Ω,F,P)be a probability space. A filtration\\non(Ω,F), is a familyM={M t}t≥0ofσ-algebrasMt⊂F\\nsuch that 0≤s<t⇒M s⊂M t.\\nA stochastic process {Xt}t≥0,Xt: Ω−→Rn,∀t, is called\\nadapted to the filtration {M t}if for each t≥0,Xtis\\nMt-measurable.\\nDefinition 2: A stochastic process, {Wt}t≥0,\\nWt: Ω−→Rn,∀t, defined for a filtration {M t}t≥0and\\ncharacterized by\\n1W0=0 almost surely\\n2Wt−Wsis independent ofMtandWt−Ws∼N (0,t−s)\\nis called a n-dimensional Wiener process orBrownian motion .\\nThe application t→Wt(ω)is called a sample path orrandom\\ntrajectory of the Wiener process for a fixed ω∈Ω.\\nTheorem\\nFor almost every ω∈Ω,P(Wt(ω)is nowhere differentiable ) =1.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='35016717-f594-40a0-b9bf-07f51f22f8cf', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nAlthough the Wiener process cannot be differentiated, we can,\\nhowever, work with new processes that allow differentiation\\nwith the Wiener process. To do this, we use Ito’s integral and\\nwe define a new process.\\nLetM2be the set of random functions hverifying\\nE(∞∫\\n0h2(t)dt)\\n<+∞\\nand such that hcan be approximated by simple functions.\\nLet{Wt}t≥0be an-dimensional Wiener process w.r.t the\\nfiltration{M t}t≥0. A stochastic process {Xt}t≥0is called an\\nIto process if it can be written in the form\\nXt=X0+t∫\\n0a(s)ds+t∫\\n0b(s)dW s, (1)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0631608a-9324-4eba-a212-fa1d4de3cbae', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nAlthough the Wiener process cannot be differentiated, we can,\\nhowever, work with new processes that allow differentiation\\nwith the Wiener process. To do this, we use Ito’s integral and\\nwe define a new process.\\nLetM2be the set of random functions hverifying\\nE(∞∫\\n0h2(t)dt)\\n<+∞\\nand such that hcan be approximated by simple functions.\\nLet{Wt}t≥0be an-dimensional Wiener process w.r.t the\\nfiltration{M t}t≥0. A stochastic process {Xt}t≥0is called an\\nIto process if it can be written in the form\\nXt=X0+t∫\\n0a(s)ds+t∫\\n0b(s)dW s, (1)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a2170b15-2ec0-463d-ad93-a713eb8ed902', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nAlthough the Wiener process cannot be differentiated, we can,\\nhowever, work with new processes that allow differentiation\\nwith the Wiener process. To do this, we use Ito’s integral and\\nwe define a new process.\\nLetM2be the set of random functions hverifying\\nE(∞∫\\n0h2(t)dt)\\n<+∞\\nand such that hcan be approximated by simple functions.\\nLet{Wt}t≥0be an-dimensional Wiener process w.r.t the\\nfiltration{M t}t≥0. A stochastic process {Xt}t≥0is called an\\nIto process if it can be written in the form\\nXt=X0+t∫\\n0a(s)ds+t∫\\n0b(s)dW s, (1)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b5b6c794-a050-41ad-86fd-89c14228e6c8', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nwhereb∈M2,ais adapted to the filtration {M t}t≥0and\\n∞∫\\n0|a(t)|dt<+∞almost surely. We also write the stochastic\\nprocess in a differential form as\\ndXt=a(t)dt+b(t)dW t. (2)\\nThe Euler–Maruyama method is a numerical method used for\\napproximating solutions to stochastic differential equations\\n(SDEs). In Python, you can use the sdeintpackage to\\nimplement the Euler–Maruyama method and solve SDEs like\\nthe one given in Eq.(2).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cb4bb14a-a10a-4a05-b20a-119beff86d74', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basic elements of probability theory\\nwhereb∈M2,ais adapted to the filtration {M t}t≥0and\\n∞∫\\n0|a(t)|dt<+∞almost surely. We also write the stochastic\\nprocess in a differential form as\\ndXt=a(t)dt+b(t)dW t. (2)\\nThe Euler–Maruyama method is a numerical method used for\\napproximating solutions to stochastic differential equations\\n(SDEs). In Python, you can use the sdeintpackage to\\nimplement the Euler–Maruyama method and solve SDEs like\\nthe one given in Eq.(2).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='582080da-fd5c-446d-85e1-e6c4041408e3', embedding=None, metadata={'page_label': '15', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of stochastic neurons\\nFor example, a stochastic version of the FHN model is\\nobtained by adding two Wiener processes: W1,twith\\namplitudeσ1is added to the membrane potential vto model\\nthe synaptic noise and W2,twith amplitude σ2is added to the\\ncurrent recovery variable wto model the channel noise. The\\ntwo-dimensional Ito process associated with the FHN model is\\n{\\ndvt= (vt−v3\\nt\\n3−wt+I)dt+σ1dW1,t,\\ndwt=ε(d+vt)dt+σ2dW2,t.(3)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='43641084-7249-4b92-bc92-5740c3fb00db', embedding=None, metadata={'page_label': '16', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of stochastic neurons\\nOn the next slide, Figure (a) and (c) shows the phase\\nportraits of the random trajectory and their respective time\\nseries in (b) and (d). In both cases, the deterministic equation\\n(i.e, Eq.(4) with σ1=0 andσ2=0) is in the excitable state\\nwithd=1.05, and therefore, there is no possibility of spiking.\\nSwitching on either noise source can induce spiking activity.\\nThe smoothness of the trajectory is distorted by the presence\\nof noise as opposed to the trajectory when there is no noise.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4672ecf7-5b4a-475c-932a-ae5942452b83', embedding=None, metadata={'page_label': '17', 'file_name': 'Lecture_s13.pdf', 'file_path': '/content/data/Lecture_s13.pdf', 'file_type': 'application/pdf', 'file_size': 1048885, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of stochastic neurons\\n{\\ndvt= (vt−v3\\nt\\n3−wt+I)dt+σ1dW1,t,\\ndwt=ε(d+vt)dt+σ2dW2,t.(4)\\n(a)\\n−2 −1 0 1 2−1−0.500.511.5\\nvwσ1=0.005,  σ2=0.0 (b)\\n0 100 200 300 400 500−2−1012\\ntv,w\\n(c)\\n−2 −1 0 1 2−1−0.500.511.5\\nvwσ1=0.0,  σ2=0.005 (d)\\n0 100 200 300 400 500−2−1012\\ntv,w\\nFigure: Phase portraits in (a) and (c) and corresponding time-series in\\n(b) and (d) with vin blue and win black. d=1.05,ε=0.05,I=0.001.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='110dea56-5c14-4e98-a4ee-a6546ff2109a', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 14: Connectivity in static and adaptive neural networks.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='44c27f68-6fa4-463d-b341-9c61b7ffab6b', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives\\n1Understand how neurons connect with each other.\\n2Understand the difference between static and adaptive neural\\nnetworks\\n3Learn about biological learning algorithms.\\n4Simulate static and adaptive neural networks with and\\nwithout noise.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b995a36a-9934-4e4e-ae61-a75868092351', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of (non)adaptive neural networks\\nA. E. Pereda, Nat. Rev. Neurosci. 2014, 15, 250..\\na) Chemical synapses are by far the most prevalent and are the main players involved in excitatory\\nsynapses. The transfer of neurotransmitters from a presynaptic axon to a postsynaptic dendrite. Unlike an\\nelectrical synapse, chemical synapses are separated by a space called the synaptic cleft, typically measured\\nbetween 15 and 25 nm. In the figure, the arrival of action potential results in the activation of\\nvoltage-gated Ca+ channels, promoting the probabilistic release of neurotransmitters by exocytosis from\\nthe presynaptic membrane. The ionotropic and metabotropic receptors on the postsynaptic membrane can\\ndetect and translate the information carried by neurotransmitters into different postsynaptic behaviors,\\nvarying from changes in membrane potential to gene expression.\\nb) Electrical synapses allow direct, virtually instantaneous, and passive flow of electric current through\\nspecial intercellular connections called gap junctions. Electrical transmission is conducted by gap junctions\\n(some clusters of intercellular channels) between two adjacent cells. The transmission is bidirectional: when\\nan action potential is transmitted from pre-synapse to postsynapse, the postsynaptic resting potential\\npropagates concurrently to the pre-synapse.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3807eb9f-cde8-45e2-bd4f-b8b277b7846f', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of (non)adaptive neural networks\\nNeurons in the brain are not isolated but connect via synapses\\nin various network architectures.\\nThe synapses between two connected neurons (the\\npre-synaptic and the post-synaptic neurons) can include\\nelectrical synapses (also called gap junctions) and/or chemical\\nsynapses.\\nChemical synapses can be inhibitory or excitatory.\\nAn inhibitory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an inhibitory neuron)\\ndecreases the likelihood of spiking in the post-synaptic neuron\\n(receiving neuron).\\nAn excitatory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an excitatory neuron)\\nincreases the likelihood of spiking in the post-synaptic neuron.\\nSome common network architectures (topology) include\\nsmall-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='65a0f3bf-cf20-4af4-b0cd-4145cf4b6fac', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of (non)adaptive neural networks\\nNeurons in the brain are not isolated but connect via synapses\\nin various network architectures.\\nThe synapses between two connected neurons (the\\npre-synaptic and the post-synaptic neurons) can include\\nelectrical synapses (also called gap junctions) and/or chemical\\nsynapses.\\nChemical synapses can be inhibitory or excitatory.\\nAn inhibitory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an inhibitory neuron)\\ndecreases the likelihood of spiking in the post-synaptic neuron\\n(receiving neuron).\\nAn excitatory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an excitatory neuron)\\nincreases the likelihood of spiking in the post-synaptic neuron.\\nSome common network architectures (topology) include\\nsmall-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e58df599-b141-4298-adea-f1ee49468a9f', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of (non)adaptive neural networks\\nNeurons in the brain are not isolated but connect via synapses\\nin various network architectures.\\nThe synapses between two connected neurons (the\\npre-synaptic and the post-synaptic neurons) can include\\nelectrical synapses (also called gap junctions) and/or chemical\\nsynapses.\\nChemical synapses can be inhibitory or excitatory.\\nAn inhibitory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an inhibitory neuron)\\ndecreases the likelihood of spiking in the post-synaptic neuron\\n(receiving neuron).\\nAn excitatory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an excitatory neuron)\\nincreases the likelihood of spiking in the post-synaptic neuron.\\nSome common network architectures (topology) include\\nsmall-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9dddc6b2-ba8b-4e2e-8973-ba985f7de0fe', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of (non)adaptive neural networks\\nNeurons in the brain are not isolated but connect via synapses\\nin various network architectures.\\nThe synapses between two connected neurons (the\\npre-synaptic and the post-synaptic neurons) can include\\nelectrical synapses (also called gap junctions) and/or chemical\\nsynapses.\\nChemical synapses can be inhibitory or excitatory.\\nAn inhibitory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an inhibitory neuron)\\ndecreases the likelihood of spiking in the post-synaptic neuron\\n(receiving neuron).\\nAn excitatory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an excitatory neuron)\\nincreases the likelihood of spiking in the post-synaptic neuron.\\nSome common network architectures (topology) include\\nsmall-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7768d11c-ec79-45e1-87d9-0ae1499a7059', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of (non)adaptive neural networks\\nNeurons in the brain are not isolated but connect via synapses\\nin various network architectures.\\nThe synapses between two connected neurons (the\\npre-synaptic and the post-synaptic neurons) can include\\nelectrical synapses (also called gap junctions) and/or chemical\\nsynapses.\\nChemical synapses can be inhibitory or excitatory.\\nAn inhibitory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an inhibitory neuron)\\ndecreases the likelihood of spiking in the post-synaptic neuron\\n(receiving neuron).\\nAn excitatory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an excitatory neuron)\\nincreases the likelihood of spiking in the post-synaptic neuron.\\nSome common network architectures (topology) include\\nsmall-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b8a2177b-f75a-4220-aa08-b93beec2e978', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of (non)adaptive neural networks\\nNeurons in the brain are not isolated but connect via synapses\\nin various network architectures.\\nThe synapses between two connected neurons (the\\npre-synaptic and the post-synaptic neurons) can include\\nelectrical synapses (also called gap junctions) and/or chemical\\nsynapses.\\nChemical synapses can be inhibitory or excitatory.\\nAn inhibitory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an inhibitory neuron)\\ndecreases the likelihood of spiking in the post-synaptic neuron\\n(receiving neuron).\\nAn excitatory chemical synapse is one in which the spiking of\\nthe pre-synaptic neuron (called an excitatory neuron)\\nincreases the likelihood of spiking in the post-synaptic neuron.\\nSome common network architectures (topology) include\\nsmall-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0a911eae-48fd-4f19-a25b-7f02484cb156', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nSome common network architectures (topology) include regular\\nlattice, small-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix. Note that the Python package\\nnetworkx is a powerful library to generate, manipulate, and analyze\\ndifferent types of networks.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='771cd42a-7eae-4cf1-a730-5aef3c7d4179', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nSome common network architectures (topology) include regular\\nlattice, small-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix. Note that the Python package\\nnetworkx is a powerful library to generate, manipulate, and analyze\\ndifferent types of networks.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b917ed28-afef-4b8b-b26f-4db4db14621a', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nSome common network architectures (topology) include regular\\nlattice, small-world, random, and scale-free networks, which are\\nencoded by a connectivity matrix. Note that the Python package\\nnetworkx is a powerful library to generate, manipulate, and analyze\\ndifferent types of networks.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='513ca5c4-4cd4-4cd9-b009-fe32fa37d3d9', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nMathematically, a network of coupled neurons (e.g., the\\nFitzHugh-Nagumo neuron) can be modeled as follows:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3dvi\\ndt=(\\nvi−v3\\ni\\n3−wi+I+Ei\\ns+Ci\\ns)\\n+σs\\nidBs\\ni\\ndt,\\ndwi\\ndt=ε(vi+α−βwi) +σc\\nidBc\\ni\\ndt,(1)\\nwhere each neuron is represented by a node i=1,...,N, and the\\nfunctional dependencies Ei\\nsandCirepresent the electrical and chemical\\nsynapses, respectively, and are given by:\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3Ei\\ns=N∑\\nj=1(̸=i)AE\\nijGE\\nij[\\nvj(t−τe)−vi(t)]\\n,\\nCi\\ns=N∑\\nj=1(̸=i)AC\\nijGC\\nij(t) Γj(t)[\\nvi(t)−Vsyn]\\n,\\nΓj(t) =1\\n1+ exp[\\n−λ(\\nvj(t−τc)−Θsyn)],(2)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='076d089a-dece-4dfe-a683-f0a8ce8c7ea6', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nMathematically, a network of coupled neurons (e.g., the\\nFitzHugh-Nagumo neuron) can be modeled as follows:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3dvi\\ndt=(\\nvi−v3\\ni\\n3−wi+I+Ei\\ns+Ci\\ns)\\n+σs\\nidBs\\ni\\ndt,\\ndwi\\ndt=ε(vi+α−βwi) +σc\\nidBc\\ni\\ndt,(1)\\nwhere each neuron is represented by a node i=1,...,N, and the\\nfunctional dependencies Ei\\nsandCirepresent the electrical and chemical\\nsynapses, respectively, and are given by:\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3Ei\\ns=N∑\\nj=1(̸=i)AE\\nijGE\\nij[\\nvj(t−τe)−vi(t)]\\n,\\nCi\\ns=N∑\\nj=1(̸=i)AC\\nijGC\\nij(t) Γj(t)[\\nvi(t)−Vsyn]\\n,\\nΓj(t) =1\\n1+ exp[\\n−λ(\\nvj(t−τc)−Θsyn)],(2)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6e1bf764-19ef-4afe-9015-bc1d32c2aac4', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe membrane potential and the recovery current variables of\\nneuron iare given by vi∈Randwi∈R, respectively.\\n0<ε≪1 sets the timescale separation between the fast viand the\\nslow wi.\\nThe excitability threshold β >0 of this version of the FHN neurons\\nis a codimension-one Hopf bifurcation parameter.\\nIis an input current.\\nα∈(0,1)is a constant parameter.\\nThe Wiener processes modeling the synaptic noise term Bs\\ni\\nrepresents mean-centered Gaussian white noise with\\n⟨Bs\\ni(t)Bs\\ni(t′)⟩t=δ(t−t′)and variance (amplitude) σs\\ni, and\\nrepresents the synaptic fluctuations observed in neural networks.\\nAnd similarly, for channel noise Bc\\niis given by a mean-centered\\nGaussian white noise with ⟨Bc\\ni(t)Bc\\ni(t′)⟩t=δ(t−t′)and variance\\n(amplitude) σc\\nirepresents the random opening and closing of\\nchannel ion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='da279a4f-bf3a-404b-bcbd-4ebab9278648', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe membrane potential and the recovery current variables of\\nneuron iare given by vi∈Randwi∈R, respectively.\\n0<ε≪1 sets the timescale separation between the fast viand the\\nslow wi.\\nThe excitability threshold β >0 of this version of the FHN neurons\\nis a codimension-one Hopf bifurcation parameter.\\nIis an input current.\\nα∈(0,1)is a constant parameter.\\nThe Wiener processes modeling the synaptic noise term Bs\\ni\\nrepresents mean-centered Gaussian white noise with\\n⟨Bs\\ni(t)Bs\\ni(t′)⟩t=δ(t−t′)and variance (amplitude) σs\\ni, and\\nrepresents the synaptic fluctuations observed in neural networks.\\nAnd similarly, for channel noise Bc\\niis given by a mean-centered\\nGaussian white noise with ⟨Bc\\ni(t)Bc\\ni(t′)⟩t=δ(t−t′)and variance\\n(amplitude) σc\\nirepresents the random opening and closing of\\nchannel ion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='268f35a6-99ec-4112-b406-ece7b27b1e24', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nEi\\nsrepresent the electrical synaptic interactions between connected\\nneurons, with strength GE\\nijand time delay τe, respectively. Since\\nelectrical synapses interact only locally, the coupling mediated by\\nelectrical synapses is of diffusive type, i.e., the electrical coupling\\nterm vanishes if viandvjare equal and if the time delay is zero,\\ni.e.,τe=0.\\nCi\\nsrepresent chemical synaptic interactions between connected\\nneurons. The chemical synaptic time delay is given by τc. The\\nchemical synaptic function is modeled by a sigmoidal input-output\\nfunction, Γ(vi) =1\\n1+e−λ(vi−Θsyn), see Eq. (2), where parameter\\nλ=10.0 determines the slope of the function and Θsyn=−0.25 the\\nsynaptic firing threshold. Note there are other mathematical forms\\nof chemical synapses as you shall see in Exercise 5.\\nThe connectivity matrices AE\\nijandAC\\nij(also known as the Adjacency\\nmatrix) encode the architecture (topology) of the electrically and\\nchemically connected neurons, respectively. If neuron iis connected to\\nneuron j, then the entries {aE\\nij}=1 ({ac\\nij}=1), if not{aE\\nij}=0\\n({aC\\nij=0}). Recall that the adjacency matrices can be generated using\\nnetworkx Python package.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ec88f800-e43e-4de9-a21d-5ad81c0d85fc', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nEi\\nsrepresent the electrical synaptic interactions between connected\\nneurons, with strength GE\\nijand time delay τe, respectively. Since\\nelectrical synapses interact only locally, the coupling mediated by\\nelectrical synapses is of diffusive type, i.e., the electrical coupling\\nterm vanishes if viandvjare equal and if the time delay is zero,\\ni.e.,τe=0.\\nCi\\nsrepresent chemical synaptic interactions between connected\\nneurons. The chemical synaptic time delay is given by τc. The\\nchemical synaptic function is modeled by a sigmoidal input-output\\nfunction, Γ(vi) =1\\n1+e−λ(vi−Θsyn), see Eq. (2), where parameter\\nλ=10.0 determines the slope of the function and Θsyn=−0.25 the\\nsynaptic firing threshold. Note there are other mathematical forms\\nof chemical synapses as you shall see in Exercise 5.\\nThe connectivity matrices AE\\nijandAC\\nij(also known as the Adjacency\\nmatrix) encode the architecture (topology) of the electrically and\\nchemically connected neurons, respectively. If neuron iis connected to\\nneuron j, then the entries {aE\\nij}=1 ({ac\\nij}=1), if not{aE\\nij}=0\\n({aC\\nij=0}). Recall that the adjacency matrices can be generated using\\nnetworkx Python package.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='08c97fbd-f80c-4169-b243-b2fb7a50ca54', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nEi\\nsrepresent the electrical synaptic interactions between connected\\nneurons, with strength GE\\nijand time delay τe, respectively. Since\\nelectrical synapses interact only locally, the coupling mediated by\\nelectrical synapses is of diffusive type, i.e., the electrical coupling\\nterm vanishes if viandvjare equal and if the time delay is zero,\\ni.e.,τe=0.\\nCi\\nsrepresent chemical synaptic interactions between connected\\nneurons. The chemical synaptic time delay is given by τc. The\\nchemical synaptic function is modeled by a sigmoidal input-output\\nfunction, Γ(vi) =1\\n1+e−λ(vi−Θsyn), see Eq. (2), where parameter\\nλ=10.0 determines the slope of the function and Θsyn=−0.25 the\\nsynaptic firing threshold. Note there are other mathematical forms\\nof chemical synapses as you shall see in Exercise 5.\\nThe connectivity matrices AE\\nijandAC\\nij(also known as the Adjacency\\nmatrix) encode the architecture (topology) of the electrically and\\nchemically connected neurons, respectively. If neuron iis connected to\\nneuron j, then the entries {aE\\nij}=1 ({ac\\nij}=1), if not{aE\\nij}=0\\n({aC\\nij=0}). Recall that the adjacency matrices can be generated using\\nnetworkx Python package.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d1930422-30c3-465e-b7a8-190f8370cd54', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nVsyn<vi(t)the chemical synaptic interaction has a depolarizing\\neffect that makes the synapse inhibitory, and for Vsyn>vi(t), the\\nsynaptic interaction has a hyper-polarizing effect making the\\nsynapse excitatory.\\nThe version of the FHN neuron given in Eq.(1) above, if the\\nmembrane potentials |vi(t)|≤2.0 (i=1,2,...,N) for all time t.\\nThus, if we for example, fix Vsyn=−3.0, then the term[\\nvi(t)−Vsyn]\\nin Eq. (2) is always positive. So, the inhibitory and\\nexcitatory natures of chemical synapses will depend only on the sign\\nin front of the chemical synaptic interaction Ci\\ns.\\nTo make the chemical synapse inhibitory, we chose a negative sign\\ni.e., when the pre-synaptic neuron spikes, it prevents the\\npost-synaptic neuron from spiking, and conversely, a positive sign\\nfor excitatory chemical synapses.\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time-dependent, unlike GEwhich is constant at all times)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='421454c0-129e-41b4-9741-0e45d345cbfe', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nVsyn<vi(t)the chemical synaptic interaction has a depolarizing\\neffect that makes the synapse inhibitory, and for Vsyn>vi(t), the\\nsynaptic interaction has a hyper-polarizing effect making the\\nsynapse excitatory.\\nThe version of the FHN neuron given in Eq.(1) above, if the\\nmembrane potentials |vi(t)|≤2.0 (i=1,2,...,N) for all time t.\\nThus, if we for example, fix Vsyn=−3.0, then the term[\\nvi(t)−Vsyn]\\nin Eq. (2) is always positive. So, the inhibitory and\\nexcitatory natures of chemical synapses will depend only on the sign\\nin front of the chemical synaptic interaction Ci\\ns.\\nTo make the chemical synapse inhibitory, we chose a negative sign\\ni.e., when the pre-synaptic neuron spikes, it prevents the\\npost-synaptic neuron from spiking, and conversely, a positive sign\\nfor excitatory chemical synapses.\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time-dependent, unlike GEwhich is constant at all times)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8d55dcad-bd5e-48bc-8b54-d22397b9691e', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nVsyn<vi(t)the chemical synaptic interaction has a depolarizing\\neffect that makes the synapse inhibitory, and for Vsyn>vi(t), the\\nsynaptic interaction has a hyper-polarizing effect making the\\nsynapse excitatory.\\nThe version of the FHN neuron given in Eq.(1) above, if the\\nmembrane potentials |vi(t)|≤2.0 (i=1,2,...,N) for all time t.\\nThus, if we for example, fix Vsyn=−3.0, then the term[\\nvi(t)−Vsyn]\\nin Eq. (2) is always positive. So, the inhibitory and\\nexcitatory natures of chemical synapses will depend only on the sign\\nin front of the chemical synaptic interaction Ci\\ns.\\nTo make the chemical synapse inhibitory, we chose a negative sign\\ni.e., when the pre-synaptic neuron spikes, it prevents the\\npost-synaptic neuron from spiking, and conversely, a positive sign\\nfor excitatory chemical synapses.\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time-dependent, unlike GEwhich is constant at all times)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e0f484a4-9ac1-42dc-8928-3feb7d911dc6', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nVsyn<vi(t)the chemical synaptic interaction has a depolarizing\\neffect that makes the synapse inhibitory, and for Vsyn>vi(t), the\\nsynaptic interaction has a hyper-polarizing effect making the\\nsynapse excitatory.\\nThe version of the FHN neuron given in Eq.(1) above, if the\\nmembrane potentials |vi(t)|≤2.0 (i=1,2,...,N) for all time t.\\nThus, if we for example, fix Vsyn=−3.0, then the term[\\nvi(t)−Vsyn]\\nin Eq. (2) is always positive. So, the inhibitory and\\nexcitatory natures of chemical synapses will depend only on the sign\\nin front of the chemical synaptic interaction Ci\\ns.\\nTo make the chemical synapse inhibitory, we chose a negative sign\\ni.e., when the pre-synaptic neuron spikes, it prevents the\\npost-synaptic neuron from spiking, and conversely, a positive sign\\nfor excitatory chemical synapses.\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time-dependent, unlike GEwhich is constant at all times)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='950f3801-2f02-4785-8550-08f24543dda9', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time dependent, unlike GE\\nijwhich is constant at all times).\\nThe modification of the chemical synaptic strength over time is\\ndone via Hebbian learning algorithms called spike-timing-dependent\\nplasticity (STDP).\\nSTDP refers to the ability of certain types of synapses to modify\\ntheir strength based on the relative timing of pre-and postsynaptic\\nspikes. This phenomenon is commonly observed in chemical\\nsynapses, where the release and reception of neurotransmitters play\\na crucial role.\\nElectrical synapses do not exhibit STDP (that is why GE\\nijis\\ntime-independent and constant) like chemical synapses do (that is\\nwhyGC\\nijis time-dependent, i.e., GC\\nij(t)).\\nWhile electrical synapses do not exhibit STDP, they contribute to\\nvarious important functions in the nervous system, including the\\nsynchronization of neuronal activity, the spread of electrical signals,\\nand the coordination of network activity.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4cf1488a-d174-452f-ae88-2230be4a9ae6', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time dependent, unlike GE\\nijwhich is constant at all times).\\nThe modification of the chemical synaptic strength over time is\\ndone via Hebbian learning algorithms called spike-timing-dependent\\nplasticity (STDP).\\nSTDP refers to the ability of certain types of synapses to modify\\ntheir strength based on the relative timing of pre-and postsynaptic\\nspikes. This phenomenon is commonly observed in chemical\\nsynapses, where the release and reception of neurotransmitters play\\na crucial role.\\nElectrical synapses do not exhibit STDP (that is why GE\\nijis\\ntime-independent and constant) like chemical synapses do (that is\\nwhyGC\\nijis time-dependent, i.e., GC\\nij(t)).\\nWhile electrical synapses do not exhibit STDP, they contribute to\\nvarious important functions in the nervous system, including the\\nsynchronization of neuronal activity, the spread of electrical signals,\\nand the coordination of network activity.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3e4fb2ad-5c9e-49fe-8877-700566e08301', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time dependent, unlike GE\\nijwhich is constant at all times).\\nThe modification of the chemical synaptic strength over time is\\ndone via Hebbian learning algorithms called spike-timing-dependent\\nplasticity (STDP).\\nSTDP refers to the ability of certain types of synapses to modify\\ntheir strength based on the relative timing of pre-and postsynaptic\\nspikes. This phenomenon is commonly observed in chemical\\nsynapses, where the release and reception of neurotransmitters play\\na crucial role.\\nElectrical synapses do not exhibit STDP (that is why GE\\nijis\\ntime-independent and constant) like chemical synapses do (that is\\nwhyGC\\nijis time-dependent, i.e., GC\\nij(t)).\\nWhile electrical synapses do not exhibit STDP, they contribute to\\nvarious important functions in the nervous system, including the\\nsynchronization of neuronal activity, the spread of electrical signals,\\nand the coordination of network activity.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='91c0ab8f-4b85-4c19-afac-64e5f1736d01', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time dependent, unlike GE\\nijwhich is constant at all times).\\nThe modification of the chemical synaptic strength over time is\\ndone via Hebbian learning algorithms called spike-timing-dependent\\nplasticity (STDP).\\nSTDP refers to the ability of certain types of synapses to modify\\ntheir strength based on the relative timing of pre-and postsynaptic\\nspikes. This phenomenon is commonly observed in chemical\\nsynapses, where the release and reception of neurotransmitters play\\na crucial role.\\nElectrical synapses do not exhibit STDP (that is why GE\\nijis\\ntime-independent and constant) like chemical synapses do (that is\\nwhyGC\\nijis time-dependent, i.e., GC\\nij(t)).\\nWhile electrical synapses do not exhibit STDP, they contribute to\\nvarious important functions in the nervous system, including the\\nsynchronization of neuronal activity, the spread of electrical signals,\\nand the coordination of network activity.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0cc1eeba-1391-4750-9fe4-fa1d0de4d384', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe strength of the chemical synapses is represented by GC\\nij(t)\\n(which is time dependent, unlike GE\\nijwhich is constant at all times).\\nThe modification of the chemical synaptic strength over time is\\ndone via Hebbian learning algorithms called spike-timing-dependent\\nplasticity (STDP).\\nSTDP refers to the ability of certain types of synapses to modify\\ntheir strength based on the relative timing of pre-and postsynaptic\\nspikes. This phenomenon is commonly observed in chemical\\nsynapses, where the release and reception of neurotransmitters play\\na crucial role.\\nElectrical synapses do not exhibit STDP (that is why GE\\nijis\\ntime-independent and constant) like chemical synapses do (that is\\nwhyGC\\nijis time-dependent, i.e., GC\\nij(t)).\\nWhile electrical synapses do not exhibit STDP, they contribute to\\nvarious important functions in the nervous system, including the\\nsynchronization of neuronal activity, the spread of electrical signals,\\nand the coordination of network activity.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a694eb0f-76bb-4004-adf9-79b565f48976', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe weight of the synaptic connection from the pre-synaptic jth neuron\\nto the post-synaptic ith neuron is represented by GC\\nij(t). With increasing\\ntime t, the synaptic strength GC\\nij(t)for each synapse is updated with a\\nnearest-spike pair-based STDP rule.\\nIn simulations, to prevent unbounded growth, negative conductances (i.e.,\\nnegative coupling strength), and elimination of synapses (i.e.,\\nGC\\nij(t) =0), we usually set a range with the lower and upper bounds,\\ne.g., GC\\nij(t)∈[GC\\nmin,GC\\nmax] = [0.0001,1.0].\\nThen, the synapses are updated according to additive (state-independent)\\nupdate rule, where the coupling weights are changed relative to their\\ncurrent values as:\\nGC\\nij(t)→GC\\nij(t) +λ∆GC\\nij(∆tij). (3)\\nOr the synapses are updated according to multiplicative\\n(state-dependent) update rule, where the coupling weights are changed\\nrelative to their current values as:\\nGC\\nij(t)→GC\\nij(t) +λ(GC\\n0−GC\\nij(t))|∆GC\\nij(∆tij)|, (4)\\nwhere GC\\n0=GC\\nmaxorGC\\n0=GC\\nmindepending on whether the coupling\\nupdate ∆GC\\nij(∆tij)is positive (LTP) or negative (LTD), respectively.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='359bd5b0-5953-4243-8f0c-fe86bf7d0eb2', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe weight of the synaptic connection from the pre-synaptic jth neuron\\nto the post-synaptic ith neuron is represented by GC\\nij(t). With increasing\\ntime t, the synaptic strength GC\\nij(t)for each synapse is updated with a\\nnearest-spike pair-based STDP rule.\\nIn simulations, to prevent unbounded growth, negative conductances (i.e.,\\nnegative coupling strength), and elimination of synapses (i.e.,\\nGC\\nij(t) =0), we usually set a range with the lower and upper bounds,\\ne.g., GC\\nij(t)∈[GC\\nmin,GC\\nmax] = [0.0001,1.0].\\nThen, the synapses are updated according to additive (state-independent)\\nupdate rule, where the coupling weights are changed relative to their\\ncurrent values as:\\nGC\\nij(t)→GC\\nij(t) +λ∆GC\\nij(∆tij). (3)\\nOr the synapses are updated according to multiplicative\\n(state-dependent) update rule, where the coupling weights are changed\\nrelative to their current values as:\\nGC\\nij(t)→GC\\nij(t) +λ(GC\\n0−GC\\nij(t))|∆GC\\nij(∆tij)|, (4)\\nwhere GC\\n0=GC\\nmaxorGC\\n0=GC\\nmindepending on whether the coupling\\nupdate ∆GC\\nij(∆tij)is positive (LTP) or negative (LTD), respectively.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2b512060-b8a8-47da-b2de-7c16eb79a089', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe weight of the synaptic connection from the pre-synaptic jth neuron\\nto the post-synaptic ith neuron is represented by GC\\nij(t). With increasing\\ntime t, the synaptic strength GC\\nij(t)for each synapse is updated with a\\nnearest-spike pair-based STDP rule.\\nIn simulations, to prevent unbounded growth, negative conductances (i.e.,\\nnegative coupling strength), and elimination of synapses (i.e.,\\nGC\\nij(t) =0), we usually set a range with the lower and upper bounds,\\ne.g., GC\\nij(t)∈[GC\\nmin,GC\\nmax] = [0.0001,1.0].\\nThen, the synapses are updated according to additive (state-independent)\\nupdate rule, where the coupling weights are changed relative to their\\ncurrent values as:\\nGC\\nij(t)→GC\\nij(t) +λ∆GC\\nij(∆tij). (3)\\nOr the synapses are updated according to multiplicative\\n(state-dependent) update rule, where the coupling weights are changed\\nrelative to their current values as:\\nGC\\nij(t)→GC\\nij(t) +λ(GC\\n0−GC\\nij(t))|∆GC\\nij(∆tij)|, (4)\\nwhere GC\\n0=GC\\nmaxorGC\\n0=GC\\nmindepending on whether the coupling\\nupdate ∆GC\\nij(∆tij)is positive (LTP) or negative (LTD), respectively.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='eb92d43e-8d24-49ff-8a95-47891dc7f1fc', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe weight of the synaptic connection from the pre-synaptic jth neuron\\nto the post-synaptic ith neuron is represented by GC\\nij(t). With increasing\\ntime t, the synaptic strength GC\\nij(t)for each synapse is updated with a\\nnearest-spike pair-based STDP rule.\\nIn simulations, to prevent unbounded growth, negative conductances (i.e.,\\nnegative coupling strength), and elimination of synapses (i.e.,\\nGC\\nij(t) =0), we usually set a range with the lower and upper bounds,\\ne.g., GC\\nij(t)∈[GC\\nmin,GC\\nmax] = [0.0001,1.0].\\nThen, the synapses are updated according to additive (state-independent)\\nupdate rule, where the coupling weights are changed relative to their\\ncurrent values as:\\nGC\\nij(t)→GC\\nij(t) +λ∆GC\\nij(∆tij). (3)\\nOr the synapses are updated according to multiplicative\\n(state-dependent) update rule, where the coupling weights are changed\\nrelative to their current values as:\\nGC\\nij(t)→GC\\nij(t) +λ(GC\\n0−GC\\nij(t))|∆GC\\nij(∆tij)|, (4)\\nwhere GC\\n0=GC\\nmaxorGC\\n0=GC\\nmindepending on whether the coupling\\nupdate ∆GC\\nij(∆tij)is positive (LTP) or negative (LTD), respectively.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1eb70a80-14c5-4a52-8db5-a016dd90a387', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nNotice that in Eq.(4) we have absolute value on ∆GC\\nij(∆tij). Hence, ∆GC\\nij(∆tij)\\ncan be positive or negative. If ∆GC\\nij(∆tij)>0⇒GC\\n0=GC\\nmaxand if\\n∆GC\\nij(∆tij)<0⇒GC\\n0=GC\\nmin.\\nIn the context of synaptic plasticity, one will investigate (and compare the\\neffects) both multiplicative and additive STDP, where the coupling update\\neither depends or not, respectively, on the current value of the synaptic weights\\nGC\\nij(t)and leads to “soft” or “hard” bounds, accordingly.\\nSoft Bounds\\nMeaning : Soft bounds imply that the update to the synaptic\\nweights is dependent on the current value of the weights. This\\ntypically results in more gradual changes as the weight\\napproaches its maximum or minimum value.\\nMechanism : In multiplicative spike-timing-dependent\\nplasticity (STDP), the amount of change (LTP or LTD) is\\nproportional to the current weight value. This results in a form\\nof feedback that naturally limits the weights, making it harder\\nfor them to reach extreme values.\\nEffect: The synaptic weights tend to approach their bounds\\nasymptotically, meaning they slow down as they get closer to\\nthe maximum or minimum allowed values.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='57675de8-157e-41fe-9e25-fa914ec1902f', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nNotice that in Eq.(4) we have absolute value on ∆GC\\nij(∆tij). Hence, ∆GC\\nij(∆tij)\\ncan be positive or negative. If ∆GC\\nij(∆tij)>0⇒GC\\n0=GC\\nmaxand if\\n∆GC\\nij(∆tij)<0⇒GC\\n0=GC\\nmin.\\nIn the context of synaptic plasticity, one will investigate (and compare the\\neffects) both multiplicative and additive STDP, where the coupling update\\neither depends or not, respectively, on the current value of the synaptic weights\\nGC\\nij(t)and leads to “soft” or “hard” bounds, accordingly.\\nSoft Bounds\\nMeaning : Soft bounds imply that the update to the synaptic\\nweights is dependent on the current value of the weights. This\\ntypically results in more gradual changes as the weight\\napproaches its maximum or minimum value.\\nMechanism : In multiplicative spike-timing-dependent\\nplasticity (STDP), the amount of change (LTP or LTD) is\\nproportional to the current weight value. This results in a form\\nof feedback that naturally limits the weights, making it harder\\nfor them to reach extreme values.\\nEffect: The synaptic weights tend to approach their bounds\\nasymptotically, meaning they slow down as they get closer to\\nthe maximum or minimum allowed values.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0da9ce14-b9af-4bc8-8b3e-e1b6d46c39b3', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nNotice that in Eq.(4) we have absolute value on ∆GC\\nij(∆tij). Hence, ∆GC\\nij(∆tij)\\ncan be positive or negative. If ∆GC\\nij(∆tij)>0⇒GC\\n0=GC\\nmaxand if\\n∆GC\\nij(∆tij)<0⇒GC\\n0=GC\\nmin.\\nIn the context of synaptic plasticity, one will investigate (and compare the\\neffects) both multiplicative and additive STDP, where the coupling update\\neither depends or not, respectively, on the current value of the synaptic weights\\nGC\\nij(t)and leads to “soft” or “hard” bounds, accordingly.\\nSoft Bounds\\nMeaning : Soft bounds imply that the update to the synaptic\\nweights is dependent on the current value of the weights. This\\ntypically results in more gradual changes as the weight\\napproaches its maximum or minimum value.\\nMechanism : In multiplicative spike-timing-dependent\\nplasticity (STDP), the amount of change (LTP or LTD) is\\nproportional to the current weight value. This results in a form\\nof feedback that naturally limits the weights, making it harder\\nfor them to reach extreme values.\\nEffect: The synaptic weights tend to approach their bounds\\nasymptotically, meaning they slow down as they get closer to\\nthe maximum or minimum allowed values.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c4b8577a-dde8-4428-ae9e-c223e34cf8ce', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nHard Bounds\\nMeaning : Hard bounds imply that the synaptic weights are\\ndirectly capped at certain maximum or minimum values,\\nregardless of their current value.\\nMechanism : In additive STDP, the updates to the synaptic\\nweights are fixed and do not depend on the current weight\\nvalue. If the update pushes the weight beyond the set bounds,\\nit is clipped to the boundary value.\\nEffect: The synaptic weights can change rapidly until they hit\\nthe maximum or minimum value, at which point they are\\nstrictly limited and cannot exceed these bounds.\\nGC\\nij(t)→GC\\nij(t) +λ(GC\\n0−GC\\nij(t))|∆GC\\nij(∆tij)|, (5)\\nGC\\n0is either GC\\nmaxorGC\\nmin, indicating the maximum or minimum bound.\\nThe termλ(GC\\n0−GC\\nij(t))suggests a dependency on the current value of\\nGC\\nij, which is characteristic of a soft bound.\\nConversely, if the update ∆GC\\nij(∆tij)were independent of GC\\nij, it would be more\\nindicative of hard bounds, where the changes are made directly and limits are\\nimposed strictly when the bounds are reached.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='af1364db-7241-4bc2-b417-014522a577a4', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nHard Bounds\\nMeaning : Hard bounds imply that the synaptic weights are\\ndirectly capped at certain maximum or minimum values,\\nregardless of their current value.\\nMechanism : In additive STDP, the updates to the synaptic\\nweights are fixed and do not depend on the current weight\\nvalue. If the update pushes the weight beyond the set bounds,\\nit is clipped to the boundary value.\\nEffect: The synaptic weights can change rapidly until they hit\\nthe maximum or minimum value, at which point they are\\nstrictly limited and cannot exceed these bounds.\\nGC\\nij(t)→GC\\nij(t) +λ(GC\\n0−GC\\nij(t))|∆GC\\nij(∆tij)|, (5)\\nGC\\n0is either GC\\nmaxorGC\\nmin, indicating the maximum or minimum bound.\\nThe termλ(GC\\n0−GC\\nij(t))suggests a dependency on the current value of\\nGC\\nij, which is characteristic of a soft bound.\\nConversely, if the update ∆GC\\nij(∆tij)were independent of GC\\nij, it would be more\\nindicative of hard bounds, where the changes are made directly and limits are\\nimposed strictly when the bounds are reached.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cfa41598-12e7-4501-85cf-1c076e2f63e7', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nHard Bounds\\nMeaning : Hard bounds imply that the synaptic weights are\\ndirectly capped at certain maximum or minimum values,\\nregardless of their current value.\\nMechanism : In additive STDP, the updates to the synaptic\\nweights are fixed and do not depend on the current weight\\nvalue. If the update pushes the weight beyond the set bounds,\\nit is clipped to the boundary value.\\nEffect: The synaptic weights can change rapidly until they hit\\nthe maximum or minimum value, at which point they are\\nstrictly limited and cannot exceed these bounds.GC\\nij(t)→GC\\nij(t) +λ(GC\\n0−GC\\nij(t))|∆GC\\nij(∆tij)|, (5)\\nGC\\n0is either GC\\nmaxorGC\\nmin, indicating the maximum or minimum bound.\\nThe termλ(GC\\n0−GC\\nij(t))suggests a dependency on the current value of\\nGC\\nij, which is characteristic of a soft bound.\\nConversely, if the update ∆GC\\nij(∆tij)were independent of GC\\nij, it would be more\\nindicative of hard bounds, where the changes are made directly and limits are\\nimposed strictly when the bounds are reached.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d01f5ea9-fde2-45b2-ae12-c3f33ce3654a', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nHard Bounds\\nMeaning : Hard bounds imply that the synaptic weights are\\ndirectly capped at certain maximum or minimum values,\\nregardless of their current value.\\nMechanism : In additive STDP, the updates to the synaptic\\nweights are fixed and do not depend on the current weight\\nvalue. If the update pushes the weight beyond the set bounds,\\nit is clipped to the boundary value.\\nEffect: The synaptic weights can change rapidly until they hit\\nthe maximum or minimum value, at which point they are\\nstrictly limited and cannot exceed these bounds.\\nGC\\nij(t)→GC\\nij(t) +λ(GC\\n0−GC\\nij(t))|∆GC\\nij(∆tij)|, (5)\\nGC\\n0is either GC\\nmaxorGC\\nmin, indicating the maximum or minimum bound.\\nThe termλ(GC\\n0−GC\\nij(t))suggests a dependency on the current value of\\nGC\\nij, which is characteristic of a soft bound.\\nConversely, if the update ∆GC\\nij(∆tij)were independent of GC\\nij, it would be more\\nindicative of hard bounds, where the changes are made directly and limits are\\nimposed strictly when the bounds are reached.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e81e01de-edba-4814-9671-8bfb5755b8e3', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe parameter λrepresents the learning rate. It was found experimentally\\nthat small learning rates led to more robust learning. Hence, in\\nsimulations, we usually choose a small learning rate (i.e., λ=0.0001)\\nwhich, by the way, also simulates the effect of STDP on the long-term\\nevolution of the neural networks.\\nIn simulations, we usually consider that the STDP update rules are not\\napplied to connections that are initially non-existent, i.e., we do not\\nconsider the creation of synapses. Moreover, if neurons are disconnected,\\nthey will remain disconnected throughout the total simulation time (there\\nis no rewiring of synapses). However, when the neural network topology\\nbecomes time-varying, these assumptions may no longer be true, in which\\ncase appropriate assumptions have to be considered.\\nThe biological learning rule, i.e., the synaptic modification ∆GC\\nij(∆tij)\\ndepends on the relative time difference ∆tij= (t(post )\\ni−t(pre)\\nj)between\\nthe nearest-spike times of the post-synaptic neuron iand the pre-synaptic\\nneuron j.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a632981c-fa73-4a4c-ac8c-7cb3ad39dd84', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe parameter λrepresents the learning rate. It was found experimentally\\nthat small learning rates led to more robust learning. Hence, in\\nsimulations, we usually choose a small learning rate (i.e., λ=0.0001)\\nwhich, by the way, also simulates the effect of STDP on the long-term\\nevolution of the neural networks.\\nIn simulations, we usually consider that the STDP update rules are not\\napplied to connections that are initially non-existent, i.e., we do not\\nconsider the creation of synapses. Moreover, if neurons are disconnected,\\nthey will remain disconnected throughout the total simulation time (there\\nis no rewiring of synapses). However, when the neural network topology\\nbecomes time-varying, these assumptions may no longer be true, in which\\ncase appropriate assumptions have to be considered.\\nThe biological learning rule, i.e., the synaptic modification ∆GC\\nij(∆tij)\\ndepends on the relative time difference ∆tij= (t(post )\\ni−t(pre)\\nj)between\\nthe nearest-spike times of the post-synaptic neuron iand the pre-synaptic\\nneuron j.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e6a45a7e-1bd3-486d-8d7a-252ea5827b2f', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe parameter λrepresents the learning rate. It was found experimentally\\nthat small learning rates led to more robust learning. Hence, in\\nsimulations, we usually choose a small learning rate (i.e., λ=0.0001)\\nwhich, by the way, also simulates the effect of STDP on the long-term\\nevolution of the neural networks.\\nIn simulations, we usually consider that the STDP update rules are not\\napplied to connections that are initially non-existent, i.e., we do not\\nconsider the creation of synapses. Moreover, if neurons are disconnected,\\nthey will remain disconnected throughout the total simulation time (there\\nis no rewiring of synapses). However, when the neural network topology\\nbecomes time-varying, these assumptions may no longer be true, in which\\ncase appropriate assumptions have to be considered.\\nThe biological learning rule, i.e., the synaptic modification ∆GC\\nij(∆tij)\\ndepends on the relative time difference ∆tij= (t(post )\\ni−t(pre)\\nj)between\\nthe nearest-spike times of the post-synaptic neuron iand the pre-synaptic\\nneuron j.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cd63abec-6514-4c8a-b2d5-8c35b249a2bc', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe STDP learning rule can be excitatory (we talk of eSTDP) with\\nan asymmetric Hebbian time window for the synaptic modification\\n∆GC\\nij(∆tij)given by:\\n∆GC\\nij(∆tij) =\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3A1e−∆tij/τ1,if∆tij>0\\n−A2e∆tij/τ2,if∆tij<0\\n0,if∆tij=0, (6)where long-term potentiation (LTP — strengthening of synapses) occurs\\nfor∆tij>0 (i.e., a post-synaptic spike follows a pre-synaptic spike),\\nlong-term depression (LTD — weakening of synapses) occurs for ∆tij<0\\n(i.e., a post-synaptic spike precedes a pre-synaptic spike), and no\\nsynaptic modifications for ∆tij=0 (i.e., a post-synaptic spike coincides a\\npre-synaptic spike). The amount of synaptic modification (i.e.,\\nstrengthening or weakening) is limited by the adjusting rate potentiation\\nparameter A1, adjusting rate depression parameter A2, and their\\nrespective temporal window for synaptic modification τ1andτ2.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e590c551-ad11-4f6d-8db6-861e09146a99', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe STDP learning rule can be excitatory (we talk of eSTDP) with\\nan asymmetric Hebbian time window for the synaptic modification\\n∆GC\\nij(∆tij)given by:\\n∆GC\\nij(∆tij) =\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3A1e−∆tij/τ1,if∆tij>0\\n−A2e∆tij/τ2,if∆tij<0\\n0,if∆tij=0, (6)\\nwhere long-term potentiation (LTP — strengthening of synapses) occurs\\nfor∆tij>0 (i.e., a post-synaptic spike follows a pre-synaptic spike),\\nlong-term depression (LTD — weakening of synapses) occurs for ∆tij<0\\n(i.e., a post-synaptic spike precedes a pre-synaptic spike), and no\\nsynaptic modifications for ∆tij=0 (i.e., a post-synaptic spike coincides a\\npre-synaptic spike). The amount of synaptic modification (i.e.,\\nstrengthening or weakening) is limited by the adjusting rate potentiation\\nparameter A1, adjusting rate depression parameter A2, and their\\nrespective temporal window for synaptic modification τ1andτ2.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='edce6154-eabd-4a6e-b9d2-98c56c7d9a0f', embedding=None, metadata={'page_label': '15', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe Figure below shows the asymmetric Hebbian time window of\\neSTDP for the synaptic modification ∆GC\\nij(∆tij)given by Eq.(6).\\nWe see in both cases that ∆GC\\nijvaries, depending on the relative\\ntime difference ∆tijbetween the nearest spike times of the\\npost-synaptic neuron iand the pre-synaptic neuron j.\\n-200 -100 0 100 200\\ntij-0.500.51GCij\\nFigure: Plot of synaptic modification ∆GC\\nijversus ∆tijfor eSTDP. The\\nblue and red curves represent LTP and LTD, respectively. A1=1.0,\\nA2=0.5,τ1=20.0,τ2=20.0.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a7a79acb-9fae-48cf-ab93-af4391ec631a', embedding=None, metadata={'page_label': '16', 'file_name': 'Lecture_s14.pdf', 'file_path': '/content/data/Lecture_s14.pdf', 'file_type': 'application/pdf', 'file_size': 1276796, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Mathematical modeling of adaptive neural networks\\nThe STDP learning rule can be inhibitory (we talk of iSTDP) with\\nan asymmetric anti-Hebbian time window for the synaptic\\nmodification ∆GC\\nij(∆tij)given by:\\n∆GC\\nij(∆tij) =\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f3−A1e−∆tij/τ1,if∆tij>0\\n−A2∆tij\\nτ2e∆tij/τ2,if∆tij<0,\\n0,if∆tij=0(7)\\nin which, when ∆tij>0, LTD occurs, while LTP occurs in the case\\nof∆tij<0, in contrast to the Hebbian time window for the\\nexcitatory STDP (eSTDP) where LTP (LTD) occurs for\\n∆tij>(<)0. The amount of synaptic modification (i.e.,\\nstrengthening or weakening) is limited by the adjusting rate\\npotentiation parameter A2, adjusting rate depression parameter A1,\\nand their respective temporal window for synaptic modification τ2\\nandτ1. Please make sure you get the differences between eSTDP\\nand iSTDP.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a0170211-9915-4e70-9c9e-52bdf8dc9bdc', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 15: STDP revisited and synchronization in neural networks.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='29d38cb4-91b4-4f2d-90c9-a52eadfc3f87', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives\\n1Further explain the STDP learning rule\\n2Understand synchronization dynamics in neurons\\n3Learn how to measure the degree of synchronization\\n4Determine whether a synchronized state is stable or unstable\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='699805ab-030c-4a69-9228-1c0d86533ebd', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Further explanation of STDP learning rule\\nThe nearest-spike Pair-based STDP rule focuses on the changes in\\nsynaptic strength driven by the precise timing of the closest spikes\\nbetween the pre-synaptic and post-synaptic neurons.\\nKey features of the nearest-spike pair-based STDP rule:\\nFor each spike from the pre-synaptic neuron j, the nearest\\npreceding or following spike from the post-synaptic neuron iis\\nconsidered.\\nFor each spike from the post-synaptic neuron i, the nearest\\npreceding or following spike from the pre-synaptic neuron jis\\nconsidered.\\nIn the context of the nearest-spike pair-based STDP rule,\\n\"preceding or following\" refers to the temporal relationship\\nbetween the spikes of the pre-synaptic and post-synaptic\\nneurons. Specifically:\\nPreceding spike: A spike that occurs before the current spike\\nunder consideration.\\nFollowing spike: A spike that occurs after the current spike\\nunder consideration.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d2c1c0ee-cac7-4b17-8052-c27c48fa4360', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Further explanation of STDP learning rule\\nNow, in other words, I explain the identifying nearest spikes:\\nFor a given spike at time tof the pre-synaptic neuron j, the nearest\\npost-synaptic spike of neuron iis found by identifying the spike that\\noccurs closest in time, whether it is before or after the time t.\\nSimilarly, for a spike at time tin the post-synaptic neuron i, the\\nnearest pre-synaptic spike of neuron jis found.\\nNumerically, in your simulations the nearest-spike pair-based\\nSTDP rule is implemented as:\\nFor each spike from the pre-synaptic neuron j:Identify the\\nnearest spike from the post-synaptic neuron i. This nearest\\nspike can either be the one that occurs immediately before\\n(preceding) or immediately after (following) the pre-synaptic\\nspike of neuron j.\\nFor each spike from the post-synaptic neuron i:Identify\\nthe nearest spike from the pre-synaptic neuron j. This nearest\\nspike can either be the one that occurs immediately before\\n(preceding) or immediately after (following) the post-synaptic\\nspike.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='894b1e24-2fb5-49c8-999a-f7e33c911f83', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Further explanation of STDP learning rule\\nCalculating Timing Differences: Once the nearest spike pairs are\\nidentified, the timing difference ∆tij=t(post)\\ni−t(pre)\\njis calculated\\nfor each pair. The sign of this timing difference determines whether\\nthe synaptic change will be potentiation or depression.\\nApplying STDP Rule: Only these nearest pairs are used to update\\nthe synaptic strength ∆GC\\nij(t). The magnitude of the synaptic\\nchange is then computed using the STDP rule, that is eSTDP in\\nEq.(6) or iSTDP in Eq.(7) given in the slides of Lecture 14.\\nSo keep in mind that the nearest-spike pair-based STDP rule simplifies\\nthe synaptic update mechanism by considering only the closest spikes,\\nmaking it computationally efficient while capturing the core dynamics of\\nsynaptic plasticity driven by precise spike timing.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='86e1370f-687d-49fb-a913-1fb6fb4faf01', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Synchronization in neurons\\nSynchronization is a widespread phenomenon in complex systems\\nincluding the brain.\\nDefinition: Synchronization phenomena are processes wherein many\\ndynamical systems adjust a given property (e.g., amplitude, phase,\\nfrequency, and even membrane potential in coupled neurons) of their\\nmotion due to suitable coupling configurations.\\nIn the brain, they can emerge from the collaboration between neurons or\\nneural networks and significantly affect all neurons and network\\nfunctioning.\\nIt is well-established that synchronization of neural activity within and\\nacross brain regions promotes normal physiological functioning, such as\\nthe precise temporal coordination of processes underlying cognition,\\nworking memory, and perception. However, synchronization of neural\\nactivity is also well known to be responsible for some pathological\\nbehaviors such as epilepsy, Parkinson’s, and Alzheimer’s. Thus,\\nunderstanding synchronization is of engineering and medical importance.\\nIt has been shown that changes in the strength of the synaptic coupling\\nand the connectivity of the neurons could lead to epileptic-like\\nsynchronization behaviors.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='36216ab8-460a-43cf-91e2-dfc48a37637e', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural synchronization problem\\nConsider the following network of NFitzHugh-Nagumo (FHN) neurons\\ncoupled via gap junctions (i.e., via electrical synapses):\\n\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3dvi\\ndt=vi(a−vi)(vi−1)−wi+Iext+N∑\\nj=1Ge\\nij(vj−vi)\\ndwi\\ndt=ε(bvi−cwi),(1)\\nwhere vi=vi(t)∈Randwi=wi(t)∈Rrepresent the fast membrane\\npotential and slow recovery current variables of the FHN neuron,\\nrespectively; the index i=1, ...,Nstands for neuron (nodes) in the\\nnetwork; Ge>0 is the coupling strength between pairs of neurons in the\\nnetwork; b,c>0 0< ε≪1 are constant parameters, excitability\\nparameter is 0 <a<1, the external inputs are Iext≥0, and the synaptic\\ncoupling strength between neuron iand neuron jisGe\\nij≥0.\\nNotice that the network is a complete graph, i.e., there is a direct\\nconnection (or edge or synapse) between every pair of nodes (neurons),\\nbut there are no self-loops.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='162f8e6e-f40e-4645-b9f1-8ea665b77cf8', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural complete synchronization problem\\nFor the sake of simplicity, let’s study the phenomenon of complete\\nsynchronization within the smallest network, i.e., when the network size in\\nEq. (1) is given by N=2. In this case, we rewrite Eq. (1) as\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3dv1\\ndt=v1(a−v1)(v1−1)−w1+Iext+Ge\\n12(v2−v1)\\ndw1\\ndt=ε(bv1−cw1),\\ndv1\\ndt=v2(a−v2)(v2−1)−w2+Iext−Ge\\n21(v2−v1)\\ndw2\\ndt=ε(bv2−cw2),(2)\\nNotice that the coupling strength between neuron 1 and neuron 2 is\\nsymmetric, i.e., Ge\\n12=Ge\\n21. Hence, in the sequel, for the sake of simpler\\nnotation, we will write Ge\\n12=Ge\\n21=Ge\\nA typical synchronization problem would be to (i) find the threshold\\nsynaptic strength Gefor which the two coupled FHN neurons may exhibit\\ncomplete synchronization and (ii) determine the stability of this complete\\nsynchronization state once it is achieved.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c7c84e37-f580-4c21-a298-8200b0bfe96d', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural compete synchronization problem\\nDefinition\\nTwo systems x(t)∈Rnandy(t)∈Rnare said to have achieved\\ncomplete synchronization if there exists a set of initial conditions\\nx(t0) =x0andy(t0) =y0such that the trajectories of the systems\\nsatisfy limt→∞∥x(t)−y(t)∥=0.\\nwhere∥·∥denotes the Euclidean norm, for initial conditions from\\nsome neighborhood of the synchronization manifold Ssuch that\\nwe have:\\n{v1(t) =v2(t) =v(t),\\nw1(t) =w2(t) =w(t).(3)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c7b915e7-4acb-47a8-8674-a02042f4c4c0', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural compete synchronization problem\\nThis means that the synchronization solution in Eq. (3) is always a\\nsolution of the coupled system, and hence when the neurons are\\nsynchronized (i.e., when all the terms Ge(v2−v1)in Eq. (2)\\nbecomes zero) their common dynamics behave like a single neuron,\\ni.e., like:\\n\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3dv\\ndt=v(a−v)(v−1)−w+Iext,\\ndw\\ndt=ε(bv−cw).(4)\\nHowever, this synchronization solution might be unstable under\\nsome conditions. Thus, the necessity of studying the stability of the\\nsynchronized states which we will do with the use of the Lyapunov\\nfunction criteria for stability.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='df818171-e77f-4c82-ad21-f4445181bbb8', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural compete synchronization problem\\nIt should be noted that achieving complete (ideal, perfect)\\nsynchronization in real-world systems, where the trajectories of\\ninteracting systems converge exactly over time (i.e.,\\nlim\\nt→∞∥x(t)−y(t)∥=0 ), is often challenging or even impossible.\\nThis difficulty can stem from factors such as parameter mismatches,\\nuncertainties, noise, different initial conditions, differing governing\\nequations of the interacting systems, and numerical integration\\nerrors during computation.\\nConsequently, synchronization in real-world systems is frequently\\npursued in a practical sense, aiming for a sufficient level of\\ncoordination tailored to specific applications to ensure the effective\\noperation of systems, even if perfect alignment is not attainable.\\nThis concept is crucial in fields such as control theory,\\ncommunications, and network synchronization, where exact\\nalignment may be impracticable or unnecessary, yet effective\\ncoordination remains essential.\\nIn such practical cases, we talk of practical synchronization which is\\nformal defined as follows:\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5699a903-8bce-46e1-89ce-c4352e1b3bb3', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural compete synchronization problem\\nDefinition\\nTwo systems x(t)∈Rnandy(t)∈Rnare said to have achieved practical\\nsynchronization if there exists a set of initial conditions x(t0) =x0and\\ny(t0) =y0and 0<δ≪1 such that the trajectories of the systems\\nsatisfy lim\\nt→∞∥x(t)−y(t)∥≤δ.\\nNow let’s study the synchronization of the coupled system in Eq. (2). By\\nintroducing coordinates transformation to the synchronization manifold\\ndefined by the errors evandew, defined as:\\n{ev=v2−v1,\\new=w2−w1,(5)\\nwe obtain the following set of error dynamical systems governing the dynamics\\nof the synchronization errors:\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3dev\\ndt=−e3\\nv−(3v1−a−1)e2\\nv−[3v2\\n1−2(1+a)v1+a+2Ge]ev−ew,\\ndew\\ndt=ε(bev−cew).\\n(6)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f38d8def-f9f7-4aa5-84ae-2d13ded716ea', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s15.pdf', 'file_path': '/content/data/Lecture_s15.pdf', 'file_type': 'application/pdf', 'file_size': 248506, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural compete synchronization problem\\nNotice that the fixed point (ev,ew) = (0,0)of the error dynamical\\nsystem in Eq. (6) lies on synchronization manifold S, i.e., where the\\nerrors evandeware both equal to zero.\\nIf the two neurons achieve complete synchronization, i.e., if we have:\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3lim\\nt→∞∥v2(t)−v1(t)∥=0,\\nlim\\nt→∞∥w2(t)−w1(t)∥=0,(7)\\nthen in the error dynamical system given in Eq.(6), we can neglect\\nthe second and higher order of the errors, so that Eq.(6) becomes:\\n\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3dev\\ndt=−[3v2−2(1+a)v+a+2Ge]ev−ew,\\ndew\\ndt=ε(bev−cew).(8)\\nNotice that in Eq. (8), the subscript \"1\" on variable v1has been\\ndropped. This is because, on the synchronization manifold, the two\\ncoupled neurons behave identically, i.e., just like one neuron given\\nby Eq.(4), where we have just vinstead of v1.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d0f85996-e544-47c5-9240-a84d55c93497', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s16.pdf', 'file_path': '/content/data/Lecture_s16.pdf', 'file_type': 'application/pdf', 'file_size': 336310, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 16: Synchronization in neural networks\\n(Continuation of Lecture 15)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='33e13f7c-478e-498d-8d85-32cdd43feef0', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s16.pdf', 'file_path': '/content/data/Lecture_s16.pdf', 'file_type': 'application/pdf', 'file_size': 336310, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural complete synchronization problem\\nFurthermore, it appears that the stability of the synchronized states\\nin Eq. (8) (see the slides of Lecture 15) depends on the coupling\\nstrength Ge. To determine the stability of the synchronized state of\\nthe two coupled neurons with respect to Ge(or any other parameter\\nof the neuron model), we can use the Krasovskii-Lyapunov stability\\ntheory.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='18453175-ac43-42e7-85be-bffb94854a77', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s16.pdf', 'file_path': '/content/data/Lecture_s16.pdf', 'file_type': 'application/pdf', 'file_size': 336310, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural complete synchronization problem\\nDefinition\\nThe Lyapunov function of a given dynamical system dei/dt=fi(ei)with a\\nfixed point at e∗\\ni(i=1,2,..,n) is a real-valued function Vwhich is defined over a\\nregion Ωof the phase space Rn(Ω⊂Rn) that contains the fixed point e∗\\niand\\nsatisfies the following requirements:\\n1Vis continuously differentiable and positive definite (i.e., V∈C1,\\nV(ei)>0∀ei̸=e∗\\ni,V(e∗\\ni) =0)\\n2V(ei)has a unique minimum with respect to the neighbourhood of Ω\\n(i.e.,∃!e∗\\ni∈Ωsuch that V(e∗\\ni)≤V(ei)∀ei∈Ω)\\n3Along any trajectory of error dynamical dei/dt=fi(ei), contained in Ω,\\nthe value of V(ei)never increases (i.e.,\\ndV(ei)/dt=∇V(ei)·fi(ei)<0,∀ei∈Ω\\\\{e∗\\ni}).\\nIfdV\\ndt≤0,∀ei∈Ω⊂Rn\\\\{e∗\\ni}, then e∗\\niis stable.\\nIfdV\\ndt<0,∀ei∈Ω⊂Rn\\\\{e∗\\ni}, then e∗\\niis locally asymptotically stable.\\nIfdV\\ndt<0,∀ei∈Rn\\\\{e∗\\ni}, then e∗\\niis globally asymptotically stable.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5de78da5-ed63-4609-a247-95168afe70d2', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s16.pdf', 'file_path': '/content/data/Lecture_s16.pdf', 'file_type': 'application/pdf', 'file_size': 336310, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural complete synchronization problem\\nNote that the Lyapunov function of a dynamical system is not unique,\\nhowever, the challenge of the Lyapunov approach to stability is that\\nconstructing a proper Lyapunov function is generally not easy. But once it\\nis successfully constructed, stability analysis becomes relatively easier.\\nFollowing the Krasovskii-Lyapunov theory which has been widely used in\\nidentifying the stability of synchronized states we define a continuous,\\npositive-definite Lyapunov function with a continuous first partial\\nderivative of the form:\\nV(ev,ew) = ev(t)2+ew(t)2, (9)\\nwhich has a unique minimum at the fixed point (e∗\\nv,e∗\\nw) = (0,0). The\\nderivative of the function Valong a trajectory of the error dynamical\\nsystem in Eq. (8) is given by:\\ndV\\ndt=2evdev\\ndt+2ewdew\\ndt. (10)\\nSubstituting Eq. (8) (see slides of Lecture 15) in Eq. (10) yields:\\ndV\\ndt=−[6v2−4(1+a)v+2a+4Ge]e2\\nv−2evew+2ε(bevew−ce2\\nw).(11)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c027fa33-b104-4e81-a0d6-7435d26ad571', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s16.pdf', 'file_path': '/content/data/Lecture_s16.pdf', 'file_type': 'application/pdf', 'file_size': 336310, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural complete synchronization problem\\nThus, the sufficient condition for a\\n1stable,\\n2locally asymptotically stable,\\n3globally asymptotically stable,\\nsynchronized states, with respect to the coupling strength Geprovided that it is\\nfulfilled at all points of the attractor of Eq. (4) (see slides in Lecture 15), is\\nthat the time derivative of the Lyapunov function dV/dtsatisfies\\n1dV\\ndt≤0,∀(ev,ew)∈Ω⊂R2\\\\{(0,0)},\\n2dV\\ndt<0,∀(ev,ew)∈Ω⊂R2\\\\{(0,0)},\\n3dV\\ndt<0,∀(ev,ew)∈R2\\\\{(0,0)}\\nrespectively, where Ωis some neighborhood containing the fixed point\\n(e∗\\nv,e∗\\nw) = (0,0)of the synchronized error dynamical system given in Eq. (8).\\nOtherwise, i.e., if dV/dt>0, then the synchronized state is unstable.\\nThus, to evaluate the expression of dV/dtand determine its sign, it\\nsuffices to solve two equations simultaneously, i.e., Eq. (4) for v, and Eq.\\n(8) for evandew, and use the current values of v,ev, and ewcalculated\\nat each time step tto evaluate the the expression dV/dtgiven in Eq.\\n(11) at time t.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8e7e1101-c292-4c01-a061-5e2421802c40', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s16.pdf', 'file_path': '/content/data/Lecture_s16.pdf', 'file_type': 'application/pdf', 'file_size': 336310, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural complete synchronization problem\\nThis can be done for a range of values of Geand determine the stability\\nproperty of the synchronized state for each value of Ge. Note that Eq.\\n(4), Eq. (8), and Eq. (11) have to be solved and evaluated simultaneously\\nas time changes.\\nAnother common and important type of synchronization is known as\\nphase synchronization. This involves sub-system properties called phases\\nand is characterized by the 2 πphase locking of two or more oscillators,\\neven if their amplitudes are uncorrelated.\\nIt’s important to note the difference between complete synchronization\\nand phase synchronization. In complete synchronization, all values of the\\nspike trains are used to compute synchronization. In contrast, phase\\nsynchronization only considers the timing of the spikes in the spike trains.\\nIt has been shown that synchronization of oscillatory phases between\\ndifferent brain regions supports both working memory and long-term\\nmemory and facilitates neural communication by promoting neural\\nplasticity.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='99e1affd-c5e9-4244-936a-b3e3942d24ab', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s16.pdf', 'file_path': '/content/data/Lecture_s16.pdf', 'file_type': 'application/pdf', 'file_size': 336310, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural complete synchronization problem\\nHow can one quantify the complete synchronization of N(and\\nnot only 2) neurons?\\nAnswer: Complete synchronization (CS): The ability of the N\\nneurons in the network to completely synchronize the actual value of\\ntheir membrane potential variables vk(t)can be quantified by the\\nstatistical index of complete synchronization Θ, given by the\\nstandard deviation of vk(t)for these Nneurons as:\\nΘ =⟨ρ(t)⟩twithρ(t) =\\ued6a\\ued6b\\ued6b\\ued6b\\ued6b√1\\nNN∑\\nk=1(\\nvk(t))2\\n−(\\n1\\nNN∑\\nk=1vk(t))2\\nN−1,(12)\\nand where the angle brackets ⟨·⟩trepresents the average over time t, i.e.,\\nthe total number of simulation time steps. ρ(t)measures the degree of\\nCS at a given time t. The value of Θis an excellent indicator of the\\ndegree of CS and reveals different synchronization levels and related\\ntransitions. Smaller values of Θindicate higher degrees of CS, and Θ =0\\nindicates the highest degree of CS.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c8296d1f-d4a4-49da-9e0d-7ff4d75c7eed', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s16.pdf', 'file_path': '/content/data/Lecture_s16.pdf', 'file_type': 'application/pdf', 'file_size': 336310, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A neural complete synchronization problem\\nHow can one quantify the phase synchronization of N\\nneurons?\\nAnswer: Phase synchronization (PS): The time-averaged Kuramoto order\\nparameter ,R, can be used to measure the degree of PS among the N-coupled\\nneurons. It is given by:\\nR=1\\nT∫T\\n0⏐⏐⏐⏐⏐1\\nNN∑\\nk=1exp(\\niϕk(t))⏐⏐⏐⏐⏐dt, (13)\\nwhereϕk(t) =2πn+2πt−t(n)\\nk\\nt(n+1)\\nk−t(n)\\nkandt(n)\\nk≤t<t(n+1)\\nk. In the argument of\\nthe exponential function, i=√−1 and the quantity ϕk(t)approximates the\\nphase of the kth neuron in the network and linearly increases over 2 πfrom one\\nspike to the next. The norm of this complex exponential function is represented\\nby⏐⏐·⏐⏐. The time at which the kth neuron exhibits its nth spike ( n=0,1,2,...)\\nis represented by t(n)\\nk. We determine the spike time occurrences from the\\ninstant vk(t)crosses the corresponding threshold vthvalue from below. The\\ntime-averaged Kuramoto order parameter Rranges from 0 corresponding to no\\nPS to 1 corresponding to full PS (i.e., all neurons fire at precisely the same\\ntimes).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0426cabd-566f-4641-9111-d9375780d2d8', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 17:\\nIntroduction to Reservoir Computing\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='75971841-5e23-4d43-aaf8-ec9418e86975', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives\\nUnderstand the baseline working principle of reservoir\\ncomputers.\\nDistinguish between the two type of reservoir compting: Echo\\nstate networks (ESN) and liquid state machines (LSM)\\nTo implement a reservoir computer to accomplish a\\nbenchmark task.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='33ab7840-88e6-4b50-9c8a-dff7417c5e48', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Reservoir Computing (RC)\\nArtificial recurrent neural networks (RNNs) are diverse\\ncomputational models that draw inspiration from biological neurons\\nand brain components.\\nIn RNNs, multiple abstract neurons are connected by abstracted\\nsynaptic connections (or links), allowing activations to flow through\\nthe network. The presence of cyclic connections within their\\ntopology sets RNNs apart from commonly used feedforward neural\\nnetworks (e.g., the multilayer perceptron).\\nThese cycles have a significant influence, yielding notable\\nconsequences including:\\n1An RNN may develop self-sustained temporal activation\\ndynamics along its recurrent connection pathways, even\\nwithout input. Mathematically, this renders an RNN a\\ndynamical system, while feedforward networks are functions.\\n2If driven by an input signal, an RNN preserves its internal state\\na nonlinear transformation of the input history — in other\\nwords, it has a dynamical memory, and is able to process\\ntemporal context information.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d81946c9-f260-4feb-b6cc-1ec7f780793e', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Reservoir Computing (RC)\\nArtificial recurrent neural networks (RNNs) are diverse\\ncomputational models that draw inspiration from biological neurons\\nand brain components.\\nIn RNNs, multiple abstract neurons are connected by abstracted\\nsynaptic connections (or links), allowing activations to flow through\\nthe network. The presence of cyclic connections within their\\ntopology sets RNNs apart from commonly used feedforward neural\\nnetworks (e.g., the multilayer perceptron).\\nThese cycles have a significant influence, yielding notable\\nconsequences including:\\n1An RNN may develop self-sustained temporal activation\\ndynamics along its recurrent connection pathways, even\\nwithout input. Mathematically, this renders an RNN a\\ndynamical system, while feedforward networks are functions.\\n2If driven by an input signal, an RNN preserves its internal state\\na nonlinear transformation of the input history — in other\\nwords, it has a dynamical memory, and is able to process\\ntemporal context information.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e11209bc-c3cc-4408-b8bb-eda915ca710c', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Reservoir Computing (RC)\\nArtificial recurrent neural networks (RNNs) are diverse\\ncomputational models that draw inspiration from biological neurons\\nand brain components.\\nIn RNNs, multiple abstract neurons are connected by abstracted\\nsynaptic connections (or links), allowing activations to flow through\\nthe network. The presence of cyclic connections within their\\ntopology sets RNNs apart from commonly used feedforward neural\\nnetworks (e.g., the multilayer perceptron).\\nThese cycles have a significant influence, yielding notable\\nconsequences including:\\n1An RNN may develop self-sustained temporal activation\\ndynamics along its recurrent connection pathways, even\\nwithout input. Mathematically, this renders an RNN a\\ndynamical system, while feedforward networks are functions.\\n2If driven by an input signal, an RNN preserves its internal state\\na nonlinear transformation of the input history — in other\\nwords, it has a dynamical memory, and is able to process\\ntemporal context information.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='241d1ed6-6c23-47ca-bffd-c70b1c870447', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Reservoir Computing (RC)\\nArtificial recurrent neural networks (RNNs) are diverse\\ncomputational models that draw inspiration from biological neurons\\nand brain components.\\nIn RNNs, multiple abstract neurons are connected by abstracted\\nsynaptic connections (or links), allowing activations to flow through\\nthe network. The presence of cyclic connections within their\\ntopology sets RNNs apart from commonly used feedforward neural\\nnetworks (e.g., the multilayer perceptron).\\nThese cycles have a significant influence, yielding notable\\nconsequences including:\\n1An RNN may develop self-sustained temporal activation\\ndynamics along its recurrent connection pathways, even\\nwithout input. Mathematically, this renders an RNN a\\ndynamical system, while feedforward networks are functions.\\n2If driven by an input signal, an RNN preserves its internal state\\na nonlinear transformation of the input history — in other\\nwords, it has a dynamical memory, and is able to process\\ntemporal context information.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7871108b-dc66-4c68-8467-4447e68f67c9', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Reservoir Computing (RC)\\nRNNs find application in diverse scientific domains, and they can be\\ncategorized into two main classes with interesting connections\\nbetween these two:\\n1Modeling biological brains. This application falls within the\\nrealm of computational neuroscience.\\n2Serving as engineering tools for technical applications. This\\nplaces RNNs within the domains of machine learning,\\ncomputation theory, nonlinear signal processing, and control.\\nEcho State Networks (ESNs) and Liquid State Machines (LSMs)\\nintroduced a new paradigm in artificial recurrent neural network (RNN)\\ntraining, where an RNN (the reservoir) is generated randomly and only a\\nreadout layer is trained. The paradigm, becoming known as reservoir\\ncomputing (RC), greatly facilitated the practical application of RNNs and\\noutperformed classical fully trained RNNs (e.g., Deep neural network) in\\nmany tasks.\\nRC has lately become a vivid research field with numerous extensions of\\nthe basic idea, including reservoir adaptation, thus broadening the initial\\nparadigm to using different methods for training the reservoir and the\\nreadout. In this course, we focus on the basics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8c3f79e9-6302-46dc-8199-c3b078739910', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Reservoir Computing (RC)\\nRNNs find application in diverse scientific domains, and they can be\\ncategorized into two main classes with interesting connections\\nbetween these two:\\n1Modeling biological brains. This application falls within the\\nrealm of computational neuroscience.\\n2Serving as engineering tools for technical applications. This\\nplaces RNNs within the domains of machine learning,\\ncomputation theory, nonlinear signal processing, and control.\\nEcho State Networks (ESNs) and Liquid State Machines (LSMs)\\nintroduced a new paradigm in artificial recurrent neural network (RNN)\\ntraining, where an RNN (the reservoir) is generated randomly and only a\\nreadout layer is trained. The paradigm, becoming known as reservoir\\ncomputing (RC), greatly facilitated the practical application of RNNs and\\noutperformed classical fully trained RNNs (e.g., Deep neural network) in\\nmany tasks.\\nRC has lately become a vivid research field with numerous extensions of\\nthe basic idea, including reservoir adaptation, thus broadening the initial\\nparadigm to using different methods for training the reservoir and the\\nreadout. In this course, we focus on the basics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cd1ea435-6345-4114-a2ab-d4e8e28cc1d5', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Reservoir Computing (RC)\\nRNNs find application in diverse scientific domains, and they can be\\ncategorized into two main classes with interesting connections\\nbetween these two:\\n1Modeling biological brains. This application falls within the\\nrealm of computational neuroscience.\\n2Serving as engineering tools for technical applications. This\\nplaces RNNs within the domains of machine learning,\\ncomputation theory, nonlinear signal processing, and control.\\nEcho State Networks (ESNs) and Liquid State Machines (LSMs)\\nintroduced a new paradigm in artificial recurrent neural network (RNN)\\ntraining, where an RNN (the reservoir) is generated randomly and only a\\nreadout layer is trained. The paradigm, becoming known as reservoir\\ncomputing (RC), greatly facilitated the practical application of RNNs and\\noutperformed classical fully trained RNNs (e.g., Deep neural network) in\\nmany tasks.\\nRC has lately become a vivid research field with numerous extensions of\\nthe basic idea, including reservoir adaptation, thus broadening the initial\\nparadigm to using different methods for training the reservoir and the\\nreadout. In this course, we focus on the basics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5065edf7-7b61-4688-b593-92d1b0d44d54', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Reservoir Computing (RC)\\nRNNs find application in diverse scientific domains, and they can be\\ncategorized into two main classes with interesting connections\\nbetween these two:\\n1Modeling biological brains. This application falls within the\\nrealm of computational neuroscience.\\n2Serving as engineering tools for technical applications. This\\nplaces RNNs within the domains of machine learning,\\ncomputation theory, nonlinear signal processing, and control.\\nEcho State Networks (ESNs) and Liquid State Machines (LSMs)\\nintroduced a new paradigm in artificial recurrent neural network (RNN)\\ntraining, where an RNN (the reservoir) is generated randomly and only a\\nreadout layer is trained. The paradigm, becoming known as reservoir\\ncomputing (RC), greatly facilitated the practical application of RNNs and\\noutperformed classical fully trained RNNs (e.g., Deep neural network) in\\nmany tasks.\\nRC has lately become a vivid research field with numerous extensions of\\nthe basic idea, including reservoir adaptation, thus broadening the initial\\nparadigm to using different methods for training the reservoir and the\\nreadout. In this course, we focus on the basics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='02048ef6-f8d7-46f6-9aa1-a887fee53b07', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Echo State Networks (ESNs)\\nEcho state network (ESN) is developed for efficient prediction of\\ncomplex signals for a considerably longer time. In contrast to RNN,\\nthe ESN is easier to implement and cost-effective since it does not\\nrequire fine-tuning of its inner components except for the\\nreadout/output layer, which helps to match the target behavior\\nwithin a close approximation.\\nHaving its simplicity of computation and powerful ability of\\nprediction, ESN has been used for calculating Lyapunov exponents,\\nattractor reconstruction of dynamical systems, and has become a\\ntesting bed for detecting generalized synchronization in coupled\\nchaotic systems.\\nApart from dynamical issues, ESN can identify nonstationarity in\\nsteady-state visual evoked potentials, predict stock price in a short\\ntime scale, and help understand the language processing as well as\\ndifferentiating speech signals.\\nResearchers are devoted to finding the optimal parameters of an\\nESN for accurate detection of target data.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e89d9418-7480-40c4-9323-ebabc9e84ae6', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Echo State Networks (ESNs)\\nEcho state network (ESN) is developed for efficient prediction of\\ncomplex signals for a considerably longer time. In contrast to RNN,\\nthe ESN is easier to implement and cost-effective since it does not\\nrequire fine-tuning of its inner components except for the\\nreadout/output layer, which helps to match the target behavior\\nwithin a close approximation.\\nHaving its simplicity of computation and powerful ability of\\nprediction, ESN has been used for calculating Lyapunov exponents,\\nattractor reconstruction of dynamical systems, and has become a\\ntesting bed for detecting generalized synchronization in coupled\\nchaotic systems.\\nApart from dynamical issues, ESN can identify nonstationarity in\\nsteady-state visual evoked potentials, predict stock price in a short\\ntime scale, and help understand the language processing as well as\\ndifferentiating speech signals.\\nResearchers are devoted to finding the optimal parameters of an\\nESN for accurate detection of target data.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8fd503f2-903b-4f0b-9f8c-bbb5ae6df359', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Echo State Networks (ESNs)\\nEcho state network (ESN) is developed for efficient prediction of\\ncomplex signals for a considerably longer time. In contrast to RNN,\\nthe ESN is easier to implement and cost-effective since it does not\\nrequire fine-tuning of its inner components except for the\\nreadout/output layer, which helps to match the target behavior\\nwithin a close approximation.\\nHaving its simplicity of computation and powerful ability of\\nprediction, ESN has been used for calculating Lyapunov exponents,\\nattractor reconstruction of dynamical systems, and has become a\\ntesting bed for detecting generalized synchronization in coupled\\nchaotic systems.\\nApart from dynamical issues, ESN can identify nonstationarity in\\nsteady-state visual evoked potentials, predict stock price in a short\\ntime scale, and help understand the language processing as well as\\ndifferentiating speech signals.\\nResearchers are devoted to finding the optimal parameters of an\\nESN for accurate detection of target data.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2f1c8bce-580b-46d8-b02c-7f7bc480f178', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Echo State Networks (ESNs)\\nEcho state network (ESN) is developed for efficient prediction of\\ncomplex signals for a considerably longer time. In contrast to RNN,\\nthe ESN is easier to implement and cost-effective since it does not\\nrequire fine-tuning of its inner components except for the\\nreadout/output layer, which helps to match the target behavior\\nwithin a close approximation.\\nHaving its simplicity of computation and powerful ability of\\nprediction, ESN has been used for calculating Lyapunov exponents,\\nattractor reconstruction of dynamical systems, and has become a\\ntesting bed for detecting generalized synchronization in coupled\\nchaotic systems.\\nApart from dynamical issues, ESN can identify nonstationarity in\\nsteady-state visual evoked potentials, predict stock price in a short\\ntime scale, and help understand the language processing as well as\\ndifferentiating speech signals.\\nResearchers are devoted to finding the optimal parameters of an\\nESN for accurate detection of target data.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='de3aa8e1-2d0d-42d5-83eb-8861953b63cf', embedding=None, metadata={'page_label': '15', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nA reservoir computer (say, ESN) has three distinct components or\\nlayers: an input layer collecting the inputs, a reservoir with a large\\nnumber of randomly connected elements (analogous to neurons in\\nthe brain) that expand the input in a high dimensional nonlinear\\nfashion and an output layer to produce the expected target.\\nThe readout or output layer is the only part where the weights are\\ntrained to produce the desired output, which should be closer to the\\ntarget data.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4ce89276-52c5-4e4c-ba15-81b8c5690b16', embedding=None, metadata={'page_label': '16', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nConsider a dynamical system whose n-dimensional state x∈Rnobeys a set of n\\nautonomous differential equations of the form\\ndx\\ndt=g(x) (1)\\nIn general, the goal of reservoir computing is to approximate (learn) the flow\\n(solution) of Eq. (1) in discrete time by a map of the form\\nx(t+1) =G(\\nx(t))\\n(2)\\nHere, the parameter truns over a set of discrete times separated by ∆ttime\\nunits of the real system, where ∆tis a timescale hyperparameter generally\\nchosen to be smaller than the characteristic timescale(s) of Eq. (1).\\nWe view the state of the real system as a linear readout from an auxiliary\\nreservoir system , whose state is a vector rtwith dimension Nres. Specifically:\\nxout(t) =Wout·r(t) (3)\\nwhere Woutis an×Nresmatrix of trainable output weights.\\nThe reservoir system is generally much higher-dimensional ( n≪Nres), and its\\ndynamics obey the standard discrete-time leaky tanh(·)(i.e., hyperbolic tangent\\nfunction – the nonlinear activation function which is applied element-wise)\\nnetwork equation. The internal state of each node of the reservoir updates itself\\nfollowing a recurrent relation given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·u(t) +b)\\n(4)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f7da6716-8ba4-4417-900d-879241657f58', embedding=None, metadata={'page_label': '17', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nConsider a dynamical system whose n-dimensional state x∈Rnobeys a set of n\\nautonomous differential equations of the form\\ndx\\ndt=g(x) (1)\\nIn general, the goal of reservoir computing is to approximate (learn) the flow\\n(solution) of Eq. (1) in discrete time by a map of the form\\nx(t+1) =G(\\nx(t))\\n(2)\\nHere, the parameter truns over a set of discrete times separated by ∆ttime\\nunits of the real system, where ∆tis a timescale hyperparameter generally\\nchosen to be smaller than the characteristic timescale(s) of Eq. (1).\\nWe view the state of the real system as a linear readout from an auxiliary\\nreservoir system , whose state is a vector rtwith dimension Nres. Specifically:\\nxout(t) =Wout·r(t) (3)\\nwhere Woutis an×Nresmatrix of trainable output weights.\\nThe reservoir system is generally much higher-dimensional ( n≪Nres), and its\\ndynamics obey the standard discrete-time leaky tanh(·)(i.e., hyperbolic tangent\\nfunction – the nonlinear activation function which is applied element-wise)\\nnetwork equation. The internal state of each node of the reservoir updates itself\\nfollowing a recurrent relation given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·u(t) +b)\\n(4)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8f6b63f0-be91-42a5-9cc4-6adf7509036e', embedding=None, metadata={'page_label': '18', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nConsider a dynamical system whose n-dimensional state x∈Rnobeys a set of n\\nautonomous differential equations of the form\\ndx\\ndt=g(x) (1)\\nIn general, the goal of reservoir computing is to approximate (learn) the flow\\n(solution) of Eq. (1) in discrete time by a map of the form\\nx(t+1) =G(\\nx(t))\\n(2)\\nHere, the parameter truns over a set of discrete times separated by ∆ttime\\nunits of the real system, where ∆tis a timescale hyperparameter generally\\nchosen to be smaller than the characteristic timescale(s) of Eq. (1).\\nWe view the state of the real system as a linear readout from an auxiliary\\nreservoir system , whose state is a vector rtwith dimension Nres. Specifically:\\nxout(t) =Wout·r(t) (3)\\nwhere Woutis an×Nresmatrix of trainable output weights.\\nThe reservoir system is generally much higher-dimensional ( n≪Nres), and its\\ndynamics obey the standard discrete-time leaky tanh(·)(i.e., hyperbolic tangent\\nfunction – the nonlinear activation function which is applied element-wise)\\nnetwork equation. The internal state of each node of the reservoir updates itself\\nfollowing a recurrent relation given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·u(t) +b)\\n(4)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4d8c56dc-1a4d-4a55-96b0-c97aa62a8915', embedding=None, metadata={'page_label': '19', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nConsider a dynamical system whose n-dimensional state x∈Rnobeys a set of n\\nautonomous differential equations of the form\\ndx\\ndt=g(x) (1)\\nIn general, the goal of reservoir computing is to approximate (learn) the flow\\n(solution) of Eq. (1) in discrete time by a map of the form\\nx(t+1) =G(\\nx(t))\\n(2)\\nHere, the parameter truns over a set of discrete times separated by ∆ttime\\nunits of the real system, where ∆tis a timescale hyperparameter generally\\nchosen to be smaller than the characteristic timescale(s) of Eq. (1).\\nWe view the state of the real system as a linear readout from an auxiliary\\nreservoir system , whose state is a vector rtwith dimension Nres. Specifically:\\nxout(t) =Wout·r(t) (3)\\nwhere Woutis an×Nresmatrix of trainable output weights.\\nThe reservoir system is generally much higher-dimensional ( n≪Nres), and its\\ndynamics obey the standard discrete-time leaky tanh(·)(i.e., hyperbolic tangent\\nfunction – the nonlinear activation function which is applied element-wise)\\nnetwork equation. The internal state of each node of the reservoir updates itself\\nfollowing a recurrent relation given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·u(t) +b)\\n(4)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='22ef31b4-b64c-49e6-9549-87a421a4e21b', embedding=None, metadata={'page_label': '20', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nConsider a dynamical system whose n-dimensional state x∈Rnobeys a set of n\\nautonomous differential equations of the form\\ndx\\ndt=g(x) (1)\\nIn general, the goal of reservoir computing is to approximate (learn) the flow\\n(solution) of Eq. (1) in discrete time by a map of the form\\nx(t+1) =G(\\nx(t))\\n(2)\\nHere, the parameter truns over a set of discrete times separated by ∆ttime\\nunits of the real system, where ∆tis a timescale hyperparameter generally\\nchosen to be smaller than the characteristic timescale(s) of Eq. (1).\\nWe view the state of the real system as a linear readout from an auxiliary\\nreservoir system , whose state is a vector rtwith dimension Nres. Specifically:\\nxout(t) =Wout·r(t) (3)\\nwhere Woutis an×Nresmatrix of trainable output weights.\\nThe reservoir system is generally much higher-dimensional ( n≪Nres), and its\\ndynamics obey the standard discrete-time leaky tanh(·)(i.e., hyperbolic tangent\\nfunction – the nonlinear activation function which is applied element-wise)\\nnetwork equation. The internal state of each node of the reservoir updates itself\\nfollowing a recurrent relation given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·u(t) +b)\\n(4)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='42c2561e-6608-41a1-879c-0a632355a0e8', embedding=None, metadata={'page_label': '21', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nWhere in Eq.(4), Wresis an Nres×Nresreservoir matrix, Winis the Nres×n\\ninput matrix, and bis a bias vector of dimension Nres. The input data u(t)is a\\nvector of dimension nthat represents either a state of the real system in Eq.(1)\\n(i.e., u(t) =x(t)) during training or the model’s own output (i.e.,\\nu(t) =Wout·r(t)) during prediction.\\nFinally, 0<α≤1 is the so-called leaky coefficient (also known as leak rate or\\nleaking factor). It plays a crucial role in shaping the memory and temporal\\ndynamics of the reservoir computer. It determines the rate at which information\\nfrom previous time steps decays and affects the system’s current state.\\nWhenα=0, there is no leakage, meaning the reservoir’s dynamics remain\\nconstant over time. When α=1, there is complete leakage, where the previous\\nstates do not influence the current state. Intermediate values, e.g., α=0.5,\\nallow for a partial leakage, where past information gradually fades away but still\\ncontributes to the current state.\\nBy adjusting α, the reservoir computer can balance capturing long-term\\ndependencies and adapting to changing inputs. A higher αallows the system to\\nrespond more quickly to new inputs, while lower values preserve information\\nfrom previous time steps for longer.\\nThe optimal value of the αdepends on the specific problem and the desired\\nmemory capacity of the reservoir. Thus, by adjusting α, the ESN can balance\\nshort-term memory with long-term memory and adapt its dynamics to the\\nrequirements of the task at hand.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='480f01c7-0b39-4562-827c-c01711062180', embedding=None, metadata={'page_label': '22', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nWhere in Eq.(4), Wresis an Nres×Nresreservoir matrix, Winis the Nres×n\\ninput matrix, and bis a bias vector of dimension Nres. The input data u(t)is a\\nvector of dimension nthat represents either a state of the real system in Eq.(1)\\n(i.e., u(t) =x(t)) during training or the model’s own output (i.e.,\\nu(t) =Wout·r(t)) during prediction.\\nFinally, 0<α≤1 is the so-called leaky coefficient (also known as leak rate or\\nleaking factor). It plays a crucial role in shaping the memory and temporal\\ndynamics of the reservoir computer. It determines the rate at which information\\nfrom previous time steps decays and affects the system’s current state.\\nWhenα=0, there is no leakage, meaning the reservoir’s dynamics remain\\nconstant over time. When α=1, there is complete leakage, where the previous\\nstates do not influence the current state. Intermediate values, e.g., α=0.5,\\nallow for a partial leakage, where past information gradually fades away but still\\ncontributes to the current state.\\nBy adjusting α, the reservoir computer can balance capturing long-term\\ndependencies and adapting to changing inputs. A higher αallows the system to\\nrespond more quickly to new inputs, while lower values preserve information\\nfrom previous time steps for longer.\\nThe optimal value of the αdepends on the specific problem and the desired\\nmemory capacity of the reservoir. Thus, by adjusting α, the ESN can balance\\nshort-term memory with long-term memory and adapt its dynamics to the\\nrequirements of the task at hand.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7f866af4-0dc9-4b99-9063-e3e63482fc77', embedding=None, metadata={'page_label': '23', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nWhere in Eq.(4), Wresis an Nres×Nresreservoir matrix, Winis the Nres×n\\ninput matrix, and bis a bias vector of dimension Nres. The input data u(t)is a\\nvector of dimension nthat represents either a state of the real system in Eq.(1)\\n(i.e., u(t) =x(t)) during training or the model’s own output (i.e.,\\nu(t) =Wout·r(t)) during prediction.\\nFinally, 0<α≤1 is the so-called leaky coefficient (also known as leak rate or\\nleaking factor). It plays a crucial role in shaping the memory and temporal\\ndynamics of the reservoir computer. It determines the rate at which information\\nfrom previous time steps decays and affects the system’s current state.\\nWhenα=0, there is no leakage, meaning the reservoir’s dynamics remain\\nconstant over time. When α=1, there is complete leakage, where the previous\\nstates do not influence the current state. Intermediate values, e.g., α=0.5,\\nallow for a partial leakage, where past information gradually fades away but still\\ncontributes to the current state.\\nBy adjusting α, the reservoir computer can balance capturing long-term\\ndependencies and adapting to changing inputs. A higher αallows the system to\\nrespond more quickly to new inputs, while lower values preserve information\\nfrom previous time steps for longer.\\nThe optimal value of the αdepends on the specific problem and the desired\\nmemory capacity of the reservoir. Thus, by adjusting α, the ESN can balance\\nshort-term memory with long-term memory and adapt its dynamics to the\\nrequirements of the task at hand.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f55a4c2a-b6d6-456e-a40f-25de8e59b570', embedding=None, metadata={'page_label': '24', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nWhere in Eq.(4), Wresis an Nres×Nresreservoir matrix, Winis the Nres×n\\ninput matrix, and bis a bias vector of dimension Nres. The input data u(t)is a\\nvector of dimension nthat represents either a state of the real system in Eq.(1)\\n(i.e., u(t) =x(t)) during training or the model’s own output (i.e.,\\nu(t) =Wout·r(t)) during prediction.\\nFinally, 0<α≤1 is the so-called leaky coefficient (also known as leak rate or\\nleaking factor). It plays a crucial role in shaping the memory and temporal\\ndynamics of the reservoir computer. It determines the rate at which information\\nfrom previous time steps decays and affects the system’s current state.\\nWhenα=0, there is no leakage, meaning the reservoir’s dynamics remain\\nconstant over time. When α=1, there is complete leakage, where the previous\\nstates do not influence the current state. Intermediate values, e.g., α=0.5,\\nallow for a partial leakage, where past information gradually fades away but still\\ncontributes to the current state.\\nBy adjusting α, the reservoir computer can balance capturing long-term\\ndependencies and adapting to changing inputs. A higher αallows the system to\\nrespond more quickly to new inputs, while lower values preserve information\\nfrom previous time steps for longer.\\nThe optimal value of the αdepends on the specific problem and the desired\\nmemory capacity of the reservoir. Thus, by adjusting α, the ESN can balance\\nshort-term memory with long-term memory and adapt its dynamics to the\\nrequirements of the task at hand.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='25091bdc-bbb6-43ab-be3f-d00db1ca2999', embedding=None, metadata={'page_label': '25', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nWhere in Eq.(4), Wresis an Nres×Nresreservoir matrix, Winis the Nres×n\\ninput matrix, and bis a bias vector of dimension Nres. The input data u(t)is a\\nvector of dimension nthat represents either a state of the real system in Eq.(1)\\n(i.e., u(t) =x(t)) during training or the model’s own output (i.e.,\\nu(t) =Wout·r(t)) during prediction.\\nFinally, 0<α≤1 is the so-called leaky coefficient (also known as leak rate or\\nleaking factor). It plays a crucial role in shaping the memory and temporal\\ndynamics of the reservoir computer. It determines the rate at which information\\nfrom previous time steps decays and affects the system’s current state.\\nWhenα=0, there is no leakage, meaning the reservoir’s dynamics remain\\nconstant over time. When α=1, there is complete leakage, where the previous\\nstates do not influence the current state. Intermediate values, e.g., α=0.5,\\nallow for a partial leakage, where past information gradually fades away but still\\ncontributes to the current state.\\nBy adjusting α, the reservoir computer can balance capturing long-term\\ndependencies and adapting to changing inputs. A higher αallows the system to\\nrespond more quickly to new inputs, while lower values preserve information\\nfrom previous time steps for longer.\\nThe optimal value of the αdepends on the specific problem and the desired\\nmemory capacity of the reservoir. Thus, by adjusting α, the ESN can balance\\nshort-term memory with long-term memory and adapt its dynamics to the\\nrequirements of the task at hand.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a6a85392-303e-4e22-88e5-f9372a0b7ea9', embedding=None, metadata={'page_label': '26', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nGenerally, only the output matrix Woutis trained, with Wres,Win, and b\\ngenerated randomly from appropriate ensembles. In practice, there are\\ngood ways to generate Wres,Win, and b. Specifically:\\nWresis the Nres×Nresweighted adjacency matrix of a directed\\nrandom Erdős-Rényi ( (ER) graph (note that other graphs, e.g.,\\nWatts–Strogatz (WS) small-world graph can also be used) on Nres\\nnodes with a link probability of 0 <q≤1, and we allow for\\nself-loops. We first draw the link weights uniformly (or even\\nnormally) and independently from [-1, 1], and then normalize them\\nso that Wreshas a desired spectral radius ρ>0.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0af819a8-c527-4017-bf9f-46e785889d91', embedding=None, metadata={'page_label': '27', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nGenerally, only the output matrix Woutis trained, with Wres,Win, and b\\ngenerated randomly from appropriate ensembles. In practice, there are\\ngood ways to generate Wres,Win, and b. Specifically:\\nWresis the Nres×Nresweighted adjacency matrix of a directed\\nrandom Erdős-Rényi ( (ER) graph (note that other graphs, e.g.,\\nWatts–Strogatz (WS) small-world graph can also be used) on Nres\\nnodes with a link probability of 0 <q≤1, and we allow for\\nself-loops. We first draw the link weights uniformly (or even\\nnormally) and independently from [-1, 1], and then normalize them\\nso that Wreshas a desired spectral radius ρ>0.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='fe6bd82a-0d06-4549-a296-5d935d5bf690', embedding=None, metadata={'page_label': '28', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nThe spectral radius ρis a key parameter that influences the dynamical\\nproperties of the reservoir. Now we explain in detail:\\nThe spectral radius of a matrix is defined as the largest absolute value of\\nits eigenvalues. Mathematically, if Wresis the adjacency matrix of the\\nreservoir, then its spectral radius ρ(Wres)is given by:\\nρ(Wres):= max {|λi|:λiis an eigenvalue of Wres}\\nThis step requires performing eigenvalue decomposition on Wresand\\nidentifying the eigenvalue with the largest magnitude.\\nIn an ESN, the dynamics of the reservoir are determined by weight matrix\\nWres. The spectral radius of Wressignificantly affects the network’s\\nperformance and its ability to maintain the two properties, namely, the\\necho state property and computational capacity property.\\n1Echo state property ensures that the network’s state is uniquely determined by\\nthe input history, rather than being influenced by the initial conditions. In other\\nwords, This property implies that the reservoir’s internal dynamics should\\nquickly forget its initial state and primarily rely on the input signals to produce\\ndesired outputs. The reservoir’s dynamics must be stable for the network to\\nhave this property. This property ensures that the reservoir’s dynamics do not\\namplify or distort the input signals excessively.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='373027d6-6e78-4588-b3e6-e25ae8fe5a48', embedding=None, metadata={'page_label': '29', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nThe spectral radius ρis a key parameter that influences the dynamical\\nproperties of the reservoir. Now we explain in detail:\\nThe spectral radius of a matrix is defined as the largest absolute value of\\nits eigenvalues. Mathematically, if Wresis the adjacency matrix of the\\nreservoir, then its spectral radius ρ(Wres)is given by:\\nρ(Wres):= max {|λi|:λiis an eigenvalue of Wres}\\nThis step requires performing eigenvalue decomposition on Wresand\\nidentifying the eigenvalue with the largest magnitude.\\nIn an ESN, the dynamics of the reservoir are determined by weight matrix\\nWres. The spectral radius of Wressignificantly affects the network’s\\nperformance and its ability to maintain the two properties, namely, the\\necho state property and computational capacity property.\\n1Echo state property ensures that the network’s state is uniquely determined by\\nthe input history, rather than being influenced by the initial conditions. In other\\nwords, This property implies that the reservoir’s internal dynamics should\\nquickly forget its initial state and primarily rely on the input signals to produce\\ndesired outputs. The reservoir’s dynamics must be stable for the network to\\nhave this property. This property ensures that the reservoir’s dynamics do not\\namplify or distort the input signals excessively.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='eb564575-5263-4117-923d-7001e1f311e3', embedding=None, metadata={'page_label': '30', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n2Computational capacity property: The spectral radius ρ(Wres)also\\ninfluences the computational capacity of the reservoir. This property\\ndetermines the reservoir’s internal states’ dynamic range and\\nmemory capacity. In other words, the spectral radius ρ(Wres)\\ncontrols the stability and the fading memory of the reservoir:\\nIfρ(Wres)<1, the reservoir dynamics are stable, and the\\nstates will eventually die out over time, ensuring that the\\ninfluence of past inputs fades away.\\nIfρ(Wres)≈1, the reservoir can maintain a balance where\\npast states influence the current state for a significant duration\\nwithout diverging, which is often desirable for capturing\\ntemporal dependencies in the input.\\nIfρ(Wres)>1, the network may become unstable, leading to\\nexploding states which are not useful for practical applications.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b5e874ed-983c-4ad1-93b8-56b489e2712e', embedding=None, metadata={'page_label': '31', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nWhen implementing an ESN, the reservoir weight matrix Wresis typically\\ninitialized as we explained above with Erdős-Rényi graph, i.e., we select\\nrandomly, with probability 0 <q≤1, the entries of Wresfrom a uniform\\nor normal distribution in [-1,1]. To control the spectral radius, the matrix\\n(Wres)is then scaled appropriately:\\n1Initialize Wreswith random values.\\n2Compute the spectral radius ρinitialof the initialized Wres.\\n3Scalethe matrix to achieve the desired spectral radius ρdesired:\\nWres←Wres\\nρinitial·ρdesired\\nThis process involves two conservative steps:\\n(1):Normalize Wres:Wres←Wres\\nρinitial.\\nThis step scales the matrix Wressuch that its spectral radius is 1.\\n(2):Scale toρdesired:Wres←Wres·ρdesired.\\nThis step adjusts the spectral radius to the desired value ρdesired.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='91790f4f-038e-47a3-8b3c-f7fe95ad38eb', embedding=None, metadata={'page_label': '32', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nThe normalization (by ρinitial) and rescaling (by ρdesired) ofWres\\nensures that the reservoir has the desired dynamical properties,\\nwhich helps in maintaining the echo state property and improving\\nthe network’s performance. The desired spectral radius ρdesiredis\\ntypically chosen based on empirical testing and the specific task\\nrequirements. Common values range between 0.8 and 1.2, with 1\\nbeing a frequently used value to balance memory and stability.\\nWinin Eq. (4) is a dense matrix whose entries are initially\\ndrawn uniformly and independently from [-1, 1].\\nbin a constant bias parameter (which prevents over-fitting)\\nand has its entries drawn uniformly and independently from\\n[−sb,sb], where sb>0 is a scale hyperparameter.\\nIn the following slides, we outline basic and standard steps in\\ntraining and predicting with an ESN:\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9b90a801-00c4-48bb-baad-710fe76a0cd1', embedding=None, metadata={'page_label': '33', 'file_name': 'Lecture_s17.pdf', 'file_path': '/content/data/Lecture_s17.pdf', 'file_type': 'application/pdf', 'file_size': 1743473, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nThe normalization (by ρinitial) and rescaling (by ρdesired) ofWres\\nensures that the reservoir has the desired dynamical properties,\\nwhich helps in maintaining the echo state property and improving\\nthe network’s performance. The desired spectral radius ρdesiredis\\ntypically chosen based on empirical testing and the specific task\\nrequirements. Common values range between 0.8 and 1.2, with 1\\nbeing a frequently used value to balance memory and stability.\\nWinin Eq. (4) is a dense matrix whose entries are initially\\ndrawn uniformly and independently from [-1, 1].\\nbin a constant bias parameter (which prevents over-fitting)\\nand has its entries drawn uniformly and independently from\\n[−sb,sb], where sb>0 is a scale hyperparameter.\\nIn the following slides, we outline basic and standard steps in\\ntraining and predicting with an ESN:\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b1822755-a5ba-45ac-8d30-f1aeb7c5b208', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 18:\\nIntroduction to Reservoir Computing\\n(Continuation of Lecture 17)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='de999c41-efa2-4ecc-b3a5-5795829e676e', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n1Training:\\nTo train an RC model from a given initial condition x(0), we first\\nintegrate the real dynamics in Eq.(1) to obtain Ntrainadditional states\\n{x(t)}t=1,...,Ntrain.\\nWe then iterate the reservoir dynamics in Eq.(4) for Ntraintimes from\\nr(0) =0, using the training data as inputs (i.e., u(t) =x(t)). This\\nproduces a corresponding sequence of reservoir states, {r(t)}t=1,...,Ntrain.\\nFinally, we solve for the output weights Woutthat render Eq.(3) the best\\nfit to the training data using Ridge Regression with Tikhonov\\nregularization:\\nWout=XRT(RRT+λI)−1(5)\\nwhere, XandRare matrices whose columns are the x(t)andr(t),\\nrespectively, for t=1,...,Ntrain.Iis the Nres×Nresidentity matrix, and\\nλ>0 is a regularization hyperparameter that prevents ill-conditioning of\\nthe weights, which can be symptomatic of overfitting the data.\\n2Training Error: A training error Etraincan be computed from\\nEtrain =\\ued79\\ued79xout(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79=\\ued79\\ued79Wout·r(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79(6)\\nwhere xout(t)is machine extracted data given by Eq.(3) and x(t)target data\\nobtained from the integrating the real system in Eq.(1), for t=1,...,Ntrain, and\\nwhere∥·∥denotes standard deviation.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6c496ae3-bbac-48c7-8305-ed0678c1840b', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n1Training:\\nTo train an RC model from a given initial condition x(0), we first\\nintegrate the real dynamics in Eq.(1) to obtain Ntrainadditional states\\n{x(t)}t=1,...,Ntrain.\\nWe then iterate the reservoir dynamics in Eq.(4) for Ntraintimes from\\nr(0) =0, using the training data as inputs (i.e., u(t) =x(t)). This\\nproduces a corresponding sequence of reservoir states, {r(t)}t=1,...,Ntrain.\\nFinally, we solve for the output weights Woutthat render Eq.(3) the best\\nfit to the training data using Ridge Regression with Tikhonov\\nregularization:\\nWout=XRT(RRT+λI)−1(5)\\nwhere, XandRare matrices whose columns are the x(t)andr(t),\\nrespectively, for t=1,...,Ntrain.Iis the Nres×Nresidentity matrix, and\\nλ>0 is a regularization hyperparameter that prevents ill-conditioning of\\nthe weights, which can be symptomatic of overfitting the data.\\n2Training Error: A training error Etraincan be computed from\\nEtrain =\\ued79\\ued79xout(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79=\\ued79\\ued79Wout·r(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79(6)\\nwhere xout(t)is machine extracted data given by Eq.(3) and x(t)target data\\nobtained from the integrating the real system in Eq.(1), for t=1,...,Ntrain, and\\nwhere∥·∥denotes standard deviation.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3b86983c-0a72-4e13-9a85-8bfaa6803f17', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n1Training:\\nTo train an RC model from a given initial condition x(0), we first\\nintegrate the real dynamics in Eq.(1) to obtain Ntrainadditional states\\n{x(t)}t=1,...,Ntrain.\\nWe then iterate the reservoir dynamics in Eq.(4) for Ntraintimes from\\nr(0) =0, using the training data as inputs (i.e., u(t) =x(t)). This\\nproduces a corresponding sequence of reservoir states, {r(t)}t=1,...,Ntrain.\\nFinally, we solve for the output weights Woutthat render Eq.(3) the best\\nfit to the training data using Ridge Regression with Tikhonov\\nregularization:\\nWout=XRT(RRT+λI)−1(5)\\nwhere, XandRare matrices whose columns are the x(t)andr(t),\\nrespectively, for t=1,...,Ntrain.Iis the Nres×Nresidentity matrix, and\\nλ>0 is a regularization hyperparameter that prevents ill-conditioning of\\nthe weights, which can be symptomatic of overfitting the data.\\n2Training Error: A training error Etraincan be computed from\\nEtrain =\\ued79\\ued79xout(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79=\\ued79\\ued79Wout·r(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79(6)\\nwhere xout(t)is machine extracted data given by Eq.(3) and x(t)target data\\nobtained from the integrating the real system in Eq.(1), for t=1,...,Ntrain, and\\nwhere∥·∥denotes standard deviation.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ad29fab9-e4fd-47ae-a53c-2f92a0683db8', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n1Training:\\nTo train an RC model from a given initial condition x(0), we first\\nintegrate the real dynamics in Eq.(1) to obtain Ntrainadditional states\\n{x(t)}t=1,...,Ntrain.\\nWe then iterate the reservoir dynamics in Eq.(4) for Ntraintimes from\\nr(0) =0, using the training data as inputs (i.e., u(t) =x(t)). This\\nproduces a corresponding sequence of reservoir states, {r(t)}t=1,...,Ntrain.\\nFinally, we solve for the output weights Woutthat render Eq.(3) the best\\nfit to the training data using Ridge Regression with Tikhonov\\nregularization:\\nWout=XRT(RRT+λI)−1(5)\\nwhere, XandRare matrices whose columns are the x(t)andr(t),\\nrespectively, for t=1,...,Ntrain.Iis the Nres×Nresidentity matrix, and\\nλ>0 is a regularization hyperparameter that prevents ill-conditioning of\\nthe weights, which can be symptomatic of overfitting the data.\\n2Training Error: A training error Etraincan be computed from\\nEtrain =\\ued79\\ued79xout(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79=\\ued79\\ued79Wout·r(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79(6)\\nwhere xout(t)is machine extracted data given by Eq.(3) and x(t)target data\\nobtained from the integrating the real system in Eq.(1), for t=1,...,Ntrain, and\\nwhere∥·∥denotes standard deviation.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a870783a-ef87-4e37-866c-4f2503f62855', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n3Prediction:\\nBefore prediction, it is good practice first to test the trained RC. To test a\\ntrained RC model from a given initial condition x(0), we first integrate\\nthe true dynamics Eq.(1) forward in time to obtain a total of Nwarmup≥0\\nstates{x(t)}t=1,...,Nwarmup.\\nDuring the first Nwarmupiterations of the RC dynamics of Eq.(4), the\\ninput term u(t)comes from the real trajectory (given by x(t)of Eq.(2)),\\ni.e.,u(t) =x(t).\\nThereafter, prediction starts when the reservoir system in Eq.(4) runs\\nautonomously. This is achieved by replacing the input term u(t)in Eq.(4)\\nwith the model’s own output at the previous iteration (i.e.,\\nu(t) =xout(t) =Wout·r(t)). This creates a closed-loop system given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·Wout·r(t) +b)\\n(7)\\nwhich we iterate without further input x(t)from the real system of Eq.(1).\\nThe autonomous reservoir states r(t)from Eq.(7) is used to calculate the\\npredicted output xp\\nout(t)of the input data x(t)fort>Nwarmupas:\\nxp\\nout(t) =Wout·r(t) (8)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='17fdddee-b0e3-4162-94bc-ea12788af448', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n3Prediction:\\nBefore prediction, it is good practice first to test the trained RC. To test a\\ntrained RC model from a given initial condition x(0), we first integrate\\nthe true dynamics Eq.(1) forward in time to obtain a total of Nwarmup≥0\\nstates{x(t)}t=1,...,Nwarmup.\\nDuring the first Nwarmupiterations of the RC dynamics of Eq.(4), the\\ninput term u(t)comes from the real trajectory (given by x(t)of Eq.(2)),\\ni.e.,u(t) =x(t).\\nThereafter, prediction starts when the reservoir system in Eq.(4) runs\\nautonomously. This is achieved by replacing the input term u(t)in Eq.(4)\\nwith the model’s own output at the previous iteration (i.e.,\\nu(t) =xout(t) =Wout·r(t)). This creates a closed-loop system given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·Wout·r(t) +b)\\n(7)\\nwhich we iterate without further input x(t)from the real system of Eq.(1).\\nThe autonomous reservoir states r(t)from Eq.(7) is used to calculate the\\npredicted output xp\\nout(t)of the input data x(t)fort>Nwarmupas:\\nxp\\nout(t) =Wout·r(t) (8)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='73a61cc4-6b16-4765-a289-7360023bc166', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n3Prediction:\\nBefore prediction, it is good practice first to test the trained RC. To test a\\ntrained RC model from a given initial condition x(0), we first integrate\\nthe true dynamics Eq.(1) forward in time to obtain a total of Nwarmup≥0\\nstates{x(t)}t=1,...,Nwarmup.\\nDuring the first Nwarmupiterations of the RC dynamics of Eq.(4), the\\ninput term u(t)comes from the real trajectory (given by x(t)of Eq.(2)),\\ni.e.,u(t) =x(t).\\nThereafter, prediction starts when the reservoir system in Eq.(4) runs\\nautonomously. This is achieved by replacing the input term u(t)in Eq.(4)\\nwith the model’s own output at the previous iteration (i.e.,\\nu(t) =xout(t) =Wout·r(t)). This creates a closed-loop system given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·Wout·r(t) +b)\\n(7)\\nwhich we iterate without further input x(t)from the real system of Eq.(1).\\nThe autonomous reservoir states r(t)from Eq.(7) is used to calculate the\\npredicted output xp\\nout(t)of the input data x(t)fort>Nwarmupas:\\nxp\\nout(t) =Wout·r(t) (8)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='29d65c02-afaf-4858-b4a0-950046c27b93', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n3Prediction:\\nBefore prediction, it is good practice first to test the trained RC. To test a\\ntrained RC model from a given initial condition x(0), we first integrate\\nthe true dynamics Eq.(1) forward in time to obtain a total of Nwarmup≥0\\nstates{x(t)}t=1,...,Nwarmup.\\nDuring the first Nwarmupiterations of the RC dynamics of Eq.(4), the\\ninput term u(t)comes from the real trajectory (given by x(t)of Eq.(2)),\\ni.e.,u(t) =x(t).\\nThereafter, prediction starts when the reservoir system in Eq.(4) runs\\nautonomously. This is achieved by replacing the input term u(t)in Eq.(4)\\nwith the model’s own output at the previous iteration (i.e.,\\nu(t) =xout(t) =Wout·r(t)). This creates a closed-loop system given by:\\nr(t+1) = (1−α)r(t) +αtanh(\\nWres·r(t) +Win·Wout·r(t) +b)\\n(7)\\nwhich we iterate without further input x(t)from the real system of Eq.(1).\\nThe autonomous reservoir states r(t)from Eq.(7) is used to calculate the\\npredicted output xp\\nout(t)of the input data x(t)fort>Nwarmupas:\\nxp\\nout(t) =Wout·r(t) (8)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cf6cfbd2-42b5-4d30-b946-83471c4d484e', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\n4Prediction Error: A prediction error Epredcan be computed\\nsimilarly to the training error as:\\nEpred=\\ued79\\ued79\\ued79xp\\nout(t)−x(t)\\ued79\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79=\\ued79\\ued79Wout·r(t)−x(t)\\ued79\\ued79\\n\\ued79\\ued79x(t)\\ued79\\ued79(9)\\nwhere xp\\nout(t)is machine extracted data given by Eq.(8) and\\nx(t)target data obtained from the integrating the real system\\nin Eq.(1), for t>Nwatmup, and where∥·∥denotes standard\\ndeviation.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b3e20155-c46b-4383-aa1c-ab6e91f51260', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nNOTE: The (normalized) root-mean-square error can also be used\\nto measure the training and prediction errors given in Eq.(6) and\\nEq.(9).\\nGiven an RC predicted trajectory x(t)and a corresponding trajectory of the real\\nsystem x(t)– each of length N– we calculate the root-mean-square error\\n(RMSE) as:\\nRMSE =\\ued6a\\ued6b\\ued6b√1\\nNN∑\\nt=1\\ued79\\ued79x(t)−x(t)\\ued79\\ued792(10)\\nwhere, this time,∥·∥denotes the Euclidean norm.\\nTo obtain a normalized version of this (NRMSE) – which is frequently used as\\nthe objective function to optimize standard RC hyperparameters – we divide the\\nRMSE by the range of the data in the real system i.e.,\\nNRMSE =RMSE\\nxi,max−xi,min(11)\\nwhere the maximum ( xi,max) and minimum ( xi,min) for dimension i=1,...,nof\\nthe state space are calculated over the corresponding training data.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6042b023-857c-488a-9f88-b6ecd4fd0a63', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s18.pdf', 'file_path': '/content/data/Lecture_s18.pdf', 'file_type': 'application/pdf', 'file_size': 256068, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Basics and implementation of a standard ESN Learning\\nNRMSE values range between 0 and 1, with 0 indicating a\\nperfect fit and 1 representing the worst fit. This normalized\\nscale allows for easier model performance interpretation and\\ncomparison across different contexts.\\nWhen comparing multiple models or algorithms, the NRMSE\\ncan provide a more reliable basis for model selection. By\\nnormalizing the error, the NRMSE allows for a fair comparison\\nof model performance, regardless of the specific scale or\\nvariability of the data.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='31613ed4-c409-4331-a17f-b7b75092ee25', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 19:\\nLiquid State Machines (LSMs)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='72bb5a12-a966-4133-bd1f-5929fd4bf063', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives\\n1Understand the architecture of Liquid-state Machine\\n2Understand the baseline working principle of Liquid-State\\nMachines\\n3Understand the properties of a good Liquid-state Machine\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ef72aeeb-4b49-4e04-9fb1-182fcf263024', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nLike ESNs, an LSM is a reservoir computing model for processing information in\\na recurrent neural network architecture.\\nIn biological circuits, individual neurons lack the capacity to process intricate\\ninput information. Instead, neural microcircuits serve as a computational\\nfoundation. The concept of microcircuit computing, known as the Liquid State\\nMachine (LSM), was introduced by Wolfgang Maass in 2002.\\nEssentially, the brain cortex or a specific area of it is treated as a \"liquid.\" These\\ncortical microcircuits exhibit remarkable computational abilities when confronted\\nwith perturbations. These microcircuits possess diverse elements, such as\\nneurons and synapses, along with a variety of mechanisms and time constants\\nthat define their interactions, including recurrent connections.\\nTo illustrate the LSM approach, consider a sequence of temporary disruptions\\napplied to an excitable medium, similar to sounds, objects dropped into a liquid\\nor wind gusts. By treating the liquid as an attractor neural network, its resting\\nstate becomes the sole attractor. However, perturbed states of the liquid\\nrepresent both current and past inputs, carrying valuable information for\\nanalyzing the surrounding environment.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f88a9b9b-07dd-4e0c-9476-c33f2746df10', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nLike ESNs, an LSM is a reservoir computing model for processing information in\\na recurrent neural network architecture.\\nIn biological circuits, individual neurons lack the capacity to process intricate\\ninput information. Instead, neural microcircuits serve as a computational\\nfoundation. The concept of microcircuit computing, known as the Liquid State\\nMachine (LSM), was introduced by Wolfgang Maass in 2002.\\nEssentially, the brain cortex or a specific area of it is treated as a \"liquid.\" These\\ncortical microcircuits exhibit remarkable computational abilities when confronted\\nwith perturbations. These microcircuits possess diverse elements, such as\\nneurons and synapses, along with a variety of mechanisms and time constants\\nthat define their interactions, including recurrent connections.\\nTo illustrate the LSM approach, consider a sequence of temporary disruptions\\napplied to an excitable medium, similar to sounds, objects dropped into a liquid\\nor wind gusts. By treating the liquid as an attractor neural network, its resting\\nstate becomes the sole attractor. However, perturbed states of the liquid\\nrepresent both current and past inputs, carrying valuable information for\\nanalyzing the surrounding environment.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8553404b-7e7b-429a-8163-855af3981937', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nLike ESNs, an LSM is a reservoir computing model for processing information in\\na recurrent neural network architecture.\\nIn biological circuits, individual neurons lack the capacity to process intricate\\ninput information. Instead, neural microcircuits serve as a computational\\nfoundation. The concept of microcircuit computing, known as the Liquid State\\nMachine (LSM), was introduced by Wolfgang Maass in 2002.\\nEssentially, the brain cortex or a specific area of it is treated as a \"liquid.\" These\\ncortical microcircuits exhibit remarkable computational abilities when confronted\\nwith perturbations. These microcircuits possess diverse elements, such as\\nneurons and synapses, along with a variety of mechanisms and time constants\\nthat define their interactions, including recurrent connections.\\nTo illustrate the LSM approach, consider a sequence of temporary disruptions\\napplied to an excitable medium, similar to sounds, objects dropped into a liquid\\nor wind gusts. By treating the liquid as an attractor neural network, its resting\\nstate becomes the sole attractor. However, perturbed states of the liquid\\nrepresent both current and past inputs, carrying valuable information for\\nanalyzing the surrounding environment.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d27cd659-4313-4b61-976b-d7129d288141', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nLike ESNs, an LSM is a reservoir computing model for processing information in\\na recurrent neural network architecture.\\nIn biological circuits, individual neurons lack the capacity to process intricate\\ninput information. Instead, neural microcircuits serve as a computational\\nfoundation. The concept of microcircuit computing, known as the Liquid State\\nMachine (LSM), was introduced by Wolfgang Maass in 2002.\\nEssentially, the brain cortex or a specific area of it is treated as a \"liquid.\" These\\ncortical microcircuits exhibit remarkable computational abilities when confronted\\nwith perturbations. These microcircuits possess diverse elements, such as\\nneurons and synapses, along with a variety of mechanisms and time constants\\nthat define their interactions, including recurrent connections.\\nTo illustrate the LSM approach, consider a sequence of temporary disruptions\\napplied to an excitable medium, similar to sounds, objects dropped into a liquid\\nor wind gusts. By treating the liquid as an attractor neural network, its resting\\nstate becomes the sole attractor. However, perturbed states of the liquid\\nrepresent both current and past inputs, carrying valuable information for\\nanalyzing the surrounding environment.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cf7de413-8c2e-4b5c-baa1-ea08b1f36e28', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn contrast to other models, the Liquid State Machine (LSM) is specifically\\ndesigned for real-time computations on continuous streams of data. These data\\nstreams consist of spike trains, which are sequences of action potentials from\\nneurons that serve as inputs to a cortical microcircuit, i.e., a network of\\ninterconnected neurons within the cerebral cortex, the brain’s outer layer\\nresponsible for many higher-order functions such as perception, cognition, and\\nmotor control. These microcircuits are the fundamental units of cortical\\nprocessing, playing a crucial role in how the brain interprets and responds to\\ninformation.\\nCortical microcircuits are also organized into vertical structures called cortical\\ncolumns or minicolumns. Each column is thought to represent a basic functional\\nunit of the cortex, processing a specific type of information.\\nIn the LSM framework, both the inputs and outputs are treated as\\ncontinuous-time data streams. Mathematically, these inputs and outputs are\\nrepresented as functions u(t)andy(t)that operate in continuous time.\\nThese functions are typically multidimensional because they capture spike trains\\nfrom multiple external neurons providing inputs to the circuit and involve various\\nreadouts that extract output spike trains. Since an LSM maps input streams\\nu(·)to output streams y(·), it is often described as implementing a functional or\\noperator, akin to a filter. From a mathematical perspective, it represents a\\nfunction that operates on objects of a higher type than numbers or bits.\\nOne notable characteristic of this higher-type computational processing is that\\nthe output stream’s target value, y(t), at a given time t, may depend on the\\ninput stream’s values, u(s), at many (potentially even infinitely many) preceding\\ntime points s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='379b34de-f52d-4ae9-a47b-6bcc92e64875', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn contrast to other models, the Liquid State Machine (LSM) is specifically\\ndesigned for real-time computations on continuous streams of data. These data\\nstreams consist of spike trains, which are sequences of action potentials from\\nneurons that serve as inputs to a cortical microcircuit, i.e., a network of\\ninterconnected neurons within the cerebral cortex, the brain’s outer layer\\nresponsible for many higher-order functions such as perception, cognition, and\\nmotor control. These microcircuits are the fundamental units of cortical\\nprocessing, playing a crucial role in how the brain interprets and responds to\\ninformation.\\nCortical microcircuits are also organized into vertical structures called cortical\\ncolumns or minicolumns. Each column is thought to represent a basic functional\\nunit of the cortex, processing a specific type of information.\\nIn the LSM framework, both the inputs and outputs are treated as\\ncontinuous-time data streams. Mathematically, these inputs and outputs are\\nrepresented as functions u(t)andy(t)that operate in continuous time.\\nThese functions are typically multidimensional because they capture spike trains\\nfrom multiple external neurons providing inputs to the circuit and involve various\\nreadouts that extract output spike trains. Since an LSM maps input streams\\nu(·)to output streams y(·), it is often described as implementing a functional or\\noperator, akin to a filter. From a mathematical perspective, it represents a\\nfunction that operates on objects of a higher type than numbers or bits.\\nOne notable characteristic of this higher-type computational processing is that\\nthe output stream’s target value, y(t), at a given time t, may depend on the\\ninput stream’s values, u(s), at many (potentially even infinitely many) preceding\\ntime points s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3613de47-c833-402f-a439-645adf99d1dd', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn contrast to other models, the Liquid State Machine (LSM) is specifically\\ndesigned for real-time computations on continuous streams of data. These data\\nstreams consist of spike trains, which are sequences of action potentials from\\nneurons that serve as inputs to a cortical microcircuit, i.e., a network of\\ninterconnected neurons within the cerebral cortex, the brain’s outer layer\\nresponsible for many higher-order functions such as perception, cognition, and\\nmotor control. These microcircuits are the fundamental units of cortical\\nprocessing, playing a crucial role in how the brain interprets and responds to\\ninformation.\\nCortical microcircuits are also organized into vertical structures called cortical\\ncolumns or minicolumns. Each column is thought to represent a basic functional\\nunit of the cortex, processing a specific type of information.\\nIn the LSM framework, both the inputs and outputs are treated as\\ncontinuous-time data streams. Mathematically, these inputs and outputs are\\nrepresented as functions u(t)andy(t)that operate in continuous time.\\nThese functions are typically multidimensional because they capture spike trains\\nfrom multiple external neurons providing inputs to the circuit and involve various\\nreadouts that extract output spike trains. Since an LSM maps input streams\\nu(·)to output streams y(·), it is often described as implementing a functional or\\noperator, akin to a filter. From a mathematical perspective, it represents a\\nfunction that operates on objects of a higher type than numbers or bits.\\nOne notable characteristic of this higher-type computational processing is that\\nthe output stream’s target value, y(t), at a given time t, may depend on the\\ninput stream’s values, u(s), at many (potentially even infinitely many) preceding\\ntime points s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4947bd24-9a5c-40fa-b36a-66971a584b4a', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn contrast to other models, the Liquid State Machine (LSM) is specifically\\ndesigned for real-time computations on continuous streams of data. These data\\nstreams consist of spike trains, which are sequences of action potentials from\\nneurons that serve as inputs to a cortical microcircuit, i.e., a network of\\ninterconnected neurons within the cerebral cortex, the brain’s outer layer\\nresponsible for many higher-order functions such as perception, cognition, and\\nmotor control. These microcircuits are the fundamental units of cortical\\nprocessing, playing a crucial role in how the brain interprets and responds to\\ninformation.\\nCortical microcircuits are also organized into vertical structures called cortical\\ncolumns or minicolumns. Each column is thought to represent a basic functional\\nunit of the cortex, processing a specific type of information.\\nIn the LSM framework, both the inputs and outputs are treated as\\ncontinuous-time data streams. Mathematically, these inputs and outputs are\\nrepresented as functions u(t)andy(t)that operate in continuous time.\\nThese functions are typically multidimensional because they capture spike trains\\nfrom multiple external neurons providing inputs to the circuit and involve various\\nreadouts that extract output spike trains. Since an LSM maps input streams\\nu(·)to output streams y(·), it is often described as implementing a functional or\\noperator, akin to a filter. From a mathematical perspective, it represents a\\nfunction that operates on objects of a higher type than numbers or bits.\\nOne notable characteristic of this higher-type computational processing is that\\nthe output stream’s target value, y(t), at a given time t, may depend on the\\ninput stream’s values, u(s), at many (potentially even infinitely many) preceding\\ntime points s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='479d38dd-5521-4373-ad4d-2770b6326022', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn contrast to other models, the Liquid State Machine (LSM) is specifically\\ndesigned for real-time computations on continuous streams of data. These data\\nstreams consist of spike trains, which are sequences of action potentials from\\nneurons that serve as inputs to a cortical microcircuit, i.e., a network of\\ninterconnected neurons within the cerebral cortex, the brain’s outer layer\\nresponsible for many higher-order functions such as perception, cognition, and\\nmotor control. These microcircuits are the fundamental units of cortical\\nprocessing, playing a crucial role in how the brain interprets and responds to\\ninformation.\\nCortical microcircuits are also organized into vertical structures called cortical\\ncolumns or minicolumns. Each column is thought to represent a basic functional\\nunit of the cortex, processing a specific type of information.\\nIn the LSM framework, both the inputs and outputs are treated as\\ncontinuous-time data streams. Mathematically, these inputs and outputs are\\nrepresented as functions u(t)andy(t)that operate in continuous time.\\nThese functions are typically multidimensional because they capture spike trains\\nfrom multiple external neurons providing inputs to the circuit and involve various\\nreadouts that extract output spike trains. Since an LSM maps input streams\\nu(·)to output streams y(·), it is often described as implementing a functional or\\noperator, akin to a filter. From a mathematical perspective, it represents a\\nfunction that operates on objects of a higher type than numbers or bits.\\nOne notable characteristic of this higher-type computational processing is that\\nthe output stream’s target value, y(t), at a given time t, may depend on the\\ninput stream’s values, u(s), at many (potentially even infinitely many) preceding\\ntime points s.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7ebfca1b-4f2f-4a60-9650-7af9cc88c332', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn biological information processing models, a typical readout consists of a single\\nneuron, referred to as a projection neuron in neuroscience. This neuron extracts\\ninformation from a local microcircuit and transmits it to other microcircuits\\nwithin the brain, whether in the same region or elsewhere.\\nVarious methods can be used to model this readout neuron, such as a linear\\ngate, a perceptron with a threshold, a sigmoidal gate, or a spiking neuron. The\\nmain purpose of the LSM (referred to as the \"Liquid\") is to act as a\\npre-processor for this readout neuron, expanding the range of possible functions\\nthat it can learn from input streams u(t).\\nThis division of computational processing into the Liquid and the readout is\\nhighly efficient because the same Liquid can serve multiple readout neurons,\\neach learning to extract a distinct \"summary\" of information from the same\\nLiquid.\\nThe need to extract different information summaries from a cortical microcircuit\\narises due to different computational objectives, such as determining the\\nmovement direction of objects or identifying object identities when u(t)\\nrepresents visual inputs.\\nNeurophysiological data indicates that spike trains from different projection\\nneurons in the same column are generally weakly correlated with natural stimuli.\\nTherefore, the LSM serves as a model for multiplexing diverse computations on\\na shared input stream u(t).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='68e1c296-38d0-48f7-a3a5-d141ef181fbf', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn biological information processing models, a typical readout consists of a single\\nneuron, referred to as a projection neuron in neuroscience. This neuron extracts\\ninformation from a local microcircuit and transmits it to other microcircuits\\nwithin the brain, whether in the same region or elsewhere.\\nVarious methods can be used to model this readout neuron, such as a linear\\ngate, a perceptron with a threshold, a sigmoidal gate, or a spiking neuron. The\\nmain purpose of the LSM (referred to as the \"Liquid\") is to act as a\\npre-processor for this readout neuron, expanding the range of possible functions\\nthat it can learn from input streams u(t).\\nThis division of computational processing into the Liquid and the readout is\\nhighly efficient because the same Liquid can serve multiple readout neurons,\\neach learning to extract a distinct \"summary\" of information from the same\\nLiquid.\\nThe need to extract different information summaries from a cortical microcircuit\\narises due to different computational objectives, such as determining the\\nmovement direction of objects or identifying object identities when u(t)\\nrepresents visual inputs.\\nNeurophysiological data indicates that spike trains from different projection\\nneurons in the same column are generally weakly correlated with natural stimuli.\\nTherefore, the LSM serves as a model for multiplexing diverse computations on\\na shared input stream u(t).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='392f6804-9653-47b5-9b37-00dcdd721416', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn biological information processing models, a typical readout consists of a single\\nneuron, referred to as a projection neuron in neuroscience. This neuron extracts\\ninformation from a local microcircuit and transmits it to other microcircuits\\nwithin the brain, whether in the same region or elsewhere.\\nVarious methods can be used to model this readout neuron, such as a linear\\ngate, a perceptron with a threshold, a sigmoidal gate, or a spiking neuron. The\\nmain purpose of the LSM (referred to as the \"Liquid\") is to act as a\\npre-processor for this readout neuron, expanding the range of possible functions\\nthat it can learn from input streams u(t).\\nThis division of computational processing into the Liquid and the readout is\\nhighly efficient because the same Liquid can serve multiple readout neurons,\\neach learning to extract a distinct \"summary\" of information from the same\\nLiquid.\\nThe need to extract different information summaries from a cortical microcircuit\\narises due to different computational objectives, such as determining the\\nmovement direction of objects or identifying object identities when u(t)\\nrepresents visual inputs.\\nNeurophysiological data indicates that spike trains from different projection\\nneurons in the same column are generally weakly correlated with natural stimuli.\\nTherefore, the LSM serves as a model for multiplexing diverse computations on\\na shared input stream u(t).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e49717d6-73d2-4c47-a002-8d927225f767', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn biological information processing models, a typical readout consists of a single\\nneuron, referred to as a projection neuron in neuroscience. This neuron extracts\\ninformation from a local microcircuit and transmits it to other microcircuits\\nwithin the brain, whether in the same region or elsewhere.\\nVarious methods can be used to model this readout neuron, such as a linear\\ngate, a perceptron with a threshold, a sigmoidal gate, or a spiking neuron. The\\nmain purpose of the LSM (referred to as the \"Liquid\") is to act as a\\npre-processor for this readout neuron, expanding the range of possible functions\\nthat it can learn from input streams u(t).\\nThis division of computational processing into the Liquid and the readout is\\nhighly efficient because the same Liquid can serve multiple readout neurons,\\neach learning to extract a distinct \"summary\" of information from the same\\nLiquid.\\nThe need to extract different information summaries from a cortical microcircuit\\narises due to different computational objectives, such as determining the\\nmovement direction of objects or identifying object identities when u(t)\\nrepresents visual inputs.\\nNeurophysiological data indicates that spike trains from different projection\\nneurons in the same column are generally weakly correlated with natural stimuli.\\nTherefore, the LSM serves as a model for multiplexing diverse computations on\\na shared input stream u(t).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9118dada-3b45-47e2-904a-fc7a9d1c4395', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nThe model of a LSM is based on a strict mathematical framework that\\nguarantees, under ideal conditions, universal computational power.\\nThe figure below shows only one input and output channel for simplicity. A\\nliquid-state machine consists of three main components. The first component is\\na layer of input neurons where an external stimulus is introduced. The signal\\nfrom this component is transmitted to the selected neurons of the second\\ncomponent, called the liquid column denoted that LM, where the proper neural\\ncomputation takes place.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='41257a20-c25f-4d7d-aabe-7b0d7ea3fcf1', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nThe model of a LSM is based on a strict mathematical framework that\\nguarantees, under ideal conditions, universal computational power.\\nThe figure below shows only one input and output channel for simplicity. A\\nliquid-state machine consists of three main components. The first component is\\na layer of input neurons where an external stimulus is introduced. The signal\\nfrom this component is transmitted to the selected neurons of the second\\ncomponent, called the liquid column denoted that LM, where the proper neural\\ncomputation takes place.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='35cd6060-a774-4810-b1c2-1c2ddb80c410', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn mathematical terms, the liquid state is simply the current output of some\\noperator or filter LMthat maps input functions u(·)onto functions xM(t):\\nxM(t) =(\\nLMu)\\n(t) (1)\\nThe liquid component of the system receives a continuous input stream,\\ndenoted as u(s). As time progresses, specifically at a later time t>s, the\\ncurrent internal state xM(t)of the liquid holds a significant amount of\\ninformation regarding the recent inputs u(s). This current liquid state xM(t)is\\nthen transmitted to the final component of the liquid-state machine. This\\ncomponent is referred to as a memory-less readout map, denoted as fM,\\nmeaning that it has no access to any states prior to time t.\\nThe readout map performs an analysis and interpretation of the liquid’s\\ncalculations. Ultimately, the input signal is transformed by the readout map,\\nresulting in the system’s output y(t)given by:\\ny(t) =fM(\\nxM(t))\\n. (2)\\nThe structure of the readout map, fM, is not explicitly provided, allowing for\\nthe utilization of various statistical analysis or pattern recognition methods that\\nare available (e.g. linear regression, stochastic gradient descent, etc).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ee418c3d-73f1-4cca-97b0-adaf55b1e98a', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn mathematical terms, the liquid state is simply the current output of some\\noperator or filter LMthat maps input functions u(·)onto functions xM(t):\\nxM(t) =(\\nLMu)\\n(t) (1)\\nThe liquid component of the system receives a continuous input stream,\\ndenoted as u(s). As time progresses, specifically at a later time t>s, the\\ncurrent internal state xM(t)of the liquid holds a significant amount of\\ninformation regarding the recent inputs u(s). This current liquid state xM(t)is\\nthen transmitted to the final component of the liquid-state machine. This\\ncomponent is referred to as a memory-less readout map, denoted as fM,\\nmeaning that it has no access to any states prior to time t.\\nThe readout map performs an analysis and interpretation of the liquid’s\\ncalculations. Ultimately, the input signal is transformed by the readout map,\\nresulting in the system’s output y(t)given by:\\ny(t) =fM(\\nxM(t))\\n. (2)\\nThe structure of the readout map, fM, is not explicitly provided, allowing for\\nthe utilization of various statistical analysis or pattern recognition methods that\\nare available (e.g. linear regression, stochastic gradient descent, etc).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b50cb879-29d6-4e10-95f9-bc556b55e8c5', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn mathematical terms, the liquid state is simply the current output of some\\noperator or filter LMthat maps input functions u(·)onto functions xM(t):\\nxM(t) =(\\nLMu)\\n(t) (1)\\nThe liquid component of the system receives a continuous input stream,\\ndenoted as u(s). As time progresses, specifically at a later time t>s, the\\ncurrent internal state xM(t)of the liquid holds a significant amount of\\ninformation regarding the recent inputs u(s). This current liquid state xM(t)is\\nthen transmitted to the final component of the liquid-state machine. This\\ncomponent is referred to as a memory-less readout map, denoted as fM,\\nmeaning that it has no access to any states prior to time t.\\nThe readout map performs an analysis and interpretation of the liquid’s\\ncalculations. Ultimately, the input signal is transformed by the readout map,\\nresulting in the system’s output y(t)given by:\\ny(t) =fM(\\nxM(t))\\n. (2)\\nThe structure of the readout map, fM, is not explicitly provided, allowing for\\nthe utilization of various statistical analysis or pattern recognition methods that\\nare available (e.g. linear regression, stochastic gradient descent, etc).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4b84452e-0a6b-4506-8d18-4c8353ebefd8', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Introduction: Liquid State Machines (LSMs)\\nIn mathematical terms, the liquid state is simply the current output of some\\noperator or filter LMthat maps input functions u(·)onto functions xM(t):\\nxM(t) =(\\nLMu)\\n(t) (1)\\nThe liquid component of the system receives a continuous input stream,\\ndenoted as u(s). As time progresses, specifically at a later time t>s, the\\ncurrent internal state xM(t)of the liquid holds a significant amount of\\ninformation regarding the recent inputs u(s). This current liquid state xM(t)is\\nthen transmitted to the final component of the liquid-state machine. This\\ncomponent is referred to as a memory-less readout map, denoted as fM,\\nmeaning that it has no access to any states prior to time t.\\nThe readout map performs an analysis and interpretation of the liquid’s\\ncalculations. Ultimately, the input signal is transformed by the readout map,\\nresulting in the system’s output y(t)given by:\\ny(t) =fM(\\nxM(t))\\n. (2)\\nThe structure of the readout map, fM, is not explicitly provided, allowing for\\nthe utilization of various statistical analysis or pattern recognition methods that\\nare available (e.g. linear regression, stochastic gradient descent, etc).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0066801f-fb1a-416f-9c10-fc3700536908', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nThe fundamental characteristic of an LSM lies in its capacity to generate\\ndistinct responses to different input patterns. This ability, known as \"the\\nseparation property\" of the liquid, plays a pivotal role.\\nOn the other hand, the \"approximation property\" refers to the capability of the\\nreadout maps to differentiate these responses, generalize them, and establish a\\nconnection with the given output.\\nThe approximation property primarily relies on the adaptive nature of the\\nreadout map, while the separation property is directly influenced by the\\ncomplexity of the liquid itself.\\nDifferentiating between two liquid states or comparing the responses of a Liquid\\nState Machine to two stimuli presents a challenging task. There is no definitive\\nmeasure of the distance between liquid states or input patterns. Due to the\\nhighly dynamic and non-linear nature of liquid states, it becomes evident that a\\nstraightforward \"one-to-one\" mapping of two states is not feasible. Even a slight\\nvariation in the input pattern can result in a significant disparity in the liquid’s\\nresponse.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e8b089a3-40fb-4d5a-9469-94e4ebb26f0c', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nThe fundamental characteristic of an LSM lies in its capacity to generate\\ndistinct responses to different input patterns. This ability, known as \"the\\nseparation property\" of the liquid, plays a pivotal role.\\nOn the other hand, the \"approximation property\" refers to the capability of the\\nreadout maps to differentiate these responses, generalize them, and establish a\\nconnection with the given output.\\nThe approximation property primarily relies on the adaptive nature of the\\nreadout map, while the separation property is directly influenced by the\\ncomplexity of the liquid itself.\\nDifferentiating between two liquid states or comparing the responses of a Liquid\\nState Machine to two stimuli presents a challenging task. There is no definitive\\nmeasure of the distance between liquid states or input patterns. Due to the\\nhighly dynamic and non-linear nature of liquid states, it becomes evident that a\\nstraightforward \"one-to-one\" mapping of two states is not feasible. Even a slight\\nvariation in the input pattern can result in a significant disparity in the liquid’s\\nresponse.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b73c745e-ebf5-46d4-9123-2c8e24fab752', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nThe fundamental characteristic of an LSM lies in its capacity to generate\\ndistinct responses to different input patterns. This ability, known as \"the\\nseparation property\" of the liquid, plays a pivotal role.\\nOn the other hand, the \"approximation property\" refers to the capability of the\\nreadout maps to differentiate these responses, generalize them, and establish a\\nconnection with the given output.\\nThe approximation property primarily relies on the adaptive nature of the\\nreadout map, while the separation property is directly influenced by the\\ncomplexity of the liquid itself.\\nDifferentiating between two liquid states or comparing the responses of a Liquid\\nState Machine to two stimuli presents a challenging task. There is no definitive\\nmeasure of the distance between liquid states or input patterns. Due to the\\nhighly dynamic and non-linear nature of liquid states, it becomes evident that a\\nstraightforward \"one-to-one\" mapping of two states is not feasible. Even a slight\\nvariation in the input pattern can result in a significant disparity in the liquid’s\\nresponse.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a319c171-8aa9-4cf9-8186-2a7c642a5b4f', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nHowever, certain basic comparisons, such as the Euclidean norm, can offer\\ninsights into the distance between liquid trajectories for two input patterns. The\\nEuclidean distance, formally calculated using the following formula, determines\\nthe distance between liquid states for all recorded time steps:\\nEI1I2(t) =\\ued6a\\ued6b\\ued6b√n∑\\ni=1(\\nyI1\\ni(t)−yI2\\ni(t))2(3)\\nwhere nstands for the number of neurons in the liquid, yI1\\ni(t)andyI2\\ni(t)are the\\nith neuron activity (the neuron activity is usually the spiking times) measured in\\ntime tafter presenting I1andI2inputs, respectively.\\nIn order to investigate the information flow in LSMs a global entropy (denoted\\nasS) concept based on the classical definition of Shannon’s informational\\nentropy, can be used. Simulating liquid for a duration of Tand obtaining N\\nspikes on the readout, the probability of having nispikes occurring during a\\nperiod tiof e.g., ti=T/100 is:\\npi=ni\\nN(4)\\nSuch a probability can be interpreted as a chance of giving the whole\\ninformation in tipart of time T.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0691c515-ece4-4145-b66a-fdf5d51766a0', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nHowever, certain basic comparisons, such as the Euclidean norm, can offer\\ninsights into the distance between liquid trajectories for two input patterns. The\\nEuclidean distance, formally calculated using the following formula, determines\\nthe distance between liquid states for all recorded time steps:\\nEI1I2(t) =\\ued6a\\ued6b\\ued6b√n∑\\ni=1(\\nyI1\\ni(t)−yI2\\ni(t))2(3)\\nwhere nstands for the number of neurons in the liquid, yI1\\ni(t)andyI2\\ni(t)are the\\nith neuron activity (the neuron activity is usually the spiking times) measured in\\ntime tafter presenting I1andI2inputs, respectively.\\nIn order to investigate the information flow in LSMs a global entropy (denoted\\nasS) concept based on the classical definition of Shannon’s informational\\nentropy, can be used. Simulating liquid for a duration of Tand obtaining N\\nspikes on the readout, the probability of having nispikes occurring during a\\nperiod tiof e.g., ti=T/100 is:\\npi=ni\\nN(4)\\nSuch a probability can be interpreted as a chance of giving the whole\\ninformation in tipart of time T.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='781f39e4-04c7-4eb1-9b72-0cd34d89a0a9', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nHowever, certain basic comparisons, such as the Euclidean norm, can offer\\ninsights into the distance between liquid trajectories for two input patterns. The\\nEuclidean distance, formally calculated using the following formula, determines\\nthe distance between liquid states for all recorded time steps:\\nEI1I2(t) =\\ued6a\\ued6b\\ued6b√n∑\\ni=1(\\nyI1\\ni(t)−yI2\\ni(t))2(3)\\nwhere nstands for the number of neurons in the liquid, yI1\\ni(t)andyI2\\ni(t)are the\\nith neuron activity (the neuron activity is usually the spiking times) measured in\\ntime tafter presenting I1andI2inputs, respectively.\\nIn order to investigate the information flow in LSMs a global entropy (denoted\\nasS) concept based on the classical definition of Shannon’s informational\\nentropy, can be used. Simulating liquid for a duration of Tand obtaining N\\nspikes on the readout, the probability of having nispikes occurring during a\\nperiod tiof e.g., ti=T/100 is:\\npi=ni\\nN(4)\\nSuch a probability can be interpreted as a chance of giving the whole\\ninformation in tipart of time T.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='32f6d11c-4760-4e89-a825-020818d3c9a9', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nUsing probability pi, partial entropy can be defined as:\\nSi\\n0=−pi·ln(pi) (5)\\nand global entropy as:\\nS=∑\\ni=1Si\\n0=−∑\\ni=1pi·ln(pi) (6)\\nIn information theory. Shannon’s entropy is a measure that quantifies the\\namount of uncertainty or unpredictability in a set of data or information. High\\nentropy indicates a high degree of randomness and complexity in the system’s\\nstates. Systems with high entropy can explore a larger state space, which may\\nimprove their ability to learn complex functions.\\nIn general, the measure of global entropy helps in evaluating the capability of\\nthe system to represent the information contained in the data properly, and its\\nhigh index is a cue that the system is able to capture the useful information\\navailable in input.\\nA neural network model should have a large Euclidean distance EI1I2(t)(good\\nseparability property) and a large global entropy S(to capture the useful\\ninformation from the input) for it to use as a liquid. Research has shown that\\nleaky integrate-and-fire, Morris-Lecar, resonate-and-fire, and Hindmarsh-Rose\\nneuron models are good candidates for LSMs.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5aa16de5-c640-4e0a-9725-1cb23cf2112a', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nUsing probability pi, partial entropy can be defined as:\\nSi\\n0=−pi·ln(pi) (5)\\nand global entropy as:\\nS=∑\\ni=1Si\\n0=−∑\\ni=1pi·ln(pi) (6)\\nIn information theory. Shannon’s entropy is a measure that quantifies the\\namount of uncertainty or unpredictability in a set of data or information. High\\nentropy indicates a high degree of randomness and complexity in the system’s\\nstates. Systems with high entropy can explore a larger state space, which may\\nimprove their ability to learn complex functions.\\nIn general, the measure of global entropy helps in evaluating the capability of\\nthe system to represent the information contained in the data properly, and its\\nhigh index is a cue that the system is able to capture the useful information\\navailable in input.\\nA neural network model should have a large Euclidean distance EI1I2(t)(good\\nseparability property) and a large global entropy S(to capture the useful\\ninformation from the input) for it to use as a liquid. Research has shown that\\nleaky integrate-and-fire, Morris-Lecar, resonate-and-fire, and Hindmarsh-Rose\\nneuron models are good candidates for LSMs.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='644246bf-41e5-4718-81d6-f2695ab3b916', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nUsing probability pi, partial entropy can be defined as:\\nSi\\n0=−pi·ln(pi) (5)\\nand global entropy as:\\nS=∑\\ni=1Si\\n0=−∑\\ni=1pi·ln(pi) (6)\\nIn information theory. Shannon’s entropy is a measure that quantifies the\\namount of uncertainty or unpredictability in a set of data or information. High\\nentropy indicates a high degree of randomness and complexity in the system’s\\nstates. Systems with high entropy can explore a larger state space, which may\\nimprove their ability to learn complex functions.\\nIn general, the measure of global entropy helps in evaluating the capability of\\nthe system to represent the information contained in the data properly, and its\\nhigh index is a cue that the system is able to capture the useful information\\navailable in input.\\nA neural network model should have a large Euclidean distance EI1I2(t)(good\\nseparability property) and a large global entropy S(to capture the useful\\ninformation from the input) for it to use as a liquid. Research has shown that\\nleaky integrate-and-fire, Morris-Lecar, resonate-and-fire, and Hindmarsh-Rose\\nneuron models are good candidates for LSMs.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b0f66de6-4db5-40c7-9bb0-b8b15d0450da', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of a good Liquid State Machines (LSMs)\\nUsing probability pi, partial entropy can be defined as:\\nSi\\n0=−pi·ln(pi) (5)\\nand global entropy as:\\nS=∑\\ni=1Si\\n0=−∑\\ni=1pi·ln(pi) (6)\\nIn information theory. Shannon’s entropy is a measure that quantifies the\\namount of uncertainty or unpredictability in a set of data or information. High\\nentropy indicates a high degree of randomness and complexity in the system’s\\nstates. Systems with high entropy can explore a larger state space, which may\\nimprove their ability to learn complex functions.\\nIn general, the measure of global entropy helps in evaluating the capability of\\nthe system to represent the information contained in the data properly, and its\\nhigh index is a cue that the system is able to capture the useful information\\navailable in input.\\nA neural network model should have a large Euclidean distance EI1I2(t)(good\\nseparability property) and a large global entropy S(to capture the useful\\ninformation from the input) for it to use as a liquid. Research has shown that\\nleaky integrate-and-fire, Morris-Lecar, resonate-and-fire, and Hindmarsh-Rose\\nneuron models are good candidates for LSMs.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='caea8143-066a-4cbf-8060-8fcddc116ba6', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nAs already mentioned, an LSM consists of three distinct parts: an\\ninput layer, a liquid, and an output layer.\\nThe input layer consists of spike generator neurons having the same\\ndimensionality as the input.\\nInput neurons connect randomly in a feedforward fashion to\\nexcitatory neurons in the liquid. We use a constant number of\\nsynapses ninpsynbetween the input neurons and the liquid.\\nThe liquid consists of N(=nexc+ninh) randomly connected neurons\\n(e.g., leaky integrate-and-fire neurons), 80 %of which are excitatory\\nand 20 %inhibitory. The visual cortex biologically inspires such\\nproportion. The liquid neuron parameters are usually the standard\\nparameter values given to the neuron model under consideration.\\nDecorrelation (to induce suitable separability property) between\\nliquid neurons is introduced by drawing synaptic delays, current\\nbias, and connection strengths from a probability distribution.\\nWe connect nrecexcitatory liquid neurons all-to-all to perfect linear\\nreadout neurons in a feedforward fashion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e295ed67-f150-4f66-8b13-c94241128246', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nAs already mentioned, an LSM consists of three distinct parts: an\\ninput layer, a liquid, and an output layer.\\nThe input layer consists of spike generator neurons having the same\\ndimensionality as the input.\\nInput neurons connect randomly in a feedforward fashion to\\nexcitatory neurons in the liquid. We use a constant number of\\nsynapses ninpsynbetween the input neurons and the liquid.\\nThe liquid consists of N(=nexc+ninh) randomly connected neurons\\n(e.g., leaky integrate-and-fire neurons), 80 %of which are excitatory\\nand 20 %inhibitory. The visual cortex biologically inspires such\\nproportion. The liquid neuron parameters are usually the standard\\nparameter values given to the neuron model under consideration.\\nDecorrelation (to induce suitable separability property) between\\nliquid neurons is introduced by drawing synaptic delays, current\\nbias, and connection strengths from a probability distribution.\\nWe connect nrecexcitatory liquid neurons all-to-all to perfect linear\\nreadout neurons in a feedforward fashion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='69ecdf92-0345-4c93-9429-889dbbf6656e', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nAs already mentioned, an LSM consists of three distinct parts: an\\ninput layer, a liquid, and an output layer.\\nThe input layer consists of spike generator neurons having the same\\ndimensionality as the input.\\nInput neurons connect randomly in a feedforward fashion to\\nexcitatory neurons in the liquid. We use a constant number of\\nsynapses ninpsynbetween the input neurons and the liquid.\\nThe liquid consists of N(=nexc+ninh) randomly connected neurons\\n(e.g., leaky integrate-and-fire neurons), 80 %of which are excitatory\\nand 20 %inhibitory. The visual cortex biologically inspires such\\nproportion. The liquid neuron parameters are usually the standard\\nparameter values given to the neuron model under consideration.\\nDecorrelation (to induce suitable separability property) between\\nliquid neurons is introduced by drawing synaptic delays, current\\nbias, and connection strengths from a probability distribution.\\nWe connect nrecexcitatory liquid neurons all-to-all to perfect linear\\nreadout neurons in a feedforward fashion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e2179b1e-9674-4de1-8138-cbbc3cdbb71a', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nAs already mentioned, an LSM consists of three distinct parts: an\\ninput layer, a liquid, and an output layer.\\nThe input layer consists of spike generator neurons having the same\\ndimensionality as the input.\\nInput neurons connect randomly in a feedforward fashion to\\nexcitatory neurons in the liquid. We use a constant number of\\nsynapses ninpsynbetween the input neurons and the liquid.\\nThe liquid consists of N(=nexc+ninh) randomly connected neurons\\n(e.g., leaky integrate-and-fire neurons), 80 %of which are excitatory\\nand 20 %inhibitory. The visual cortex biologically inspires such\\nproportion. The liquid neuron parameters are usually the standard\\nparameter values given to the neuron model under consideration.\\nDecorrelation (to induce suitable separability property) between\\nliquid neurons is introduced by drawing synaptic delays, current\\nbias, and connection strengths from a probability distribution.\\nWe connect nrecexcitatory liquid neurons all-to-all to perfect linear\\nreadout neurons in a feedforward fashion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='67aa01ee-ae24-40be-aaa8-02c38a04bb1d', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nAs already mentioned, an LSM consists of three distinct parts: an\\ninput layer, a liquid, and an output layer.\\nThe input layer consists of spike generator neurons having the same\\ndimensionality as the input.\\nInput neurons connect randomly in a feedforward fashion to\\nexcitatory neurons in the liquid. We use a constant number of\\nsynapses ninpsynbetween the input neurons and the liquid.\\nThe liquid consists of N(=nexc+ninh) randomly connected neurons\\n(e.g., leaky integrate-and-fire neurons), 80 %of which are excitatory\\nand 20 %inhibitory. The visual cortex biologically inspires such\\nproportion. The liquid neuron parameters are usually the standard\\nparameter values given to the neuron model under consideration.\\nDecorrelation (to induce suitable separability property) between\\nliquid neurons is introduced by drawing synaptic delays, current\\nbias, and connection strengths from a probability distribution.\\nWe connect nrecexcitatory liquid neurons all-to-all to perfect linear\\nreadout neurons in a feedforward fashion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4c715c2c-a493-444f-9fc9-e4f0110a72f3', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nAs already mentioned, an LSM consists of three distinct parts: an\\ninput layer, a liquid, and an output layer.\\nThe input layer consists of spike generator neurons having the same\\ndimensionality as the input.\\nInput neurons connect randomly in a feedforward fashion to\\nexcitatory neurons in the liquid. We use a constant number of\\nsynapses ninpsynbetween the input neurons and the liquid.\\nThe liquid consists of N(=nexc+ninh) randomly connected neurons\\n(e.g., leaky integrate-and-fire neurons), 80 %of which are excitatory\\nand 20 %inhibitory. The visual cortex biologically inspires such\\nproportion. The liquid neuron parameters are usually the standard\\nparameter values given to the neuron model under consideration.\\nDecorrelation (to induce suitable separability property) between\\nliquid neurons is introduced by drawing synaptic delays, current\\nbias, and connection strengths from a probability distribution.\\nWe connect nrecexcitatory liquid neurons all-to-all to perfect linear\\nreadout neurons in a feedforward fashion.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f50667c6-e7ca-4dd5-bb52-735dfbf490a1', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nOnly these connections (i.e., those between the recorded liquid\\nneurons and the output neurons) are trained in a way that we\\ndescribe later.\\nThe readout neurons map the liquid activity to the desired output.\\nNote that nrec=nexc(i.e., an all-to-all connection between internal\\nexcitatory liquid neurons and readouts neurons) is a common\\nchoice. ( However, it should be noted that sometimes mapping only\\na fraction of the excitatory neurons to the output lower memory\\nconsumption and do not impact the performance of the LSM. )\\nThe connection strengths between input and liquid neurons and\\nwithin the liquid can be tuned to make the liquid memory-driven or\\ninput-driven.\\nFor example, by increasing the connection strengths between input\\nand liquid neurons, the activity regime of the liquid will depend\\nmore on the inputs than its memory.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='69fde5d1-83f0-40c4-95f9-e0aa5e16e69a', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nOnly these connections (i.e., those between the recorded liquid\\nneurons and the output neurons) are trained in a way that we\\ndescribe later.\\nThe readout neurons map the liquid activity to the desired output.\\nNote that nrec=nexc(i.e., an all-to-all connection between internal\\nexcitatory liquid neurons and readouts neurons) is a common\\nchoice. ( However, it should be noted that sometimes mapping only\\na fraction of the excitatory neurons to the output lower memory\\nconsumption and do not impact the performance of the LSM. )\\nThe connection strengths between input and liquid neurons and\\nwithin the liquid can be tuned to make the liquid memory-driven or\\ninput-driven.\\nFor example, by increasing the connection strengths between input\\nand liquid neurons, the activity regime of the liquid will depend\\nmore on the inputs than its memory.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1b3ad4a0-0f04-4973-9198-6b85ec011afb', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nOnly these connections (i.e., those between the recorded liquid\\nneurons and the output neurons) are trained in a way that we\\ndescribe later.\\nThe readout neurons map the liquid activity to the desired output.\\nNote that nrec=nexc(i.e., an all-to-all connection between internal\\nexcitatory liquid neurons and readouts neurons) is a common\\nchoice. ( However, it should be noted that sometimes mapping only\\na fraction of the excitatory neurons to the output lower memory\\nconsumption and do not impact the performance of the LSM. )\\nThe connection strengths between input and liquid neurons and\\nwithin the liquid can be tuned to make the liquid memory-driven or\\ninput-driven.\\nFor example, by increasing the connection strengths between input\\nand liquid neurons, the activity regime of the liquid will depend\\nmore on the inputs than its memory.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c49e0e3a-457f-4583-831f-fd4d8af83883', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Architecture of a Liquid State Machine\\nOnly these connections (i.e., those between the recorded liquid\\nneurons and the output neurons) are trained in a way that we\\ndescribe later.\\nThe readout neurons map the liquid activity to the desired output.\\nNote that nrec=nexc(i.e., an all-to-all connection between internal\\nexcitatory liquid neurons and readouts neurons) is a common\\nchoice. ( However, it should be noted that sometimes mapping only\\na fraction of the excitatory neurons to the output lower memory\\nconsumption and do not impact the performance of the LSM. )\\nThe connection strengths between input and liquid neurons and\\nwithin the liquid can be tuned to make the liquid memory-driven or\\ninput-driven.\\nFor example, by increasing the connection strengths between input\\nand liquid neurons, the activity regime of the liquid will depend\\nmore on the inputs than its memory.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c62a80e8-7b4d-461b-90f3-9ac1f711bab6', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Training of a Liquid State Machine\\nThe training part of an LSM consists of finding the proper weights of the\\nconnections between the liquid and the readout neurons.\\nLetwi∈Rnrecbe the weights between a readout neuron iand the set of\\nrecorded liquid neurons. Training consists of finding the proper weights for all\\nreadout neurons.\\nThe liquid state x(t)∈Rnrecis a vector containing the post-synaptic membrane\\npotentials of the nrecrecorded liquid neurons at time t.\\nWe sample the liquid state at discrete timesteps of ∆samplefort∈[0,ttrain].\\nThey are accumulated into a matrix X∈Rnrec×nsamplewhere\\nnsample =ttrain/∆sample\\nThe matrix Xcontains all the liquid states encountered during training. We,\\ntherefore, have the linear system for all readout neurons i:\\nyi=X·wi (7)\\nwhere yi∈Rnsampleis the sampled target (output) signals of readout neuron i.\\nIn other words, each readout neuron solves a linear regression (just as with\\nESN) to map the accumulated liquid states to accumulate target signals for this\\nneuron.\\nTo reduce overfitting, we use a regularized linear regression that penalizes strong\\nsynaptic weights. The parameter λis selected with respect to a cross-validation\\ndataset.\\nOnce the weights wi∈Rnrecare sufficiently well trained, the test and prediction\\nphases are similar to the ones described for the ESN.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='249defbf-52a6-4538-bea1-3b6235a1861f', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Training of a Liquid State Machine\\nThe training part of an LSM consists of finding the proper weights of the\\nconnections between the liquid and the readout neurons.\\nLetwi∈Rnrecbe the weights between a readout neuron iand the set of\\nrecorded liquid neurons. Training consists of finding the proper weights for all\\nreadout neurons.\\nThe liquid state x(t)∈Rnrecis a vector containing the post-synaptic membrane\\npotentials of the nrecrecorded liquid neurons at time t.\\nWe sample the liquid state at discrete timesteps of ∆samplefort∈[0,ttrain].\\nThey are accumulated into a matrix X∈Rnrec×nsamplewhere\\nnsample =ttrain/∆sample\\nThe matrix Xcontains all the liquid states encountered during training. We,\\ntherefore, have the linear system for all readout neurons i:\\nyi=X·wi (7)\\nwhere yi∈Rnsampleis the sampled target (output) signals of readout neuron i.\\nIn other words, each readout neuron solves a linear regression (just as with\\nESN) to map the accumulated liquid states to accumulate target signals for this\\nneuron.\\nTo reduce overfitting, we use a regularized linear regression that penalizes strong\\nsynaptic weights. The parameter λis selected with respect to a cross-validation\\ndataset.\\nOnce the weights wi∈Rnrecare sufficiently well trained, the test and prediction\\nphases are similar to the ones described for the ESN.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7508a490-25e7-4aa8-a995-90a9a8264b3c', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Training of a Liquid State Machine\\nThe training part of an LSM consists of finding the proper weights of the\\nconnections between the liquid and the readout neurons.\\nLetwi∈Rnrecbe the weights between a readout neuron iand the set of\\nrecorded liquid neurons. Training consists of finding the proper weights for all\\nreadout neurons.\\nThe liquid state x(t)∈Rnrecis a vector containing the post-synaptic membrane\\npotentials of the nrecrecorded liquid neurons at time t.\\nWe sample the liquid state at discrete timesteps of ∆samplefort∈[0,ttrain].\\nThey are accumulated into a matrix X∈Rnrec×nsamplewhere\\nnsample =ttrain/∆sample\\nThe matrix Xcontains all the liquid states encountered during training. We,\\ntherefore, have the linear system for all readout neurons i:\\nyi=X·wi (7)\\nwhere yi∈Rnsampleis the sampled target (output) signals of readout neuron i.\\nIn other words, each readout neuron solves a linear regression (just as with\\nESN) to map the accumulated liquid states to accumulate target signals for this\\nneuron.\\nTo reduce overfitting, we use a regularized linear regression that penalizes strong\\nsynaptic weights. The parameter λis selected with respect to a cross-validation\\ndataset.\\nOnce the weights wi∈Rnrecare sufficiently well trained, the test and prediction\\nphases are similar to the ones described for the ESN.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c9313acc-0517-4e8c-b23f-0e11388130e0', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Training of a Liquid State Machine\\nThe training part of an LSM consists of finding the proper weights of the\\nconnections between the liquid and the readout neurons.\\nLetwi∈Rnrecbe the weights between a readout neuron iand the set of\\nrecorded liquid neurons. Training consists of finding the proper weights for all\\nreadout neurons.\\nThe liquid state x(t)∈Rnrecis a vector containing the post-synaptic membrane\\npotentials of the nrecrecorded liquid neurons at time t.\\nWe sample the liquid state at discrete timesteps of ∆samplefort∈[0,ttrain].\\nThey are accumulated into a matrix X∈Rnrec×nsamplewhere\\nnsample =ttrain/∆sample\\nThe matrix Xcontains all the liquid states encountered during training. We,\\ntherefore, have the linear system for all readout neurons i:\\nyi=X·wi (7)\\nwhere yi∈Rnsampleis the sampled target (output) signals of readout neuron i.\\nIn other words, each readout neuron solves a linear regression (just as with\\nESN) to map the accumulated liquid states to accumulate target signals for this\\nneuron.\\nTo reduce overfitting, we use a regularized linear regression that penalizes strong\\nsynaptic weights. The parameter λis selected with respect to a cross-validation\\ndataset.\\nOnce the weights wi∈Rnrecare sufficiently well trained, the test and prediction\\nphases are similar to the ones described for the ESN.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='85935e72-f01c-4d72-93cc-27d5cf7ebef9', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Training of a Liquid State Machine\\nThe training part of an LSM consists of finding the proper weights of the\\nconnections between the liquid and the readout neurons.\\nLetwi∈Rnrecbe the weights between a readout neuron iand the set of\\nrecorded liquid neurons. Training consists of finding the proper weights for all\\nreadout neurons.\\nThe liquid state x(t)∈Rnrecis a vector containing the post-synaptic membrane\\npotentials of the nrecrecorded liquid neurons at time t.\\nWe sample the liquid state at discrete timesteps of ∆samplefort∈[0,ttrain].\\nThey are accumulated into a matrix X∈Rnrec×nsamplewhere\\nnsample =ttrain/∆sample\\nThe matrix Xcontains all the liquid states encountered during training. We,\\ntherefore, have the linear system for all readout neurons i:\\nyi=X·wi (7)\\nwhere yi∈Rnsampleis the sampled target (output) signals of readout neuron i.\\nIn other words, each readout neuron solves a linear regression (just as with\\nESN) to map the accumulated liquid states to accumulate target signals for this\\nneuron.\\nTo reduce overfitting, we use a regularized linear regression that penalizes strong\\nsynaptic weights. The parameter λis selected with respect to a cross-validation\\ndataset.\\nOnce the weights wi∈Rnrecare sufficiently well trained, the test and prediction\\nphases are similar to the ones described for the ESN.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='dd389e56-13e2-417a-b3c4-faa12f654b2c', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Training of a Liquid State Machine\\nThe training part of an LSM consists of finding the proper weights of the\\nconnections between the liquid and the readout neurons.\\nLetwi∈Rnrecbe the weights between a readout neuron iand the set of\\nrecorded liquid neurons. Training consists of finding the proper weights for all\\nreadout neurons.\\nThe liquid state x(t)∈Rnrecis a vector containing the post-synaptic membrane\\npotentials of the nrecrecorded liquid neurons at time t.\\nWe sample the liquid state at discrete timesteps of ∆samplefort∈[0,ttrain].\\nThey are accumulated into a matrix X∈Rnrec×nsamplewhere\\nnsample =ttrain/∆sample\\nThe matrix Xcontains all the liquid states encountered during training. We,\\ntherefore, have the linear system for all readout neurons i:\\nyi=X·wi (7)\\nwhere yi∈Rnsampleis the sampled target (output) signals of readout neuron i.\\nIn other words, each readout neuron solves a linear regression (just as with\\nESN) to map the accumulated liquid states to accumulate target signals for this\\nneuron.\\nTo reduce overfitting, we use a regularized linear regression that penalizes strong\\nsynaptic weights. The parameter λis selected with respect to a cross-validation\\ndataset.\\nOnce the weights wi∈Rnrecare sufficiently well trained, the test and prediction\\nphases are similar to the ones described for the ESN.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8aa0c212-27f0-4c4b-a148-666fdcaa339e', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s19.pdf', 'file_path': '/content/data/Lecture_s19.pdf', 'file_type': 'application/pdf', 'file_size': 312707, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Evaluation of performance of LSM\\nWe evaluate the performance of the method with respect to the predictions\\ngenerated by the liquid. We define a metric to evaluate the predictions. This\\nmetric is general and consists of computing the normalized error for all tests or\\npredictions:\\nE(W) =1\\nntest\\nsamplesntest\\nsamples∑\\ni=1\\ued79\\ued79Xtest·wi−yi\\ued79\\ued79, (8)\\nwhere Xtestthe accumulated liquid states during the test or prediction period,\\nandntest\\nsamplesthe number of samples in the test set. The residual error is the one\\nwe implicitly minimize when solving the linear equations for all readout neurons,\\nsee Eq. (7) above.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='51f8a5e4-f0fb-4c68-9661-3f0182013b2d', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 2: Mathematical modelling of biological neurons\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='63a05b62-8907-40cf-995c-2f1683de7932', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives [M. Yamakou]\\nTo derive the Hodgkin-Huxley neuron model, obtained from\\nexperiments on a squid giant axon, and which provides us\\nwith the most biophysically realistic equations for describing\\nneuronal dynamics.\\n.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b865efd4-a189-438b-95d7-77b7c3446a24', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nThe neuron model was developed by Alan L. Hodgkin and\\nAndrew F. Huxley in 1952 using the giant squid axon, earning\\nthem a Nobel Prize in Physiology or Medicine 1963. This\\napproach was refined over the next 50 years and is now known\\nas the conductance-based approach to modeling neurons.\\nMemorial University at http://www.mun.ca/biology/\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='897a042d-6e59-4c0e-8a54-137436610cb3', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nThe model simplifies the electrochemical mechanism by\\nrepresenting the neuron membrane as a capacitor, ionic gates,\\nand ionic pumps as conductance-battery pairs. The figure\\nbelow illustrates the electrical circuit.\\nCircuit diagram for Hodgkin-Huxley (HH) equations.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0df5021a-ee66-4476-abdc-7958962bc0a1', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nHodgkin and Huxley found that there are three main types of\\ncurrents describing the dynamics of a neuron: Sodium ( Na+),\\nPotassium ( K+), and a leak current (consisting of Chloride\\n(Cl−) ions).\\nThere are biological constructs in a neuron’s membrane that\\ngate the flow of specific ions depending on the membrane\\npotential V.\\nVoltage-gated ion channels control the flow of these ions.\\nWhen the neuron’s membrane reaches a specific voltage, it\\nopens up, allowing these ions to move in and out of the\\nneuron.\\nTo mimic the probabilistic dynamics of the ion channels in the\\nneuron, Hodgkin and Huxley proposed that channels consist\\nof four components that can be opened or closed.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1b61e4a3-e991-4c49-8b90-2afb73f3c245', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nHodgkin and Huxley found that there are three main types of\\ncurrents describing the dynamics of a neuron: Sodium ( Na+),\\nPotassium ( K+), and a leak current (consisting of Chloride\\n(Cl−) ions).\\nThere are biological constructs in a neuron’s membrane that\\ngate the flow of specific ions depending on the membrane\\npotential V.\\nVoltage-gated ion channels control the flow of these ions.\\nWhen the neuron’s membrane reaches a specific voltage, it\\nopens up, allowing these ions to move in and out of the\\nneuron.\\nTo mimic the probabilistic dynamics of the ion channels in the\\nneuron, Hodgkin and Huxley proposed that channels consist\\nof four components that can be opened or closed.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6d13f349-81ff-4871-bab4-861e4938bba0', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nHodgkin and Huxley found that there are three main types of\\ncurrents describing the dynamics of a neuron: Sodium ( Na+),\\nPotassium ( K+), and a leak current (consisting of Chloride\\n(Cl−) ions).\\nThere are biological constructs in a neuron’s membrane that\\ngate the flow of specific ions depending on the membrane\\npotential V.\\nVoltage-gated ion channels control the flow of these ions.\\nWhen the neuron’s membrane reaches a specific voltage, it\\nopens up, allowing these ions to move in and out of the\\nneuron.\\nTo mimic the probabilistic dynamics of the ion channels in the\\nneuron, Hodgkin and Huxley proposed that channels consist\\nof four components that can be opened or closed.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b141acbf-7f26-484a-8814-847f7ada80a3', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nHodgkin and Huxley found that there are three main types of\\ncurrents describing the dynamics of a neuron: Sodium ( Na+),\\nPotassium ( K+), and a leak current (consisting of Chloride\\n(Cl−) ions).\\nThere are biological constructs in a neuron’s membrane that\\ngate the flow of specific ions depending on the membrane\\npotential V.\\nVoltage-gated ion channels control the flow of these ions.\\nWhen the neuron’s membrane reaches a specific voltage, it\\nopens up, allowing these ions to move in and out of the\\nneuron.\\nTo mimic the probabilistic dynamics of the ion channels in the\\nneuron, Hodgkin and Huxley proposed that channels consist\\nof four components that can be opened or closed.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9268f93e-48dc-4801-a27d-41babc16d694', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nFor potassium channels, the four components have identical\\nprobability nto be open, resulting in a probability PK=n4.\\nOpening and closing of these components depend on the\\nmembrane potential V, which determines their transition from\\nopen to closed position.\\nThus, a component passes from the closed (with probability\\n1−n) to the open state (with probability n) following\\ncoefficients αnandβn, themselves dependent on V,\\n1−n⇌αn\\nβnn,\\nobeying the Boltzmann equations describing the stochastic\\nbehavior of K+ions channels and have the general form\\nαn(V)=θn,1(V−θn,2)\\nθn,4+ exp(θn,2−V\\nθn,3), βn(V)=θn,5exp(\\n−V\\nθn,6)\\n,\\nwhereθn,i,i={1,2,3,4,5,6}values are found experimentally (by\\nfine-tuning) to fit the neuron’s behavior best.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='681f8a88-3bef-4f88-9aec-d4c00a7defae', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nFor potassium channels, the four components have identical\\nprobability nto be open, resulting in a probability PK=n4.\\nOpening and closing of these components depend on the\\nmembrane potential V, which determines their transition from\\nopen to closed position.\\nThus, a component passes from the closed (with probability\\n1−n) to the open state (with probability n) following\\ncoefficients αnandβn, themselves dependent on V,\\n1−n⇌αn\\nβnn,\\nobeying the Boltzmann equations describing the stochastic\\nbehavior of K+ions channels and have the general form\\nαn(V)=θn,1(V−θn,2)\\nθn,4+ exp(θn,2−V\\nθn,3), βn(V)=θn,5exp(\\n−V\\nθn,6)\\n,\\nwhereθn,i,i={1,2,3,4,5,6}values are found experimentally (by\\nfine-tuning) to fit the neuron’s behavior best.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='66d54384-65b6-4275-8081-37f6942482e1', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nIf the initial value of the probability nthat the K+is opened\\nis known, the values of nin time are given by the dynamical\\nsystem:\\ndn\\ndt=αn(1−n)−βnn.\\nLet\\nn∞=αn\\nαn+βnandτn=1\\nαn+βn.\\nn∞is the nvalue of equilibrium and the constant τnthe\\napproaching time of this equilibrium. As αnandβn, these\\nvalues depend on the membrane potential V. We can then\\nrewrite the equation describing the evolution of nas follows,\\ndn\\ndt=n∞−n\\nτn.\\nLetIKbe the number of K+ions that flow through the\\nmembrane per unit time. In the HH model, IKis given by,\\nIK=n4gK(V−EK), (1)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='33d5fa48-2761-4bf5-a91b-22dd56a235e0', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nIf the initial value of the probability nthat the K+is opened\\nis known, the values of nin time are given by the dynamical\\nsystem:\\ndn\\ndt=αn(1−n)−βnn.\\nLet\\nn∞=αn\\nαn+βnandτn=1\\nαn+βn.\\nn∞is the nvalue of equilibrium and the constant τnthe\\napproaching time of this equilibrium. As αnandβn, these\\nvalues depend on the membrane potential V. We can then\\nrewrite the equation describing the evolution of nas follows,\\ndn\\ndt=n∞−n\\nτn.\\nLetIKbe the number of K+ions that flow through the\\nmembrane per unit time. In the HH model, IKis given by,\\nIK=n4gK(V−EK), (1)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f8b4bf21-bcaa-4468-9b29-d4e783034ac1', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nIf the initial value of the probability nthat the K+is opened\\nis known, the values of nin time are given by the dynamical\\nsystem:\\ndn\\ndt=αn(1−n)−βnn.\\nLet\\nn∞=αn\\nαn+βnandτn=1\\nαn+βn.\\nn∞is the nvalue of equilibrium and the constant τnthe\\napproaching time of this equilibrium. As αnandβn, these\\nvalues depend on the membrane potential V. We can then\\nrewrite the equation describing the evolution of nas follows,\\ndn\\ndt=n∞−n\\nτn.\\nLetIKbe the number of K+ions that flow through the\\nmembrane per unit time. In the HH model, IKis given by,\\nIK=n4gK(V−EK), (1)Marius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='fd9b67f8-ad44-4bc4-80a7-d89c2be7dd90', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nwhere in the last equation of the previous slide, Vrepresents\\nthe membrane potential, EKis the equilibrium potential of the\\nK+ions, gKis conductivity of K+ions, and nhave been\\npreviously defined.\\nIf all K+ion channels are opened (i.e., n=1), they will\\ntransmit currents with a maximum conductance gmax\\nK.\\nIf the conductance is minimum (i.e., gk:=1\\nR=0), we will\\nhave no flow of K+ions because all the K+ion channels will\\nbe closed i.e., 1−n=1. Hence, the resistance Rbecomes\\ninfinitely large, therefore, zero current ( IK=0).\\nNote, however, that, most of the time, some of the K+ion\\nchannels are blocked, and thus we mostly have gkand very\\nrarely have gmax\\nK.\\nIf the membrane potential equals the ion’s equilibrium potential\\n(V=EK), there is no circulation, and the current IKis also zero.\\nIn the HH model, IKis given by,\\nIK=n4gK(V−EK) (2)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6702c58b-e5f3-42e8-8374-7b03a7256391', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nwhere in the last equation of the previous slide, Vrepresents\\nthe membrane potential, EKis the equilibrium potential of the\\nK+ions, gKis conductivity of K+ions, and nhave been\\npreviously defined.\\nIf all K+ion channels are opened (i.e., n=1), they will\\ntransmit currents with a maximum conductance gmax\\nK.\\nIf the conductance is minimum (i.e., gk:=1\\nR=0), we will\\nhave no flow of K+ions because all the K+ion channels will\\nbe closed i.e., 1−n=1. Hence, the resistance Rbecomes\\ninfinitely large, therefore, zero current ( IK=0).\\nNote, however, that, most of the time, some of the K+ion\\nchannels are blocked, and thus we mostly have gkand very\\nrarely have gmax\\nK.\\nIf the membrane potential equals the ion’s equilibrium potential\\n(V=EK), there is no circulation, and the current IKis also zero.\\nIn the HH model, IKis given by,\\nIK=n4gK(V−EK) (2)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e2b5bc6e-0227-41b0-9e30-45a2b7eb966a', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nwhere in the last equation of the previous slide, Vrepresents\\nthe membrane potential, EKis the equilibrium potential of the\\nK+ions, gKis conductivity of K+ions, and nhave been\\npreviously defined.\\nIf all K+ion channels are opened (i.e., n=1), they will\\ntransmit currents with a maximum conductance gmax\\nK.\\nIf the conductance is minimum (i.e., gk:=1\\nR=0), we will\\nhave no flow of K+ions because all the K+ion channels will\\nbe closed i.e., 1−n=1. Hence, the resistance Rbecomes\\ninfinitely large, therefore, zero current ( IK=0).\\nNote, however, that, most of the time, some of the K+ion\\nchannels are blocked, and thus we mostly have gkand very\\nrarely have gmax\\nK.\\nIf the membrane potential equals the ion’s equilibrium potential\\n(V=EK), there is no circulation, and the current IKis also zero.\\nIn the HH model, IKis given by,\\nIK=n4gK(V−EK) (2)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9957c5b2-2765-4d17-a690-e3c0d1d5599d', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nwhere in the last equation of the previous slide, Vrepresents\\nthe membrane potential, EKis the equilibrium potential of the\\nK+ions, gKis conductivity of K+ions, and nhave been\\npreviously defined.\\nIf all K+ion channels are opened (i.e., n=1), they will\\ntransmit currents with a maximum conductance gmax\\nK.\\nIf the conductance is minimum (i.e., gk:=1\\nR=0), we will\\nhave no flow of K+ions because all the K+ion channels will\\nbe closed i.e., 1−n=1. Hence, the resistance Rbecomes\\ninfinitely large, therefore, zero current ( IK=0).\\nNote, however, that, most of the time, some of the K+ion\\nchannels are blocked, and thus we mostly have gkand very\\nrarely have gmax\\nK.\\nIf the membrane potential equals the ion’s equilibrium potential\\n(V=EK), there is no circulation, and the current IKis also zero.\\nIn the HH model, IKis given by,\\nIK=n4gK(V−EK) (2)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d3f73e60-b5a8-44fe-a856-690dbcd7e061', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nwhere in the last equation of the previous slide, Vrepresents\\nthe membrane potential, EKis the equilibrium potential of the\\nK+ions, gKis conductivity of K+ions, and nhave been\\npreviously defined.\\nIf all K+ion channels are opened (i.e., n=1), they will\\ntransmit currents with a maximum conductance gmax\\nK.\\nIf the conductance is minimum (i.e., gk:=1\\nR=0), we will\\nhave no flow of K+ions because all the K+ion channels will\\nbe closed i.e., 1−n=1. Hence, the resistance Rbecomes\\ninfinitely large, therefore, zero current ( IK=0).\\nNote, however, that, most of the time, some of the K+ion\\nchannels are blocked, and thus we mostly have gkand very\\nrarely have gmax\\nK.\\nIf the membrane potential equals the ion’s equilibrium potential\\n(V=EK), there is no circulation, and the current IKis also zero.\\nIn the HH model, IKis given by,\\nIK=n4gK(V−EK) (2)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4aade882-fba0-4295-9647-49e83c3c373b', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nA similar approach to describe the sodium current ( INa).\\nHowever, Unlike other channels, sodium ( Na+) channels can\\nbe open and active, open and inactive, or closed.\\nTo model these states, a Na+channel consisting of four\\ncomponents is considered: three controlling opening and\\nclosing and the fourth one controlling activation or\\ninactivation.\\nThe opening and closing components each have a probability\\nmof being open, while the activation/inactivation component\\nhas a probability hof being active.\\nThe probability of a Na+channel being open and active is\\nthusPNa=m3h, and both mandhdepend on membrane\\npotential V.\\nLetINabe the Na+flux, .i.e., the amount of Naions flowing\\nthrough the membrane. INais represented by,\\nINa=m3hgNa(V−ENa), (3)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='61f40b27-185d-41c6-a0fe-c398eea7fef2', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nA similar approach to describe the sodium current ( INa).\\nHowever, Unlike other channels, sodium ( Na+) channels can\\nbe open and active, open and inactive, or closed.\\nTo model these states, a Na+channel consisting of four\\ncomponents is considered: three controlling opening and\\nclosing and the fourth one controlling activation or\\ninactivation.\\nThe opening and closing components each have a probability\\nmof being open, while the activation/inactivation component\\nhas a probability hof being active.\\nThe probability of a Na+channel being open and active is\\nthusPNa=m3h, and both mandhdepend on membrane\\npotential V.\\nLetINabe the Na+flux, .i.e., the amount of Naions flowing\\nthrough the membrane. INais represented by,\\nINa=m3hgNa(V−ENa), (3)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6233f707-e286-4934-874a-b0963e5ee9ec', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nA similar approach to describe the sodium current ( INa).\\nHowever, Unlike other channels, sodium ( Na+) channels can\\nbe open and active, open and inactive, or closed.\\nTo model these states, a Na+channel consisting of four\\ncomponents is considered: three controlling opening and\\nclosing and the fourth one controlling activation or\\ninactivation.\\nThe opening and closing components each have a probability\\nmof being open, while the activation/inactivation component\\nhas a probability hof being active.\\nThe probability of a Na+channel being open and active is\\nthusPNa=m3h, and both mandhdepend on membrane\\npotential V.\\nLetINabe the Na+flux, .i.e., the amount of Naions flowing\\nthrough the membrane. INais represented by,\\nINa=m3hgNa(V−ENa), (3)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='840f5f9f-ceb2-40ca-b2d1-417b0049bc27', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nA similar approach to describe the sodium current ( INa).\\nHowever, Unlike other channels, sodium ( Na+) channels can\\nbe open and active, open and inactive, or closed.\\nTo model these states, a Na+channel consisting of four\\ncomponents is considered: three controlling opening and\\nclosing and the fourth one controlling activation or\\ninactivation.\\nThe opening and closing components each have a probability\\nmof being open, while the activation/inactivation component\\nhas a probability hof being active.\\nThe probability of a Na+channel being open and active is\\nthusPNa=m3h, and both mandhdepend on membrane\\npotential V.\\nLetINabe the Na+flux, .i.e., the amount of Naions flowing\\nthrough the membrane. INais represented by,\\nINa=m3hgNa(V−ENa), (3)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='aa450a01-7874-4344-9ea0-cb4951f89b3e', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nA similar approach to describe the sodium current ( INa).\\nHowever, Unlike other channels, sodium ( Na+) channels can\\nbe open and active, open and inactive, or closed.\\nTo model these states, a Na+channel consisting of four\\ncomponents is considered: three controlling opening and\\nclosing and the fourth one controlling activation or\\ninactivation.\\nThe opening and closing components each have a probability\\nmof being open, while the activation/inactivation component\\nhas a probability hof being active.\\nThe probability of a Na+channel being open and active is\\nthusPNa=m3h, and both mandhdepend on membrane\\npotential V.\\nLetINabe the Na+flux, .i.e., the amount of Naions flowing\\nthrough the membrane. INais represented by,\\nINa=m3hgNa(V−ENa), (3)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='714b15ac-a21c-4326-a77d-08365fa48c2c', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nWhere in the last equation in the previous slide, Vis the\\nmembrane potential and ENais the equilibrium potential of\\nNa+ions, and gNais the conductance of the Na+channel.\\nAs we saw for the evolution of the variable nof the K+\\nchannels, the transition from the open position (with\\nprobability m) or closed (with probability 1 −m) of each\\ncomponent of the Na+channels is given by the V-dependent\\ncoefficients αmandβm,\\n1−m⇌αm\\nβmm,\\nobeying the Boltzmann equations describing the stochastic\\nbehavior of the Na+channels and have the general form\\nαm(V)=θn,7(V−θn,8)\\nθn,10+ exp(θn,8−V\\nθn,9), βm(V)=θn,11exp(\\n−V\\nθn,12)\\n,\\nwhereθm,i,i={7,8,9,10,11,12}values are found\\nexperimentally (by fine-tuning) to fit the neuron’s behavior\\nbest.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='391374b1-01e9-4626-913c-703b9b95d41f', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nWhere in the last equation in the previous slide, Vis the\\nmembrane potential and ENais the equilibrium potential of\\nNa+ions, and gNais the conductance of the Na+channel.\\nAs we saw for the evolution of the variable nof the K+\\nchannels, the transition from the open position (with\\nprobability m) or closed (with probability 1 −m) of each\\ncomponent of the Na+channels is given by the V-dependent\\ncoefficients αmandβm,\\n1−m⇌αm\\nβmm,\\nobeying the Boltzmann equations describing the stochastic\\nbehavior of the Na+channels and have the general form\\nαm(V)=θn,7(V−θn,8)\\nθn,10+ exp(θn,8−V\\nθn,9), βm(V)=θn,11exp(\\n−V\\nθn,12)\\n,\\nwhereθm,i,i={7,8,9,10,11,12}values are found\\nexperimentally (by fine-tuning) to fit the neuron’s behavior\\nbest.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f762f99d-c08d-4ce9-a26e-5038f094b764', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nIn a similar fashion, for h, transitions from the active position\\n(with probability h) to the inactive position (with probability\\n1−h) are given by the coefficients αhandβh,\\n1−h⇌αh\\nβhh.\\nand which obey the Boltzmann equations describing the\\nstochastic behavior of the channels and have the general form\\nαh(V)=θn,13exp(\\n−V\\nθn,14)\\n, βh(V)=θn,15\\nθn,16+ exp(θn,17−V\\nθn,17)\\nwhereθm,i,i={13,14,15,16,17}values are found experimentally\\n(by fine-tuning) to fit the neuron’s behavior best.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='25f75109-2d1e-44b8-8df2-15c0397dc9a5', embedding=None, metadata={'page_label': '11', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nIn the same way as for n, the evolutions of mandhare given\\nby the differential equations,\\ndm\\ndt=αm(1−m)−βmm=m∞−m\\nτm,\\ndh\\ndt=αh(1−h)−βhh=h∞−h\\nτh.\\nFrom where we extract the following notations:\\nm∞=1\\nαm+βm, τm=1\\nαm+βm,\\nh∞=1\\nαh+βh, τh=1\\nαh+βh.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='df7ec6a0-f7c0-487d-94ff-94d45582fa45', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nA similar approach to describe the leak current ( IL). However,\\nUnlike other K+andNa+channels, leakage channels are\\nalways opened. (Hence the term leak current.)\\nThe opening components each have a probability 1 of being\\nopened. The probability of a Cl−channel being open and\\nactive is thus PL=1×1×1×1=1.\\nLetILbe the Cl−flux, .i.e., the amount of Cl−ions flowing\\nthrough the membrane. ILis represented by,\\nIL=gL(V−EL), (4)\\nwhere Vis the membrane potential and ELis the equilibrium\\npotential of the leakage ions (mostly Cl−).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b1c1ffbd-af67-4f12-bffc-6eb6e0812cfd', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nA similar approach to describe the leak current ( IL). However,\\nUnlike other K+andNa+channels, leakage channels are\\nalways opened. (Hence the term leak current.)\\nThe opening components each have a probability 1 of being\\nopened. The probability of a Cl−channel being open and\\nactive is thus PL=1×1×1×1=1.\\nLetILbe the Cl−flux, .i.e., the amount of Cl−ions flowing\\nthrough the membrane. ILis represented by,\\nIL=gL(V−EL), (4)\\nwhere Vis the membrane potential and ELis the equilibrium\\npotential of the leakage ions (mostly Cl−).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f219eea6-0e6d-4863-ab26-ddc209d05632', embedding=None, metadata={'page_label': '12', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nA similar approach to describe the leak current ( IL). However,\\nUnlike other K+andNa+channels, leakage channels are\\nalways opened. (Hence the term leak current.)\\nThe opening components each have a probability 1 of being\\nopened. The probability of a Cl−channel being open and\\nactive is thus PL=1×1×1×1=1.\\nLetILbe the Cl−flux, .i.e., the amount of Cl−ions flowing\\nthrough the membrane. ILis represented by,\\nIL=gL(V−EL), (4)\\nwhere Vis the membrane potential and ELis the equilibrium\\npotential of the leakage ions (mostly Cl−).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='71ec0fe7-d32b-4229-b73c-b4f9e8a55f2f', embedding=None, metadata={'page_label': '13', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nFrom the conservation of electric charges, Kirchhoff’s current\\nlaw applied to the circuit in the Figure 3 given slide 4 above\\nI=I0=CdV\\ndt+IK+INa+IL,\\nWhere I0is the input current, IKis the potassium current, INa\\nis the sodium current, ILis the leak current, which models all\\nions that flow through the ion channels, which are always\\nopen, the capacitance of the membrane is represented by Cm,\\nandVrepresents the voltage of the membrane potential. We\\ntherefore have\\n−CmdV\\ndt=IK+INa+IL−I0,\\nwhich, after dropping the subscript minCm, is given more\\nexplicitly by\\n−CdV\\ndt=n4¯gK(V−EK) +m3hgNa(V−ENa) + ¯gL(V−EL)−I0.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8049f54f-6491-4249-82d6-bda77a133176', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nThus, the full model of the nerve impulse proposed by\\nHodgkin and Huxley is\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3CdV\\ndt=n4gK(EK−V) +m3hgNa(ENa−V) +gL(EL−V) +I0,\\ndn\\ndt=αn(1−n)−βnn=n∞−n\\nτn,\\ndm\\ndt=αm(1−m)−βmm=m∞−m\\nτm,\\ndh\\ndt=αh(1−h)−βhh=h∞−h\\nτh.\\nWhere t is the time in ms. Note that conductances gKandgNado\\nnot remain constant: they depend on V(in a very complicated\\nway). They are both only constant when the corresponding ion\\nchannels are all opened, in which case gKandgNabecomes gmax\\nKand\\ngmax\\nNa, respectively. gLis a constant. (Why is it always a constant?)\\nThe so-called gating variables m,n,hare all bounded in the unit\\ninterval [0,1]. (Why do you think it is so?)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b02c04b3-b92c-4b19-9f5a-3cfb44cd7cb5', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nThus, the full model of the nerve impulse proposed by\\nHodgkin and Huxley is\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3CdV\\ndt=n4gK(EK−V) +m3hgNa(ENa−V) +gL(EL−V) +I0,\\ndn\\ndt=αn(1−n)−βnn=n∞−n\\nτn,\\ndm\\ndt=αm(1−m)−βmm=m∞−m\\nτm,\\ndh\\ndt=αh(1−h)−βhh=h∞−h\\nτh.\\nWhere t is the time in ms. Note that conductances gKandgNado\\nnot remain constant: they depend on V(in a very complicated\\nway). They are both only constant when the corresponding ion\\nchannels are all opened, in which case gKandgNabecomes gmax\\nKand\\ngmax\\nNa, respectively. gLis a constant. (Why is it always a constant?)\\nThe so-called gating variables m,n,hare all bounded in the unit\\ninterval [0,1]. (Why do you think it is so?)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='bb60a12f-9ca7-4287-a417-c1a339244c4b', embedding=None, metadata={'page_label': '14', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nThus, the full model of the nerve impulse proposed by\\nHodgkin and Huxley is\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3CdV\\ndt=n4gK(EK−V) +m3hgNa(ENa−V) +gL(EL−V) +I0,\\ndn\\ndt=αn(1−n)−βnn=n∞−n\\nτn,\\ndm\\ndt=αm(1−m)−βmm=m∞−m\\nτm,\\ndh\\ndt=αh(1−h)−βhh=h∞−h\\nτh.\\nWhere t is the time in ms. Note that conductances gKandgNado\\nnot remain constant: they depend on V(in a very complicated\\nway). They are both only constant when the corresponding ion\\nchannels are all opened, in which case gKandgNabecomes gmax\\nKand\\ngmax\\nNa, respectively. gLis a constant. (Why is it always a constant?)\\nThe so-called gating variables m,n,hare all bounded in the unit\\ninterval [0,1]. (Why do you think it is so?)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='246a7928-99eb-49d1-aa2e-7331b6b510f0', embedding=None, metadata={'page_label': '15', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nThe Boltzmann equations give the expressions of the so-called\\nrate constants of the HH neuron model, αj(V)andβj(V),\\nwhere j={n,m,h}, together with the values of the other\\nparameters θj,i, are determined experimentally by using the\\nVoltage Clamp experiments.\\nαn(V) =0.01(10−V)\\nexp(\\n10−V\\n10)\\n−1, αm(V) =0.1(25−V)\\nexp(\\n25−V\\n10)\\n−1\\nαh(v) =0.07exp(−V\\n20)\\n, βn(V) =0.125exp(−V\\n80)\\n,\\nβm(V) =4.0exp(−V\\n18)\\n, βh(V) =1\\nexp(\\n30−V\\n30)\\n+1.C=1.0µF/cm2,ENa=115.0mV,EK=−12.0mV,\\nEL=10.6mV,gNa=gmax\\nNa=120.0mS/cm2,\\ngK=gmax\\nK=36.0mS/cm2,gL=gmax\\nL=0.3mS/cm2\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='940ed683-3d50-4187-94bc-25b951762e9a', embedding=None, metadata={'page_label': '15', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deriving the Hodgkin-Huxley (HH) neuron model [M. Yamakou]\\nThe Boltzmann equations give the expressions of the so-called\\nrate constants of the HH neuron model, αj(V)andβj(V),\\nwhere j={n,m,h}, together with the values of the other\\nparameters θj,i, are determined experimentally by using the\\nVoltage Clamp experiments.\\nαn(V) =0.01(10−V)\\nexp(\\n10−V\\n10)\\n−1, αm(V) =0.1(25−V)\\nexp(\\n25−V\\n10)\\n−1\\nαh(v) =0.07exp(−V\\n20)\\n, βn(V) =0.125exp(−V\\n80)\\n,\\nβm(V) =4.0exp(−V\\n18)\\n, βh(V) =1\\nexp(\\n30−V\\n30)\\n+1.\\nC=1.0µF/cm2,ENa=115.0mV,EK=−12.0mV,\\nEL=10.6mV,gNa=gmax\\nNa=120.0mS/cm2,\\ngK=gmax\\nK=36.0mS/cm2,gL=gmax\\nL=0.3mS/cm2\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='562d9f2b-af07-480f-89e0-e52eda98ca00', embedding=None, metadata={'page_label': '16', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Properties of solutions of the Hodgkin-Huxley (HH) neuron. [M. Yamakou]\\nIn the absence of external current I0: equilibrium.\\nAfter a weak impulse from I0: rapid relaxation to equilibrium.\\nAfter a sufficiently strong (short) from impulse I0: Fires for the\\ncorresponding short duration.\\nWith constant, sufficiently strong I0: The pulses occur\\nperiodically (limit cycle!)\\nImmediately after repolarization, the HH neuron cannot fire\\nagain immediately (refractory period).\\nProfile of a spike of the HH neuron\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='dc4fa498-e917-471d-9dfa-2889b6a738ed', embedding=None, metadata={'page_label': '17', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Explicit mathematical analysis of Hodgkin-Huxley (HH) equations?? [M. Yamakou]\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3CdV\\ndt=n4gK(EK−V) +m3hgNa(ENa−V) +gL(EL−V) +I0,\\ndn\\ndt=αn(1−n)−βnn=n∞−n\\nτn,\\ndm\\ndt=αm(1−m)−βmm=m∞−m\\nτm,\\ndh\\ndt=αh(1−h)−βhh=h∞−h\\nτh.\\nDynamics of the HH equations are relatively simple. However, their\\nexplicit analysis (fixed points (equilibria), stability, bifurcations, etc)\\nis extremely difficult because of the “unwieldy” right-hand sides, (i.e.,\\nstrong nonlinearity, high dimensionality, & large parameter space.)\\nThe search for equilibria and their stability properties is impossible\\nwithout computer numerics.\\nThus, one would like to have the system of equations of Vmade up\\nof simpler equations but with similar properties to the HH model.\\nThis can be via timescale separation analysis and exploiting\\nsimilarities between the HH variables.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8ad1ca1e-03ed-4f2c-b239-c66a31f9f2e6', embedding=None, metadata={'page_label': '17', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Explicit mathematical analysis of Hodgkin-Huxley (HH) equations?? [M. Yamakou]\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3CdV\\ndt=n4gK(EK−V) +m3hgNa(ENa−V) +gL(EL−V) +I0,\\ndn\\ndt=αn(1−n)−βnn=n∞−n\\nτn,\\ndm\\ndt=αm(1−m)−βmm=m∞−m\\nτm,\\ndh\\ndt=αh(1−h)−βhh=h∞−h\\nτh.\\nDynamics of the HH equations are relatively simple. However, their\\nexplicit analysis (fixed points (equilibria), stability, bifurcations, etc)\\nis extremely difficult because of the “unwieldy” right-hand sides, (i.e.,\\nstrong nonlinearity, high dimensionality, & large parameter space.)\\nThe search for equilibria and their stability properties is impossible\\nwithout computer numerics.\\nThus, one would like to have the system of equations of Vmade up\\nof simpler equations but with similar properties to the HH model.\\nThis can be via timescale separation analysis and exploiting\\nsimilarities between the HH variables.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='dfc3bdda-ed47-4ca2-94c2-092a795b40f1', embedding=None, metadata={'page_label': '17', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Explicit mathematical analysis of Hodgkin-Huxley (HH) equations?? [M. Yamakou]\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3CdV\\ndt=n4gK(EK−V) +m3hgNa(ENa−V) +gL(EL−V) +I0,\\ndn\\ndt=αn(1−n)−βnn=n∞−n\\nτn,\\ndm\\ndt=αm(1−m)−βmm=m∞−m\\nτm,\\ndh\\ndt=αh(1−h)−βhh=h∞−h\\nτh.\\nDynamics of the HH equations are relatively simple. However, their\\nexplicit analysis (fixed points (equilibria), stability, bifurcations, etc)\\nis extremely difficult because of the “unwieldy” right-hand sides, (i.e.,\\nstrong nonlinearity, high dimensionality, & large parameter space.)\\nThe search for equilibria and their stability properties is impossible\\nwithout computer numerics.\\nThus, one would like to have the system of equations of Vmade up\\nof simpler equations but with similar properties to the HH model.\\nThis can be via timescale separation analysis and exploiting\\nsimilarities between the HH variables.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='61ac1d52-05f5-4780-9b15-9679207bfc9d', embedding=None, metadata={'page_label': '17', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Explicit mathematical analysis of Hodgkin-Huxley (HH) equations?? [M. Yamakou]\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3CdV\\ndt=n4gK(EK−V) +m3hgNa(ENa−V) +gL(EL−V) +I0,\\ndn\\ndt=αn(1−n)−βnn=n∞−n\\nτn,\\ndm\\ndt=αm(1−m)−βmm=m∞−m\\nτm,\\ndh\\ndt=αh(1−h)−βhh=h∞−h\\nτh.\\nDynamics of the HH equations are relatively simple. However, their\\nexplicit analysis (fixed points (equilibria), stability, bifurcations, etc)\\nis extremely difficult because of the “unwieldy” right-hand sides, (i.e.,\\nstrong nonlinearity, high dimensionality, & large parameter space.)\\nThe search for equilibria and their stability properties is impossible\\nwithout computer numerics.\\nThus, one would like to have the system of equations of Vmade up\\nof simpler equations but with similar properties to the HH model.\\nThis can be via timescale separation analysis and exploiting\\nsimilarities between the HH variables.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ffcb3d80-da8e-4e41-ba18-0a46b7dc7dd8', embedding=None, metadata={'page_label': '18', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Simulating the Hodgkin-Huxley (HH) neuron on a computer [M. Yamakou]\\nFigure: Response of the Hodgkin-Huxley neuron model. Graphics taken\\nfrom http://www.genesis-sim.org/GENESIS/cnslecs/cns1.htmlMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='bd9cba95-91de-4180-a647-43e72ad9d773', embedding=None, metadata={'page_label': '19', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Simulating the Hodgkin-Huxley (HH) neuron on a computer [M. Yamakou]\\nBy simulating the neuron, we can observe that the membrane\\npotential begins to generate action potentials (spikes) once\\nthe input current increases above a certain threshold.\\nAs shown below, we can visualize the membrane potential V\\nat different input currents. Additionally, we can look at the\\nsteady-state spiking rate (in Hz) of the HH neuron.\\nFigure: Response of the Hodgkin-Huxley neuron model. Graphics taken\\nfrom http://www.genesis-sim.org/GENESIS/cnslecs/cns1.htmlMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='642a1e9d-6320-484c-8fff-d55b6e25d36f', embedding=None, metadata={'page_label': '20', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Firing rate (spiking rate) as a function of the input current I0in Hodgkin-Huxley\\n(HH) neuron model and ReLU-type behavior. [M. Yamakou]\\nBy simulating the neuron, we can observe that the neuron’s\\nfiring rate is a function of the input current. In this standard\\nmodel, the firing rate r(I0)could be approximated by a\\nHeaviside function. However, different types of functions can\\nbe obtained by different neuron types.\\nFigure: Response of the Hodgkin-Huxley neuron model. Graphics taken\\nfrom http://www.genesis-sim.org/GENESIS/cnslecs/cns1.htmlMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a03803f5-b8d6-41d8-b136-69f2493c9937', embedding=None, metadata={'page_label': '21', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The inspiration for artificial neural networks (ANN) [M. Yamakou]\\nBased on the activation of the neuron, you can observe that\\nthere are two states: firing and not firing. The firing state can\\nbe defined by the activation function f.\\nIn the case of the standard model, the activation function is a\\nHeaviside function with a similar property current to the ReLU\\nfunction. The neuron sums the inputs Ii, and the final firing\\nrate results from passing the sum through an activation\\nfunction f.\\nr(I0) =f(N∑\\ni=1Ii)\\n. (5)\\nThis abstraction is used to move from the complex and\\ncomputationally expensive model to a simpler and cheaper\\nrate-based models. As a result, it is easier to model networks\\nof neurons. This transition has formed the basis for today’s\\npopular artificial neural networks (ANN).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1fd960ef-008c-4217-9ca0-78b789593f39', embedding=None, metadata={'page_label': '21', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The inspiration for artificial neural networks (ANN) [M. Yamakou]\\nBased on the activation of the neuron, you can observe that\\nthere are two states: firing and not firing. The firing state can\\nbe defined by the activation function f.\\nIn the case of the standard model, the activation function is a\\nHeaviside function with a similar property current to the ReLU\\nfunction. The neuron sums the inputs Ii, and the final firing\\nrate results from passing the sum through an activation\\nfunction f.\\nr(I0) =f(N∑\\ni=1Ii)\\n. (5)\\nThis abstraction is used to move from the complex and\\ncomputationally expensive model to a simpler and cheaper\\nrate-based models. As a result, it is easier to model networks\\nof neurons. This transition has formed the basis for today’s\\npopular artificial neural networks (ANN).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ce4c015f-96b9-47a6-90a2-e8b80a660a9a', embedding=None, metadata={'page_label': '21', 'file_name': 'Lecture_s2.pdf', 'file_path': '/content/data/Lecture_s2.pdf', 'file_type': 'application/pdf', 'file_size': 3242248, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The inspiration for artificial neural networks (ANN) [M. Yamakou]\\nBased on the activation of the neuron, you can observe that\\nthere are two states: firing and not firing. The firing state can\\nbe defined by the activation function f.\\nIn the case of the standard model, the activation function is a\\nHeaviside function with a similar property current to the ReLU\\nfunction. The neuron sums the inputs Ii, and the final firing\\nrate results from passing the sum through an activation\\nfunction f.\\nr(I0) =f(N∑\\ni=1Ii)\\n. (5)\\nThis abstraction is used to move from the complex and\\ncomputationally expensive model to a simpler and cheaper\\nrate-based models. As a result, it is easier to model networks\\nof neurons. This transition has formed the basis for today’s\\npopular artificial neural networks (ANN).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5898534b-26ce-4ca6-b9ac-5b05230d5a13', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 3: Timescale separation analysis and dimension reduction\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5271434d-23d9-4a95-bd19-a27e6307e5c3', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objective\\nPerform timescale separation analysis of ordinary differential\\nequations (ODEs) and dimension reduction.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='fda886a8-7822-461b-bf06-8a9c41c7c760', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Timescale separation analysis of one ODE\\nConsider a 1D linear ODE characterized by a timescale ε >0:\\nεdx(t)\\ndt=−x(t) +ℓ(t), (1)\\nwhere the driving term (also called forcing term) ℓ(t)could be\\n(1) constant (2) piece-wise constant, i.e., it may change its\\nvalue after some time intervals (3) changes continuously but\\nslowly (4) changes continuously and rapidly.\\nThe solution x(t)of this ODE will approach the driving term\\nℓ(t)with some time constant εwhich can be\\n1short, i.e., has a small value (0 < ε≪1), in which case we\\ntalk of slow drive.\\n2long, i.e., has a large value ( ε > > >1), in which case we talk of\\nfast drive.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='54657396-09ee-4d64-a777-ca867daa6d7b', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Timescale separation analysis of one ODE\\nConsider a 1D linear ODE characterized by a timescale ε >0:\\nεdx(t)\\ndt=−x(t) +ℓ(t), (1)\\nwhere the driving term (also called forcing term) ℓ(t)could be\\n(1) constant (2) piece-wise constant, i.e., it may change its\\nvalue after some time intervals (3) changes continuously but\\nslowly (4) changes continuously and rapidly.\\nThe solution x(t)of this ODE will approach the driving term\\nℓ(t)with some time constant εwhich can be\\n1short, i.e., has a small value (0 < ε≪1), in which case we\\ntalk of slow drive.\\n2long, i.e., has a large value ( ε > > >1), in which case we talk of\\nfast drive.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='79b015fa-369c-4e75-8724-265df5f4c214', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Timescale separation analysis of one ODE\\nPiece-wise drive and short timescale: x(t)will approach the\\nvalue of ℓ(t)rapidly (almost instantaneously). That is, if\\nε→0 (i.e., 0 < ε≪1), then x(t)→ℓ(t).\\nPiece-wise drive and long timescale: x(t)will approach the\\nvalue of ℓ(t)exponentially (i.e., with some delay). That is, if\\nε→∞(i.e.,ε > > >1), then x(t)→ℓ(t−ε).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f3c3d06e-12dc-4059-aa0b-5cf29a52d107', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Timescale separation analysis of one ODE\\nContinuous drive and short timescale: x(t)will approach the\\nvalue of ℓ(t)rapidly (almost instantaneously). That is, if\\nε→0 (i.e., 0 < ε≪1), then x(t)→ℓ(t).\\nContinuous drive and long timescale: x(t)will approach the\\nvalue of ℓ(t)exponentially (i.e., with some delay). That is, if\\nε→∞(i.e.,ε > > >1), then x(t)→ℓ(t−ε).\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3d7c4820-736e-4411-8d3e-7640d9b38075', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Timescale separation analysis of a pair of coupled ODEs\\nConsider a pair of unidirectionally (like in chemical synapses)\\ncoupled ODEs characterized by the timescales ε1andε2.\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3ε1dx\\ndt=−x(t) +y(t),\\nε2dy\\ndt=−y(t) +ℓ(t),(2)\\nwhere ε1≪ε2.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='13fa2139-0d83-4482-91ff-5635b9384b07', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Timescale separation analysis of a pair of coupled ODEs\\nLet us generalize to a pair of bidirectionally (like in electrical\\nsynapses) coupled ODEs characterized by the timescales ε1\\nandε2.\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3ε1dx\\ndt=−x(t) +y(t),\\nε2dy\\ndt=−y(t) +f(x) +ℓ(t),(3)\\nwhere ε1≪ε2.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='83969109-da66-432c-937a-97434e97f502', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s3.pdf', 'file_path': '/content/data/Lecture_s3.pdf', 'file_type': 'application/pdf', 'file_size': 2513942, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Timescale separation and reduction of HH model to 2D\\nThe presence of multiple timescales in a set of coupled ODEs\\ncan be used to reduce the dimension of the system by\\neliminating the fast variables.\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3ε1dx\\ndt=−x(t) +h(y),\\nε2dy\\ndt=f(y) +g(x),(4)\\nsuch that ε1≪ε2⇒x=h(y), then the reduced 1D ODE is\\ngiven by:\\nε2dy\\ndt=f(y) +g[h(y)] (5)\\nThese are the types of analysis we will use to reduce the 4D\\nHH neuron model to a 2D simpler neuron model.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8f486f23-4b09-496a-87cf-2904b02f447d', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s4.pdf', 'file_path': '/content/data/Lecture_s4.pdf', 'file_type': 'application/pdf', 'file_size': 2780587, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 4: Reduction of Hodgkin-Huxley Model to 2D\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8d0857fd-bef9-434f-8727-273b7b8e3c0b', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s4.pdf', 'file_path': '/content/data/Lecture_s4.pdf', 'file_type': 'application/pdf', 'file_size': 2780587, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objective\\nUse timescale separation and similarity analysis of the voltage\\nVand gating variables m,h,nof the 4D Hodgkin-Huxley\\nneuron model to reduce it into a 2D neuron model.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9eed7807-9789-4915-b5ac-149112ff1b72', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s4.pdf', 'file_path': '/content/data/Lecture_s4.pdf', 'file_type': 'application/pdf', 'file_size': 2780587, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1. The Hodgkin-Huxley (HH) Neuron Model\\nFigure: Response of the Hodgkin-Huxley neuron model. Graphics taken\\nfrom http://www.genesis-sim.org/GENESIS/cnslecs/cns1.htmlMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='fca674ec-6421-46dd-bc22-e4a87bfb5060', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s4.pdf', 'file_path': '/content/data/Lecture_s4.pdf', 'file_type': 'application/pdf', 'file_size': 2780587, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' iii_variableshandmaresimilarverilyNtestEms\\ntIEiBecausethegatingvariablemisfastfastcomparedtohandmthetimeconstantImmusbesmallerthenthetimeconstantsthandTmieImethandImInNotethatthemshouldalsobefastcomparedtotheexternalstimulusIInotherwordsIshouldnotbetoofastforadimensionreductionsothatwecansaymfollowsimmediatelythevoltagevariableV', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='00ef516f-6d5b-4c7b-9e42-1695c74ca47a', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s4.pdf', 'file_path': '/content/data/Lecture_s4.pdf', 'file_type': 'application/pdf', 'file_size': 2780587, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"ConsidertheequationdigmailsmPmmmotifIfthevoltagevariableVisslowwhichisthecaseiftheexternalstimulusIisnottoofastandthegatingvariableshandncannotbefastbecausetheyarecontrolledbyslowerlargertimeConstantsthsImandtensTmAhemmwillapproachMoi.emmorapidlyandfastComparedtovoltagevariableVHencewecanreplacethegatingvariableMctbyitsinstantaneousvaluemyEvetti.eMctMaliceNotethatthistechniqueworksforallsortsofcoupleddifferentialequationswheneveryouobserveadifferenceintimescaleYoucanalwaysexploitthesetimescaledifferencestoeliminatethefeastvariabletetdqnthinfatedgeflytgth'DEzdogflygin\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='498b06d4-b5b2-4049-afab-af898f44dc30', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s4.pdf', 'file_path': '/content/data/Lecture_s4.pdf', 'file_type': 'application/pdf', 'file_size': 2780587, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='sothevoltageequationoftheHttneuronmodelbecomesCdtMgEnVMauimgLenaugleeV2ExploitationofsimilaritiestcorrelationsThedynamicsofthegatingvariableshandmareverysimilarinthesensethatifheincreasesndecreasesandviceversa\\nThereforewehaveamirrorsymmetrywhichallowsustosaythatIhatisproportionaltoMctieahitisverysimilartomitsuptosomeConstantKWewriteIheek.netLetusmakethisargumentmoreprecisebylookingatgraphgivenbelow', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6eb86f80-88d6-4e64-9e86-ac7493f61b46', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s4.pdf', 'file_path': '/content/data/Lecture_s4.pdf', 'file_type': 'application/pdf', 'file_size': 2780587, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='hahaiiiiiiAForanotherstimulusIthiscloudofdatapointsdoesnotfilltheentirenhplanbutitiselongatedaboutthegreenlinegivenbychRonWhenthevoltagevariableVspikesthegatingvariableshandMexhibitdetourswhichmirrorimagesConsideringthegreenlinechkonshowninthepreviousfigurewenoticethatif20thenhCwherece0,13Forthesakeofsimplicityletusassumethatc1', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='79316ff4-478b-4327-86e1-5522838e1a09', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s4.pdf', 'file_path': '/content/data/Lecture_s4.pdf', 'file_type': 'application/pdf', 'file_size': 2780587, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Ifhothenhow1Considerthediagrambelow\\niInthisÉÉjÉ'mthepointonIcanbewrittenintermsoftheoriginalcoordinatesystemnhcenteredattheoriginOThissamepointi.enihcanalsobewrittenintermsofanewcoordinatesystemGyercenteredatthevestpointdouresthallrest\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1a34e9d1-fa10-4b87-ab52-9267d0badcff', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 5: Reduction of Hodgkin-Huxley into 2D model Continued\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='28b9db9a-e5a5-4eeb-b780-77ea234c73e4', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objective\\nSame as in Lecture 4.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a069654c-46a3-4ccc-8902-99cb26a56373', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='AswehaveseenbeforeallthedatapointsareelongatedinthedirectionofunitvectorézSoanarbitrarypointfinhintheplanespannedbytheunitsrectorferezwillhaveaverysmallEzcomponentandespeciallyazeroEzcommponentatMusthastHencethepointfihwosowesuppresstheZcoordinatebecauseitisverysmallandsometimesevenzerowhichgivethereductionofdimensionality', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3a2faec2-6be7-4425-91cc-4e96af250d55', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Todeterminetheslopekoofthelinegivenby1hatKomitweneedatleasttwopointsonthislineOneofthesepointsisMresthrestwhichwecandeterminewithoutamistakei.ewithhighprecisionSoatrestwehavethat1haWestKomockestEoTFithetwodimensionaldescriptioninthe2dimensionalplanetoaonedimensionalcoordinatethatcorrespondstotheprojectiononthethegreenline1hitkometwhataboutthedynamicsWeknowthatdhahighanddmotifthat', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='45313f69-df46-45f4-80b2-7267495d12a5', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='isheapproachestowithsometimeconstantthandmapproachesMoowithsometimeconstantInThereforewecanreformulatethedynamicsofthegatingvariableshaduintermsofthedynamicsofanewvanablewbyTranslateandrotatecoordinatesystemSuppressonecoordinateExpressthedynamicsinnewcoordinateSowehaveIhatk.netwetdhqhateEn.atYdEWEILwiththeseanalysiswehavearrivedattheendoftheargument', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='517c0d61-dc6a-4830-bc22-c42b97abe637', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='IntheHHneuronmodelwehaveinsertedtheinstantaneousmomentaryvalueofthefastgatingvariableMctinthevoltageequationofthemodelMCEMaluetFromtheequationIhitWctwecannowreplacethevariablehatinthevoltageequationbyhitIwetrecallthatthisisbecausehitandmitaresimilarIIIkingAlsowereplacethegatingvariablenetsinthevoltageequationbyMctWEwheretheconstantkoisgivenbyktbtseeequationabove', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a854d52e-b773-4610-9ea6-65a737d6e9dc', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Sowecannowwritethe4D1Itneurointoa21neuronmodelascdqI.GEVMAIWHENVtgEVitdWIFEwhereMacvistheinstantaneousvalueofthemvariableCatvestsinceitisfastIfwemultiplythefirstequationabovebytheleakresistancegivenbyREROLEREGEnuREADINGEwartEVtRIwheremembranetimeconstantisgivenbyTRCthatcontrolsthedynamicsofthevoltagevariableVWedosomethingsimilartothetimeconstanttoffwhichisnottrivialtocalculatebutpossibleWeassumethattheeffectivetimeconstant', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='483f3487-0e21-4b46-873e-783ca70a0004', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='JeffLVchangesasIEnIEEEwhereTwissometypicalvalueandInteffwissomenormalizationfactorThenetresultisdifferentialequationforwwhereTwcouldberesvesentivevalueofte.gameanvalueoftbetweenoandVestetcwhichcontrolsthedynamicsofwSowecangenericallywritethe2DneuronmodelasIdoFVCEwetRIwdogGUctwet', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3aa2963c-ef34-4f52-b28e-ccd00faf3802', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s5.pdf', 'file_path': '/content/data/Lecture_s5.pdf', 'file_type': 'application/pdf', 'file_size': 2658518, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The2DneuronmodelinequationenablesgraphicalanalysisofthemodelandevenananalyticaltreatmentwhenTccTwTwCeTthegraphicalanalysisenablesustodiscussrepetitivespikinginneuronsandtodistinguishbetweenTypeIandTypeIIneuronsviatheirbifurcations', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6f1aec18-c2ed-441d-8d93-1d46a42d61d9', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s6.pdf', 'file_path': '/content/data/Lecture_s6.pdf', 'file_type': 'application/pdf', 'file_size': 2560544, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 6: Elements of Dynamical Systems Theory\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cd8b1e72-8d16-425a-90bc-04b79b4a979f', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s6.pdf', 'file_path': '/content/data/Lecture_s6.pdf', 'file_type': 'application/pdf', 'file_size': 2560544, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objective\\nPresent the basic notions of dynamical system theory, which\\nare essential in analyzing the basic dynamics of the neurons.\\n.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='daac26a4-6150-4ca0-8b20-8ede9b691900', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s6.pdf', 'file_path': '/content/data/Lecture_s6.pdf', 'file_type': 'application/pdf', 'file_size': 2560544, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' ConsiderthedynamicalequationsgivenbyIÉEUltWattTwdogEEvettwitwhereYWEIREFE5kIRk2ieEEareatleast2timescontinuouslydifferentiablefunctionsIccEwWedefinethefollowinginvariantsets1thesetoffixedpointsofequationdefinedbyVeWeYWEIREYwEYw042theVnullclineandtheWnullclineofEquationdefinedbyUnulldineVWEIREYw0WnulllineuWEMECUW0ExampleGonsideraspecificexampleofEquationwherethevectorfieldsaregivenbyIdyavwtIoTwdugevwThesetoffixedpointsofequationaregivenbyCeWeLuWfirauwIooowo', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='246faefa-996c-46d3-a8e5-e8a892785cbc', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s6.pdf', 'file_path': '/content/data/Lecture_s6.pdf', 'file_type': 'application/pdf', 'file_size': 2560544, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='IEEELEEqueEawecÉaSoveweUweinarwtfcuwoEgeEaWenotethatthefixedpointsofthedifferentiableequationrepresentinganeuroncorrespondtothereststateoftheneuronieastateinwhichtheneuronhasnoactivitynospikingthereststateoftheneuronisalsoreferredtoasthequiescentstatethernulldineisgivenbyVWUWeinwauIoTheWnullclineisgivenbyYWCWeINWcuVnullclineK0\\nIififthNotethatthefigureofthephasespaceaboveisobtainedundertheassumptionsthatC0IsoandCaSo', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8b83cde7-90a2-420a-8f6a-6ebf942a14db', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s6.pdf', 'file_path': '/content/data/Lecture_s6.pdf', 'file_type': 'application/pdf', 'file_size': 2560544, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ForcoIocaowecanhaveadifferentphaseportraitthephaseportraitwilldependonthesignofmagnitudesoftheseparametersstabilityanalysisqthequiescentstateConsideragainthegenericdynamicalsystemgivenaboveieTvEatTICVWTwoffEYwFixedpointVeweXWEIRFz5204oFivewetIoOFzVeWeLetuszoomintotheneighborhoodofthefixedpointveweusingthetransformationsEvvexUVeywweLayfewwejFaYwElatveyweLyedigdigEVWElateywe', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='717c34e2-a27e-4427-89bb-c97ea526faef', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s6.pdf', 'file_path': '/content/data/Lecture_s6.pdf', 'file_type': 'application/pdf', 'file_size': 2560544, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='IfwetaylorexpandECatveyweandEcatveyweaboutthefixedpointVewewegetEntreyweEveweveveEIwetytweweggl.aeIlatevetweavevalveweyhavewetIIIetHOTEentveytwefywejtntflq.netyafylue.netHOTNoticethatthetermEvewevanishesbythedefinitionofthefixedpointlecueweCWGirlFIEzoFIIntveywexUgglavetvewwewety25gvvetvewwetweFaintveytwex22fttYEySimilarlyforEentveyweweTa y l o rexpandandgetElutveyweIn25gtEy', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5030cd54-c6a6-417c-9e1a-c8bce4c103a0', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s6.pdf', 'file_path': '/content/data/Lecture_s6.pdf', 'file_type': 'application/pdf', 'file_size': 2560544, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='SoouroriginaldifferentialequationscanbewrittentugnJEEty2EywdaynEntyEylet3nythenwecanwritetheaboveequationinacompactmatrixformasfollowsEEJEwherethematrixJiscalledtheJacobianmatrixofthedifferentialequationgivenabove', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4c26541c-1e1a-4837-8867-bf66543680ea', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s7.pdf', 'file_path': '/content/data/Lecture_s7.pdf', 'file_type': 'application/pdf', 'file_size': 2267933, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 7: Stability Analysis of the Rest States of a Neuron\\n(Continuation of Lecture 6)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7e21497a-7008-434a-b6d5-99fd6661127d', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s7.pdf', 'file_path': '/content/data/Lecture_s7.pdf', 'file_type': 'application/pdf', 'file_size': 2267933, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objective\\nLearn how to determine the nature (stable or unstable) of a\\nneuron model’s rest state (fixed point) and their bifurcations.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='84772617-1bfa-4d9f-b7c3-369bea225fdd', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s7.pdf', 'file_path': '/content/data/Lecture_s7.pdf', 'file_type': 'application/pdf', 'file_size': 2267933, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Asearchforsolutionyields311ke'twherekickareconstantsandIfEaretheeigenvalueofJTocalculate1wesolvetheeigenvalueproblemgivenbydetJjAIJjAI0whereIisazxzidentitymatrixThetwosolutionsof1JjAtaregivenyandywhere7272271222122yXX271222722yOtay2h12mEquationaboveiscalledtheTraceofJdenotedbyTJEquationaboveiscalledthedeterminantofJletJthesolution3Itkoé'tCanaeitherdivergeorConvergencetowardsthefixedpointastoReta70IIeHencethestabilityofthefixedpoint5Cge8requiresthatRefnRe72720Refx2co\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2c2a824a-0183-4a16-ba4e-3c9fbdcb08b3', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s7.pdf', 'file_path': '/content/data/Lecture_s7.pdf', 'file_type': 'application/pdf', 'file_size': 2267933, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='IfReXaoandReasothenthefixedpointFeisunstableIfRe72720andRefa0thenthefixedpointJeisasaddlepointiestableinthendirectionandunstableintheydirectionIfRe71oandRefacothenthefixedpointJeisasaddlepointwhichisstableinydirectorandunstableinthendirectionIfRe71ReX70thenthefixedpointismarginallystableorsimplyundetermineinwhichhigherordertermsneedtobeconsideredintheTa y l o rexpansionNotethatthefixedpointcueweoftheoriginaldifferentialequationsgivenbytudigFlywEwdigELYWhasbeentranslatedtotheoriginThatiswehaveusedthetransformationsveunandwewytoshiftthefixedpointveweto0,0InotherwordsWehavetranslatedthedifferentialequations', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2f879860-d14c-4956-8ff5-37ae9939af71', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s7.pdf', 'file_path': '/content/data/Lecture_s7.pdf', 'file_type': 'application/pdf', 'file_size': 2267933, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Idyen2ÉtLazyIdgEYWtwEgn'EntZafywdyEYwseethatthefixedpointseethatthefixedisatCeeYee0,0pointisatfuewetwhichcouldbeatanyvaluesNotethatfora2DdynamicalsystemwithfixedpointVeWeandJacobianmatrixJwehavethatTrJo4Cueweisstabledet570IampleInvestigatethestabilityofoneofthefixedpointsofthesocalledFitzhughNagumoFitrneuronmodelgivenbythefollowingequationsdayVavv1WFwiwIfEbuewGYwwhereuweitrepresentthemembranevoltageandrecoverycurrentrespectivelyOac1bocoandOcEdcIareallconstantparametersTtÉfixedpointvewei.ethereststateoftheFAneuronmodelthevariablesvetandwitreacha\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1a9e72b3-e92e-42a3-a537-bbd1f2359c76', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s7.pdf', 'file_path': '/content/data/Lecture_s7.pdf', 'file_type': 'application/pdf', 'file_size': 2267933, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='stationarystatewhilethesetoffixedpointsisdefinedbytheintersectionofnulllinesasVeweywelkFUwGvWoFromequationweobtainthefixedpointequationsasweevewhichhassolutionsforthevvariableasiVeI0veFYi_bwhereVezandNeexisti.eVezve112onlyifwehave19,1ISinceweassumedthatb0c0andOcactwehavethefollowingorderingVezLaCVez1VezandUnCoincidei.eVezVezwhenwehaveL', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='71a97d91-de22-4848-8b8d-e1c99442b69a', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s8.pdf', 'file_path': '/content/data/Lecture_s8.pdf', 'file_type': 'application/pdf', 'file_size': 2217166, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 8: Stability Analysis of the Rest States of a Neuron\\n(Continuation of Lecture 7)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='709e8bf7-4469-476c-bb74-4b2398d93381', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s8.pdf', 'file_path': '/content/data/Lecture_s8.pdf', 'file_type': 'application/pdf', 'file_size': 2217166, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objective\\nLearn how to determine the nature (stable or unstable) of a\\nneuron model’s rest state (fixed point) and their bifurcations.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='076365da-26ac-4a50-b1ac-720c37f82a55', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s8.pdf', 'file_path': '/content/data/Lecture_s8.pdf', 'file_type': 'application/pdf', 'file_size': 2217166, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ForthemomentLetusreturntothegeneralfixedpointcueweandstudyitsstabilityInordertodeterminethestabilityofsuchafixedpointweneedtostudythelinearizedmatrixequationEEFAV2712WHav2GWYdJVeWethestabilityofthefixedpointehwetwilldependonthesignsofthetraceTvJanddeterminantdefJoftheJacobianmatrixJUeWeForafixedpointvewetobestableitsufficestoshowthatTJLoanddet570WecalculateJoeweJoeweEbeeTrJivewe3vEt2at1veaEedefJVeewe3CEVEZECattvetEaetEb', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='72cc71b0-0edc-4b15-b633-a56c7f4573a5', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s8.pdf', 'file_path': '/content/data/Lecture_s8.pdf', 'file_type': 'application/pdf', 'file_size': 2217166, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"NowLet'sdeterminethematurei.estableorunstableofoneofthefixedpointsVesWesezWeNesWeIchoosethesimplestofthefixedpointsi.eVasweooSowehaveTrJVezWenatedntJivewentEcacbSinceocac102Ec1C0andb0wehaveTrJCVerWeaLOdettiveswesoVesWesooisafixedpointarbitrary22matrixgivenbyJEThenwehavethatTJatdDetJiadbeAlsothecharacteristicequationassociatedtothematrixJisgivenbyDetJXIIXI0whereIisthe22identitymatrixandXtheeigenvalueofthematrixJwehavethatX0\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='23e87b23-6574-4a1a-8ca0-20d22c257fe5', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s8.pdf', 'file_path': '/content/data/Lecture_s8.pdf', 'file_type': 'application/pdf', 'file_size': 2217166, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='11aabcdo0axdXCboXCataaadCboUsingthequadraticformulawegettherootsofabovequadraticpolynomialequationasX19IycatapacadataaftattackwhichcanthenbewrittenintermsofthetraceanddeterminantofthematrixJas7EEEINAUDIX2IfEYtrJ54DJWenoticethattheeigenvalues7and72ofthematrixJareinfactsolutionsofthesecularequation72TrJtDet50wheretrJandDetJare', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e2871e3d-b50e-4404-aa82-9a2c0a02e1cc', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s8.pdf', 'file_path': '/content/data/Lecture_s8.pdf', 'file_type': 'application/pdf', 'file_size': 2217166, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='thetraceanddeterminantoftheMatrixJrespectivelyThereexistthreetopologicalequivalenceclassesofhyperbolicfixedpointsintheplaneiein1122namelyµStablefoniorstablemodesalsocalledattractorsandareattractiveinalldirectionsiiunstablefociorunstablemodesalsocalledrepellersandarerepulsiveinalldirectionandiisaddleattractiveinonedirectionandrepulsiveintheotherTheirclassificationaccordingtothetypeofeigenvalueisgivenbythetablebelowEigenvalues\\niiii', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e6dfd540-57e3-4371-a525-81c54dbdf307', embedding=None, metadata={'page_label': '1', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Lecture 9: Hopf Bifurcation Analysis in a 2D Neuron Model\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f3f3d972-d469-45bc-bcec-d27f2b59d37e', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Objectives\\n1Understand one of the processes via which neurons change the\\nstability of their quiescent and spiking states.\\n2Understand what a Hopf bifurcation is.\\n3Show the existence and calculate the direction of a Hopf\\nbifurcation in a 2D neuron model.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='44de30e7-aec9-451a-a1af-d332c90e5648', embedding=None, metadata={'page_label': '2', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\nConsider the differential system given by Eq.(1) with a parameter\\nµ∈Rsuch that\\ndx\\ndt=(dx1\\ndt\\ndx2\\ndt)\\n=(\\nf1(x1,x2,µ)\\nf2(x1,x2,µ))\\n=f(x,µ),(1)\\nThe parameter µcan modify the behavior of the solutions of the\\nsystem. Thus, it should be useful to represent the evolution of the\\nfixed point xeaccording to the variation of the parameter µ0.\\nFor a differential system dx/dt=f(x,µ0),µ0is called a bifurcation\\nparameter if a topological change of a solution occurs when the\\nparameterµ0changes.\\nIt is called a bifurcation parameter because it can completely change\\nthe behavior of the solutions.\\nThere are many types of bifurcations but in this course, only the\\nAndronov-Hopf bifurcation (or Hopf bifurcation for short) is\\ndiscussed in detail, as it is crucial for the spiking phenomenon we\\nare interested in.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c6a861ae-0104-4518-ac1f-9cae54285c78', embedding=None, metadata={'page_label': '3', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\nFor a fixed point xeof a differential system dx/dt=f(x,µ), the\\npair (xe,µ0)is called a Andronov-Hopf bifurcation point when\\n1TrDxf(xe,µ0) =0,\\n2DetDxf(xe,µ0) =ω(µ)>0,\\n3d\\ndµTrDxf(xe,µ)|µ=µ0̸=0.\\nThe first Lyapunov coefficient L1̸=0 defined as:\\nL1=1\\n16(ω(µ0))[\\n∂2f1\\n∂x1∂x2(\\n∂2f1\\n∂x2\\n1+∂2f1\\n∂x2\\n2)\\n+∂2f2\\n∂x1∂x2(\\n∂2f2\\n∂x2\\n1+∂2f2\\n∂x2\\n2)\\n−∂2f1\\n∂x2\\n1∂2f2\\n∂x2\\n1+∂2f1\\n∂x2\\n2∂2f2\\n∂x2\\n2]\\n+1\\n16[\\n∂3f1\\n∂x3\\n1+∂3f1\\n∂x1∂x2\\n2+∂3f2\\n∂x2\\n1∂x2+∂3f2\\n∂x3\\n2]\\n,\\n(2)\\ndetermines the criticality (direction) of the Andronov-Hopf\\nbifurcation. The Andronov-Hopf bifurcation is super-critical if\\nL1<0 andsub-critical ifL1>0. When conditions 1 ,2,and 3 above\\nhold, a unique isolated periodic solution (limit cycle —\\nself-sustained spiking activity) bifurcates when the value of the\\nparameterµpassesµ0.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='60fb5648-6e29-4ac1-bdc5-72aafe342818', embedding=None, metadata={'page_label': '4', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\nIn the theory of bifurcations, a Hopf bifurcation is a critical point where a\\nsystem’s stability switches and a periodic solution arises.\\nFigure: Dynamics of the Hopf bifurcation is governed by eigenvalue value\\nz=λ+iω. Possible trajectories are in red, stable structures are in dark\\nblue, and unstable structures are in dashed light blue. Super-critical Hopf\\nbifurcation ( L1<0): 1a) stable fixed point 1b) unstable fixed point,\\nstable limit cycle 1c) phase space dynamics. Subcritical Hopf bifurcation\\n(L1>0): 2a) stable fixed point, unstable limit cycle 2b) unstable fixed\\npoint 2c) phase space dynamics.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='02e4bb43-020e-4973-afee-3bc15fa14cf0', embedding=None, metadata={'page_label': '5', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\nIt is helpful to draw the bifurcation diagram (one of the\\nvariables versus the bifurcation parameter) to understand how\\nthe system is modified when the parameter µchanges.\\nTo illustrate this, we consider equation{\\ndv = (v−v3\\n3−w+I)dt,\\ndw =ε(d+v)dt,(3)\\nwith 0<ε≪1. The nullclines of the system are:\\n{\\nvnull:w=v−v3\\n3+I,\\nwnull:v=−d,(4)\\nand therefore, the fixed point is\\n(ve,we) = (−d,−d+d3\\n3+I). (5)\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3ec2bcd6-9d84-44bc-8705-084507741d65', embedding=None, metadata={'page_label': '6', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\nHere,dis a bifurcation parameter that can drastically change\\nthe neuron’s behavior.\\nTo see this, we study the behavior of the linearized system in\\nthe neighborhood of the fixed point by looking at the\\nJacobian matrix at (ve,we):\\nJ(ve,we) =(\\n1−v2\\ne−1\\nε0)\\n,\\nwhere detJ=εandtrJ=1−v2\\ne. The eigenvalues of the\\nJacobian at (ve,we)are\\nλ1,2=1\\n2[\\n(1−d2)±√\\n(1−d2)2−4ε]\\n.(6)\\nFollowing the table given in Lecture 8, depending on the value\\nof the parameter d, we identify the following three cases:\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a86eda2b-d8c6-417b-a94a-2bd4ed54ec5b', embedding=None, metadata={'page_label': '7', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\n1If|d|>1, then (ve,we)is stable node. At this point, it is important\\nto point out that a neuron is said to be in an excitable state when\\nstarting with some initial condition in the basin of attraction of a\\nunique stable fixed point will result in at most one large\\nnon-monotonic excursion (spike) into the phase space after which\\nthe phase trajectory returns and stays at this fixed point.\\n2If|d|<1, then (ve,we)is an unstable node and there exists a stable\\nperiodic cycle around it. The neuron is said to be in oscillatory state.\\n3Ifd=1, the fixed point at (ve,we) = (−1,−2+I)is a\\nAndronov-Hopf bifurcation point, for all I≥0. Furthermore, the\\nvalue and, most importantly, the sign of the first Lyapunov\\ncoefficient is given by L1=−8.0. This implies that the fixed point\\nat(ve,we) = (−1,−2+I)undergoes a super-critical Hopf\\nbifurcation; i.e., the stable fixed becomes unstable by creating a\\nstable limit cycle (spiking) surrounding it.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='89952df7-d85c-4d34-bc7d-4bd58dc294f0', embedding=None, metadata={'page_label': '8', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\nThe bifurcation diagram for Eq.(3) above is shown in the Figure\\nbelow, where we can see the range of values of the bifurcation\\nparameter dfor which we have either a no spiking (no limit cycle)\\nor spiking (limit cycle).\\n−1 0 1 200.511.522.53\\ndvmaxfixed pointlimit cycle\\nHopf bifurcation points\\nFigure:Bifurcation diagram computed with the maximum values ( vmax) of the\\nmembrane potential variable. The blue circles represent a stable fixed point for\\n|d|>1. When|d|=1 a Hopf bifurcation occurs. When |d|<1 the system has\\nan unstable fixed point and a stable limit cycle. ε=0.05,I=0.001.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e3ab1c2c-564e-41e1-b8ac-e7a9a06ac238', embedding=None, metadata={'page_label': '9', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\n(a)\\n−2 −1 0 1 2−1−0.500.51\\nvw (b)\\n0 100 200 300 400 500−2−1012\\ntv,w\\n(c)\\n−2 −1 0 1 2−1−0.500.51\\nvw (d)\\n0 100 200 300 400 500−2−1012\\ntv,w\\nFigure:In(a)and(c)the red curve represents the cubic v-nullcline, the green\\nvertical line is the w-nullcline which intersects the red curve at the fixed point\\nat(ve,we) = (−d,−d+d3\\n3+I). The blue curve with arrow shows the behavior\\nof a trajectory with initial conditions at (vi,wi) = (2.25,−0.35)ford=1.05 in\\n(a), and d=0.95 in (c).(b)and(d)show the time series of v(in blue) and w\\n(in black) of the phase portraits (a)and(c)respectively. In (b)the model is in\\nthe excitable state with no possibility of a limit cycle solution, while in (d),\\nthere is a limit cycle (Spiking). ε=0.05,I=0.001.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='efb72163-5bc9-4a5a-bd64-5ff90a419ce5', embedding=None, metadata={'page_label': '10', 'file_name': 'Lecture_s9.pdf', 'file_path': '/content/data/Lecture_s9.pdf', 'file_type': 'application/pdf', 'file_size': 1110349, 'creation_date': '2024-08-05', 'last_modified_date': '2024-08-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Andronov-Hopf Bifurcation in a 2D neuron model\\nRemark: The stimulus current Iin Eq. (3) is not a bifurcation\\nparameter. Fixing dand varying I≥0 only moves the red curve\\nrepresenting the v-nullcline upward if Iis increased or downward if\\nIis decreased. Since the w-nullcline is vertical, changing Idoes not\\nchange the position of the v-coordinate of the fixed point at\\n(ve,we) = (−d,−d+d3\\n3+I)and therefore, the fixed point remains\\nstable if|d|>1 or unstable if|d|<1. This can also be easily seen\\nby looking at Eq.(6) above, which determines the stability of the\\nunique fixed point (ve,we), which is independent of I.\\nMarius Yamakou (marius.yamakou@fau.de) Theory of Neural Dynamics & Application to ML based on RC', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a Q&A assistant. Your goal is to answer questions as accurately as\n",
        "possible based on the instructions and context provided.\n",
        "\"\"\"\n",
        "## Default format supportable by llama2\n",
        "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ],
      "metadata": {
        "id": "MInUBr7GuPev"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = \"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\"\n"
      ],
      "metadata": {
        "id": "DOWOkg5Rz_E3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    tokenizer_kwargs={\"token\": HF_TOKEN},\n",
        "    model_kwargs={\"token\": HF_TOKEN, \"torch_dtype\": torch.float16, \"load_in_8bit\":True},\n",
        "    device_map=\"auto\",\n",
        "    # uncomment this if using CUDA to reduce memory usage\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "6f44f25518fb4e06b2f91a40c4392d91",
            "23186c287e6248f699ee0c81e5d9da7a",
            "cd65aa5e68e3411dbc71139ca9797d03",
            "48bf1e2a7d1e438bb6ffc519194797bb",
            "2a3610f955c84452892513e2fe37611f",
            "2b62f25e7c594b109f2a78b1e440d8b4",
            "9e4fbc333a214b7c9220d736d3a73798",
            "c3ee8cf36f4c41e1b2db8b24dd70a18a",
            "94768292709e4d71a56db30d4778c0bc",
            "3d88fc8d38804c5f9b8f670922d05979",
            "368b868468a64933b71e0cbe6ce11946",
            "a2043ec35e4f4d3d951bb9fd45b25f8b",
            "1dc10852032c4cfe967aa69301c645f9",
            "71cf0489caab462ebc3ee501e514e6c3",
            "1516ca70c6f84c86a8696cf607d03d7d",
            "3edc97bce2a2464dbf9eae1f5492ced7",
            "9368a2ea1ff740659040f9df00c9cf70",
            "ddce9ee35bdc47c384d26c84a395d1dc",
            "1972bc94832d4498bf9e1d20a0c0e2f1",
            "98a7c2fa34cf4b30966f16cff77d556c",
            "3dcec5edfa7d460f96e4fa25453bab85",
            "83a339373e7545f2bafa38b5bac22f89",
            "7fde39d34b91442d84aaf6f1089d20f7",
            "8d05943c50334fbaa3dcc5ff6b97d1e7",
            "a32a92fd8b3d462695bdf75c60085eab",
            "f6b25b2b9694422da7efb6bb8f928f04",
            "0df2d910af13486690fc794a6c8271ae",
            "9625cb33e26642209ab32abc4a36464e",
            "7c34927a88034f3c970f8dd4cccc9a2f",
            "85e4699427c840eab0dfb06e5ae03e08",
            "7692035db3f6483ab83284352d171379",
            "5aa6f900a01d4576bc5d247c29d64410",
            "af88faad4c8d4cb1887501c9e30351f6",
            "5a7ec53a2a654edbb649723d9f237845",
            "bcc75806a4e64ad484639af4b0a3a8e8",
            "34546d917667447787e3ce76b04d67dd",
            "e31a6092c8be4e358eb03362cca38fe2",
            "aded0e543ca941318750705f8221f966",
            "564416f44e854691ba1534375def19c8",
            "e24c6d3012024d5db0741c40f484b515",
            "9b7bc54d5cbe438292831364dcae0673",
            "b93d1829220b4c74a4c6573ade108800",
            "49f4e568589b4afa9c6ff843627013cc",
            "a85edd49a25a4af9a161cd039d1d8767",
            "820ce7adac774fed80309d963109fd0f",
            "83fcdd717fbb47c0b611c5d7dd5a8d29",
            "78ca0f3dcf89406f8b0753d5a6c2bc14",
            "4c35956eb73d414ba15ba5ebf3aafeef",
            "901135536aa546ff9c7214c57f49a6a7",
            "f1b52925d0c7489eae1b1f2fe4755c2e",
            "0428a6d06c1a4b5a801c132bd87e4d7d",
            "dca67f3cc34d45c599b2c69dafa17fce",
            "9fbf2edd3e1647ab9f5f912e964aa0ed",
            "2fc5ee63c2c14c22bd6f6e80c3d94055",
            "1f36e5588c444f06ba794fb2a39247f4",
            "24a9e407b46d40c6af2505c24ce2ac9e",
            "ef6118a4805542368862eb4af4fe9097",
            "e765b1d1ec5a4726b54cf5fd002dd710",
            "1f0b1e9b4d9040749d0d7a8bf90855ec",
            "d2bb2017a864437cbd87caae59bbf499",
            "c9fba519e21f441eac977bbf0ec7cef5",
            "2f893b02cd9943b3a993fa0a2b1d4016",
            "9c154b8107604d1c9e1e8eef658a2549",
            "57c09239648b469d947eea45903bc08a",
            "b00eb3d1e74a4279b6e59b43bffd56f6",
            "4755b7a0fd5e4e03b05b5a1d6dc66345",
            "6de30dbda7db47869a9b3a943536c614",
            "c4251b30ca904278b9c1cd907d2ea33c",
            "00b0001629a641c284964ba5ed671f73",
            "9471753f1c3541fdab8f58d2de85ce25",
            "c6534ba2e08d4b25ac9b8b218f1d30b2",
            "b8f31d2572604f22b37f54a7c0122340",
            "57b7dd1abe9e41bea5f6e1221c62ec8e",
            "085833309e7d4ecbb3b68f48f9ce4b99",
            "1f260a76dfaf4a5abb1e7ec5c37f2430",
            "c4c5624fd0b042d0b45b9937efb61a79",
            "839bc671e5dd48a4a0a488494caa594f",
            "b0cc51d8af524bda93c87a51aeb668bd",
            "65b7fb7ce2164875b962b2749f1b3b23",
            "36bc261dbffa4d71afcbc4141185cd16",
            "3ab0120f427e45e49d45d80e448d19e9",
            "16d7071b113c480191a4aeaf7c6d3644",
            "2f3efb4bac6e40f5b0ffa0efeeda8b7c",
            "d0d3943866e344d3809de54f60d78c98",
            "108729f80ee54e4d80268bbc1550dd3d",
            "68e9a7ff491543f38d9986eabd057f78",
            "5017fe0f175d46d3be30d818b107d849",
            "a2b43515c26442fdbf52c3dcc01849b0",
            "7e47f91060af45589ce64113762d253b",
            "38694bf78ea44694841f0871d48327d4",
            "5a3d6534d9824991a33fd59454613bfa",
            "a2eb66b5210d4a1ea212efc4357c5fb0",
            "73f409df692c44e2884196d8067067e1",
            "c52b52b2d9744c1f990c756c486aae73",
            "539653d0fc714982b22d29e1b711ff81",
            "cebac32c040a44008e29c83f6baca16f",
            "053fb6ab8e3841abbcfaa70303449527",
            "b169dec2097b4960ad1b7578c16a616e",
            "9ac45475f2134fcca6e6a6455c27aa83",
            "b9011770f8d741ecbc2cfa54349d33c1",
            "18de817313834c87a1ae662b3b23d2f7",
            "c9675e14bbdc4112a8f13568a43b71fc",
            "7d01b671527c490aa149b982f5fafefa",
            "0c6514f0c9944068a214982cb051438a",
            "ae794a04f0c14b969e94fadf7f717d76",
            "8bc4173fd8f44431ac40790ed627df5b",
            "42cb7e18bd7044a3a05cd866deeb42d3",
            "f3f302f66fb349d5adebe110d54cba80",
            "7dde47747db94502b4d0f24ebcd48790",
            "7ceaa16c81d64ccca55492d979e5c506",
            "ac9d01d1c2c246bb884dc58c7c172a9b",
            "5c72ec540f6e472ea5883f56f22c38c0",
            "04d91a1433cd43b9856f346f34d4c8e1",
            "84489bb79ceb434e82249c5fb519209d",
            "0a9c2e0034af487099657c37a58ebc93",
            "39a1537271544a2aa13ae2d08269ecd0",
            "7bdb89d2b1564c62b786acaab8b530a6",
            "d21d18790bff452589336d29e28d0d7e",
            "4f82bed047034a5382de937b694ea5e6",
            "5a99d3707a36477e946a3acbd2ce4bba",
            "0a786e5d745540fc856e2753be11ed4b"
          ]
        },
        "id": "fQuiGa5GvMBL",
        "outputId": "90583154-a719-498e-ae00-1bd82548bdfa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f44f25518fb4e06b2f91a40c4392d91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2043ec35e4f4d3d951bb9fd45b25f8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fde39d34b91442d84aaf6f1089d20f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a7ec53a2a654edbb649723d9f237845"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "820ce7adac774fed80309d963109fd0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24a9e407b46d40c6af2505c24ce2ac9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6de30dbda7db47869a9b3a943536c614"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0cc51d8af524bda93c87a51aeb668bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e47f91060af45589ce64113762d253b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9011770f8d741ecbc2cfa54349d33c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac9d01d1c2c246bb884dc58c7c172a9b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts0KL_Yq4wN2",
        "outputId": "5a406506-ce1f-46a0-91a1-7e83914e320c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.12)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.28)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.96)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain-community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-community\n",
            "Successfully installed langchain-community-0.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2wEMBg95Dh2",
        "outputId": "23be36a4-06d8-4f0c-babe-b5df920ff3dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-embeddings-langchain\n",
            "  Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl.metadata (663 bytes)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-langchain) (0.10.59)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.38.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.16.0)\n",
            "Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: llama-index-embeddings-langchain\n",
            "Successfully installed llama-index-embeddings-langchain-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "660a430b570943fea33c49c64b787f22",
            "1a2855aea5004a8d83d27f3141996e69",
            "900f479d347c4a548c424957eec0a570",
            "6fefcd1997294b51a698796c862563e0",
            "dbd8303a68a44f30a2caa4d9b1edd85b",
            "22e5a55c556741d0b414351dd69539bd",
            "5b0be9e08d4e4114ad327512e02c21b2",
            "f3825c68edaf45748fe5c219d06b510a",
            "08c16ecc0ccb40989553a026aeaa83c0",
            "088d3f465a014be6b2e5fba053cf8251",
            "567c39ae2edb423fa9fe65710d025b70",
            "0ae25547c0ad4f168ea9c4328ee30b98",
            "5a3529bffb534abcaa6513a6465f8630",
            "92560faf9f4742499cc9f888ecbe0a0b",
            "94eb8d49696b49ccbf917c67b9116e36",
            "1a10eb44a5744618a22fc0b0e3eb875c",
            "c0cb631bb6d14e50a28162daf8e9f097",
            "2d2d75f1c0a7402ab60e7547e84f7140",
            "8de3b6b82bae40b1b35348e415d2652b",
            "f461197184a242378cac80d9bb0a13ca",
            "5c158b0ea8044d298880543ba8c91ac1",
            "857566c52dd14bf09288933f3796802e",
            "0058df8af6e04a99a4c515e861cdd840",
            "cf3f2e7406664f99aaf4fb07b894cb55",
            "e04d3e2c405b4fa8ae31e7a584c8dc85",
            "f6f4e0430c554df4b6d2b69ef8f539ff",
            "1f34cdcc18c1455baa2a7ccda2b0b1de",
            "aef89f5053e448c7883bde176f0326c0",
            "24c64127d3c44545b04c65b0b26bedd1",
            "6cce74ca94ab485d984eae8def8f6feb",
            "975a6a1d3617480a9db4fe468f42d337",
            "77651858867541888a9f3b9e89dda820",
            "6e682385575640379a502225120bb2b5",
            "f0ab1a4d686c45f29cb42a0305335564",
            "dae1ac367f824b7b802bbb33dfc58f80",
            "7c1b86b554f64d858662903201c73fcd",
            "d9786aad6a2c4efea5a2359efa49a31d",
            "0e3ff65d74d24827bc8f252327765ece",
            "b67345449c1d47569793ed412bd76695",
            "0581db2aabb4449aaa978d20763ae1fb",
            "e5226df417164e98a319262e6c7bf9c3",
            "43aefacf9dec400fb2bd239989239cc7",
            "3ad013d907844779927317db7d4b4f9e",
            "e5a23cc0dc254ffeb9ae117bf9f5102c",
            "64b720cd90cd4320868a79bafa5eb9d1",
            "1a8d8eeda36a4e2ca561981d6b343697",
            "22a92851d818474ab870cf67d11cb22c",
            "6714d59d686d4914a42926abcba63f24",
            "19098490e90946538e88ff37574092ec",
            "ef007d2e3614491bb1be8c48bd5c71cc",
            "82da42c27611403d99864e9bab91dec8",
            "4d3a25c49b7e4aff92ddee21ac88f73b",
            "4b19907cd45d4d56beb7bd7c7d1ca8b0",
            "a1573b90a6934bcc97cd704bab512334",
            "9765c4638d044d27b3bf413a0aaa201b",
            "9d85880f3bf343e2a4e4a7a3ed19ca80",
            "7ba598730578459390390d5b30ac96a6",
            "7b19566be7594dd087f6b860c46907aa",
            "9c49270cfdf847c685ab37a230636903",
            "74606bf5bc844e6b94f7f84d1f42b039",
            "31f249ed50d546b6bea739720a976371",
            "69f4fe206d744323bc7fd25ff6105c39",
            "110ff227953a4ff88e885839e7f97cb0",
            "ff0595a3699746c6a0445abc112fa733",
            "94bed7f33b7a455aa6fc84b26829a341",
            "8b48f8bc09a54ecbacb8c3031926b63d",
            "59d7ae8a67cc41329308a3cbf7f5b739",
            "19c22b17485f4058abd4a4cd532de5b2",
            "9a5d5561b7b6478a813da55cfd6c8570",
            "1a7fb1ec7c85490f88a0fb5ebcecdc29",
            "e21362aa9b0443be81ae406079f1797f",
            "8b4170db6cdf4160843a7693d0fec4a6",
            "334309978afb4ca3b61bad493d4401a6",
            "37b1def29f6c42f99867b3f5510ef278",
            "ee865b74415d4de5890a154fade0a2ec",
            "23084bb3f345411a9c1e416cb875bc49",
            "5642c46b500d4694a1187bf4d0ba53a8",
            "700cbf3774404a35a6f051787b886f27",
            "50e93e5d27094adfa755566be9013349",
            "0ac982a2c41342acb60708b6b7db8e44",
            "6229d96ac9e84c969b20427e804e0854",
            "c79290b97be04ff3a4d611de3809026e",
            "427edc9628224d0398effe145b67cc90",
            "d50483c1ac4844618c2e61d385f17fcd",
            "a103e5d1946d4b16be574d7ec1ded456",
            "d6244ead88f04f0baa5f8beda7382a0a",
            "6e1dd139cee44ab49db527b204abe50e",
            "b092327659e740d7a72485c3e1ac19ba",
            "8c5d5d23c15d4198a064d690336e9160",
            "07661b4c79794fafb8994bacc0f74746",
            "7759827cd7d34ae4b115014ef8d3b715",
            "9c9f2a95f38f4e33b8429917ccd5af8d",
            "75d3f95468424924a8a2e5f00f9fd809",
            "4bdab3a6c83341ab9f83deb24c21c52b",
            "52a0bddea5014317945566d3fb102fa0",
            "91f48715f4fd45cfa89786ebebdd6a45",
            "3cf0b778b1224ad2b6fa0b18966506a5",
            "cc1a469e40fc494db65d6f85a01b8439",
            "00a3edeb1f82474eab845cadda14e6eb",
            "0b14563674e046cc92cbe32a6c26e073",
            "398a7903e32e46fd879e49dba0602638",
            "48c737d0b6d6416b90436d5fc711a12c",
            "37cca22f018d441e9d51ffb42e80eb4d",
            "02db7dfda8404d2eb4a7e3a761f33a6a",
            "b451941d17934dffa39478a95ac35877",
            "efea7d0297ae4a1fad457a68798d16a6",
            "4c3e205726c34f19be623259cf6696b1",
            "1b2ca0c463a740949c050e940884dad4",
            "5fa3eb6fdc9f46f7aa1fecfdb359c136",
            "bdc920c630574a3eb3569cbb447594d0",
            "8c80f1d3985241d9bcdaad0c547446db",
            "e94b90d5d09040f290d8df3c3a590033",
            "8822b38ab43142c1b6ccf51f99473d95",
            "661fca0d34374a96a4e625a177edc15f",
            "a5a48eb63dbb49d59965f0cf82e091a7",
            "4e4c150ed15546f6b650745e841d57a2",
            "77a93f0ebdd14e3db2d9561e8c5fad51",
            "623ddc42e76f46fe9df818517dc1fae5",
            "ac7c6c90a5fd44c2ba466da3be0bedbf",
            "80802eb6aa384d93add2ded4147debcd",
            "fd662d4aca3d460c97fc2c9cac97dc91"
          ]
        },
        "id": "66V-a7D7wUZd",
        "outputId": "901229f0-12d8-4531-c206-81b956414723"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "660a430b570943fea33c49c64b787f22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ae25547c0ad4f168ea9c4328ee30b98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0058df8af6e04a99a4c515e861cdd840"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0ab1a4d686c45f29cb42a0305335564"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64b720cd90cd4320868a79bafa5eb9d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d85880f3bf343e2a4e4a7a3ed19ca80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59d7ae8a67cc41329308a3cbf7f5b739"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "700cbf3774404a35a6f051787b886f27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c5d5d23c15d4198a064d690336e9160"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b14563674e046cc92cbe32a6c26e073"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c80f1d3985241d9bcdaad0c547446db"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BfIS4804scW",
        "outputId": "a8879137-caa3-4de7-cd4d-87900ba3d405"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-6394536e40c5>:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vyE9TCw5jbZ",
        "outputId": "9b237d91-cd6d-44fe-80cb-5b4539abcb3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ServiceContext(llm_predictor=LLMPredictor(system_prompt=None, query_wrapper_prompt=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>), prompt_helper=PromptHelper(context_window=4096, num_output=256, chunk_overlap_ratio=0.1, chunk_size_limit=None, separator=' '), embed_model=LangchainEmbedding(model_name='sentence-transformers/all-mpnet-base-v2', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x790ec6e10130>, num_workers=None), transformations=[SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x790ec6e10130>, id_func=<function default_id_func at 0x791014e7ac20>, chunk_size=1024, chunk_overlap=200, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')], llama_logger=<llama_index.core.service_context_elements.llama_logger.LlamaLogger object at 0x790ec61eb790>, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x790ec6e10130>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "Ef4tvyD55lfP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH1W4yLm5ywG",
        "outputId": "69dfe470-d4ab-4703-82d2-61910f51f8ac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x790ec71429b0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "KqwvfGS850wE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"tell me different types of synapses \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibBs274A57jk",
        "outputId": "fce07363-ecbb-4f9d-8262-306105e4ca5d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISV-bA006Drv",
        "outputId": "076a6990-60bb-432f-c76d-c062d5c2bd75"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are two main types of synapses: chemical and electrical. Chemical synapses are the most prevalent and involve the transfer of neurotransmitters from a presynaptic axon to a postsynaptic dendrite. Electrical synapses, on the other hand, allow direct and virtually instantaneous flow of electric current through special intercellular connections called gap junctions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lbOWNHZv6aKI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}